{
    "2": {
        "bug_type": "UAF",
        "buggy_value": "((delete, /data/jiangjiajun/LLM4Security/data/projects/linux/net/key/af_key.c, 2669, -1), ValueLabel.SRC)",
        "relevant_functions": [
            [
                "/data/jiangjiajun/LLM4Security/data/projects/linux/net/key/af_key.c"
            ],
            [
                "pfkey_spdget"
            ],
            [
                "static int pfkey_spdget(struct sock *sk, struct sk_buff *skb, const struct sadb_msg *hdr, void * const *ext_hdrs)\n{\n\tstruct net *net = sock_net(sk);\n\tunsigned int dir;\n\tint err = 0, delete;\n\tstruct sadb_x_policy *pol;\n\tstruct xfrm_policy *xp;\n\tstruct km_event c;\n\n\tif ((pol = ext_hdrs[SADB_X_EXT_POLICY-1]) == NULL)\n\t\treturn -EINVAL;\n\n\tdir = xfrm_policy_id2dir(pol->sadb_x_policy_id);\n\tif (dir >= XFRM_POLICY_MAX)\n\t\treturn -EINVAL;\n\n\tdelete = (hdr->sadb_msg_type == SADB_X_SPDDELETE2);\n\txp = xfrm_policy_byid(net, &dummy_mark, 0, XFRM_POLICY_TYPE_MAIN,\n\t\t\t      dir, pol->sadb_x_policy_id, delete, &err);\n\tif (xp == NULL)\n\t\treturn -ENOENT;\n\n\tif (delete) {\n\t\txfrm_audit_policy_delete(xp, err ? 0 : 1, true);\n\n\t\tif (err)\n\t\t\tgoto out;\n\t\tc.seq = hdr->sadb_msg_seq;\n\t\tc.portid = hdr->sadb_msg_pid;\n\t\tc.data.byid = 1;\n\t\tc.event = XFRM_MSG_DELPOLICY;\n\t\tkm_policy_notify(xp, dir, &c);\n\t} else {\n\t\terr = key_pol_get_resp(sk, xp, hdr, dir);\n\t}\n\nout:\n\txfrm_pol_put(xp);\n\treturn err;\n}"
            ]
        ],
        "explanation": "Explanation: The propagation path in question involves the variable `delete` at line 23 in function `pfkey_spdget`. The path is labeled as a sink for UAF (Use-After-Free) bug. To evaluate reachability, we must trace the flow of `delete` and check for conflicting conditions or early exits.\n\nIn the code, `delete` is assigned at line 17: `delete = (hdr->sadb_msg_type == SADB_X_SPDDELETE2);`. This is a boolean value based on the message type. At line 23, there is a branch condition `if (delete)`, which leads to two blocks: one for deletion (lines 24-32) and one for non-deletion (line 34). The sink is at the branch condition itself (line 23), implying that the UAF concern might relate to how `delete` controls subsequent operations involving `xp`.\n\nCrucially, `xp` is obtained from `xfrm_policy_byid` at lines 18-19. If `xp` is NULL (line 20), the function returns early at line 21, preventing execution of the branch at line 23. Thus, for the branch at line 23 to be reached, `xp` must not be NULL. Additionally, the value of `delete` does not inherently cause a UAF on its own; it is a control variable. The UAF risk would involve the usage of `xp` after potential free operations, but the code shows that `xp` is managed with `xfrm_pol_put(xp)` at line 38 in the `out` label, which is called regardless of the branch taken. There is no explicit free or release of `xp` within the function other than this put, which suggests reference counting. The branch for `delete` (true case) performs notifications but does not free `xp` immediately; the put happens later. Therefore, the value of `delete` alone does not lead to a use-after-free in this path, as the sink is merely the condition check, and the actual usage of `xp` is protected by the reference put. Moreover, there are no conflicting conditions on `delete` that would make the path unreachable\u2014it is simply a boolean derived from the message type. However, since the sink is at the branch condition and not an actual use of a freed object, and given that the early return for NULL `xp` would avoid the branch entirely, the path is reachable for the condition check but does not inherently cause UAF without further context on how `xp` is handled externally. But based solely on the provided code and the guidelines, the propagation path to the sink at line 23 is reachable as there are no conflicting conditions or early returns that prevent it, though it may not directly result in UAF.\nAnswer: Yes",
        "is_human_confirmed_true": "False",
        "reason": "the sink rule mismatched this code point. And the LLM mess up program points and source/sink points"
    },
    "0": {
        "bug_type": "UAF",
        "buggy_value": "((delete)\n\t\txfrm_policy_kill(ret), /data/jiangjiajun/LLM4Security/data/projects/linux/net/xfrm/xfrm_policy.c, 1712, -1), ValueLabel.SRC)",
        "relevant_functions": [
            [
                "/data/jiangjiajun/LLM4Security/data/projects/linux/net/xfrm/xfrm_policy.c"
            ],
            [
                "xfrm_policy_bysel_ctx"
            ],
            [
                "struct xfrm_policy *\nxfrm_policy_bysel_ctx(struct net *net, const struct xfrm_mark *mark, u32 if_id,\n\t\t      u8 type, int dir, struct xfrm_selector *sel,\n\t\t      struct xfrm_sec_ctx *ctx, int delete, int *err)\n{\n\tstruct xfrm_pol_inexact_bin *bin = NULL;\n\tstruct xfrm_policy *pol, *ret = NULL;\n\tstruct hlist_head *chain;\n\n\t*err = 0;\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\tchain = policy_hash_bysel(net, sel, sel->family, dir);\n\tif (!chain) {\n\t\tstruct xfrm_pol_inexact_candidates cand;\n\t\tint i;\n\n\t\tbin = xfrm_policy_inexact_lookup(net, type,\n\t\t\t\t\t\t sel->family, dir, if_id);\n\t\tif (!bin) {\n\t\t\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (!xfrm_policy_find_inexact_candidates(&cand, bin,\n\t\t\t\t\t\t\t &sel->saddr,\n\t\t\t\t\t\t\t &sel->daddr)) {\n\t\t\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tpol = NULL;\n\t\tfor (i = 0; i < ARRAY_SIZE(cand.res); i++) {\n\t\t\tstruct xfrm_policy *tmp;\n\n\t\t\ttmp = __xfrm_policy_bysel_ctx(cand.res[i], mark,\n\t\t\t\t\t\t      if_id, type, dir,\n\t\t\t\t\t\t      sel, ctx);\n\t\t\tif (!tmp)\n\t\t\t\tcontinue;\n\n\t\t\tif (!pol || tmp->pos < pol->pos)\n\t\t\t\tpol = tmp;\n\t\t}\n\t} else {\n\t\tpol = __xfrm_policy_bysel_ctx(chain, mark, if_id, type, dir,\n\t\t\t\t\t      sel, ctx);\n\t}\n\n\tif (pol) {\n\t\txfrm_pol_hold(pol);\n\t\tif (delete) {\n\t\t\t*err = security_xfrm_policy_delete(pol->security);\n\t\t\tif (*err) {\n\t\t\t\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\t\t\t\treturn pol;\n\t\t\t}\n\t\t\t__xfrm_policy_unlink(pol, dir);\n\t\t}\n\t\tret = pol;\n\t}\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\n\tif (ret && delete)\n\t\txfrm_policy_kill(ret);\n\tif (bin && delete)\n\t\txfrm_policy_inexact_prune_bin(bin);\n\treturn ret;\n}\nEXPORT_SYMBOL(xfrm_policy_bysel_ctx);\n\nstruct xfrm_policy *\nxfrm_policy_byid(struct net *net, const struct xfrm_mark *mark, u32 if_id,\n\t\t u8 type, int dir, u32 id, int delete, int *err)\n{\n\tstruct xfrm_policy *pol, *ret;\n\tstruct hlist_head *chain;\n\n\t*err = -ENOENT;\n\tif (xfrm_policy_id2dir(id) != dir)\n\t\treturn NULL;\n\n\t*err = 0;\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\tchain = net->xfrm.policy_byidx + idx_hash(net, id);\n\tret = NULL;\n\thlist_for_each_entry(pol, chain, byidx) {\n\t\tif (pol->type == type && pol->index == id &&\n\t\t    pol->if_id == if_id && xfrm_policy_mark_match(mark, pol)) {\n\t\t\txfrm_pol_hold(pol);\n\t\t\tif (delete) {\n\t\t\t\t*err = security_xfrm_policy_delete(\n\t\t\t\t\t\t\t\tpol->security);\n\t\t\t\tif (*err) {\n\t\t\t\t\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\t\t\t\t\treturn pol;\n\t\t\t\t}\n\t\t\t\t__xfrm_policy_unlink(pol, dir);\n\t\t\t}\n\t\t\tret = pol;\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\n\tif (ret && delete)\n\t\txfrm_policy_kill(ret);\n\treturn ret;\n}\nEXPORT_SYMBOL(xfrm_policy_byid);\n\n#ifdef CONFIG_SECURITY_NETWORK_XFRM\nstatic inline int\nxfrm_policy_flush_secctx_check(struct net *net, u8 type, bool task_valid)\n{\n\tstruct xfrm_policy *pol;\n\tint err = 0;\n\n\tlist_for_each_entry(pol, &net->xfrm.policy_all, walk.all) {\n\t\tif (pol->walk.dead ||\n\t\t    xfrm_policy_id2dir(pol->index) >= XFRM_POLICY_MAX ||\n\t\t    pol->type != type)\n\t\t\tcontinue;\n\n\t\terr = security_xfrm_policy_delete(pol->security);\n\t\tif (err) {\n\t\t\txfrm_audit_policy_delete(pol, 0, task_valid);\n\t\t\treturn err;\n\t\t}\n\t}\n\treturn err;\n}\n\nstatic inline int xfrm_dev_policy_flush_secctx_check(struct net *net,\n\t\t\t\t\t\t     struct net_device *dev,\n\t\t\t\t\t\t     bool task_valid)\n{\n\tstruct xfrm_policy *pol;\n\tint err = 0;\n\n\tlist_for_each_entry(pol, &net->xfrm.policy_all, walk.all) {\n\t\tif (pol->walk.dead ||\n\t\t    xfrm_policy_id2dir(pol->index) >= XFRM_POLICY_MAX ||\n\t\t    pol->xdo.dev != dev)\n\t\t\tcontinue;\n\n\t\terr = security_xfrm_policy_delete(pol->security);\n\t\tif (err) {\n\t\t\txfrm_audit_policy_delete(pol, 0, task_valid);\n\t\t\treturn err;\n\t\t}\n\t}\n\treturn err;\n}\n#else\nstatic inline int\nxfrm_policy_flush_secctx_check(struct net *net, u8 type, bool task_valid)\n{\n\treturn 0;\n}\n\nstatic inline int xfrm_dev_policy_flush_secctx_check(struct net *net,\n\t\t\t\t\t\t     struct net_device *dev,\n\t\t\t\t\t\t     bool task_valid)\n{\n\treturn 0;\n}\n#endif\n\nint xfrm_policy_flush(struct net *net, u8 type, bool task_valid)\n{\n\tint dir, err = 0, cnt = 0;\n\tstruct xfrm_policy *pol;\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\n\terr = xfrm_policy_flush_secctx_check(net, type, task_valid);\n\tif (err)\n\t\tgoto out;\n\nagain:\n\tlist_for_each_entry(pol, &net->xfrm.policy_all, walk.all) {\n\t\tif (pol->walk.dead)\n\t\t\tcontinue;\n\n\t\tdir = xfrm_policy_id2dir(pol->index);\n\t\tif (dir >= XFRM_POLICY_MAX ||\n\t\t    pol->type != type)\n\t\t\tcontinue;\n\n\t\t__xfrm_policy_unlink(pol, dir);\n\t\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\t\tcnt++;\n\t\txfrm_audit_policy_delete(pol, 1, task_valid);\n\t\txfrm_policy_kill(pol);\n\t\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\t\tgoto again;\n\t}\n\tif (cnt)\n\t\t__xfrm_policy_inexact_flush(net);\n\telse\n\t\terr = -ESRCH;\nout:\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\treturn err;\n}\nEXPORT_SYMBOL(xfrm_policy_flush);\n\nint xfrm_dev_policy_flush(struct net *net, struct net_device *dev,\n\t\t\t  bool task_valid)\n{\n\tint dir, err = 0, cnt = 0;\n\tstruct xfrm_policy *pol;\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\n\terr = xfrm_dev_policy_flush_secctx_check(net, dev, task_valid);\n\tif (err)\n\t\tgoto out;\n\nagain:\n\tlist_for_each_entry(pol, &net->xfrm.policy_all, walk.all) {\n\t\tif (pol->walk.dead)\n\t\t\tcontinue;\n\n\t\tdir = xfrm_policy_id2dir(pol->index);\n\t\tif (dir >= XFRM_POLICY_MAX ||\n\t\t    pol->xdo.dev != dev)\n\t\t\tcontinue;\n\n\t\t__xfrm_policy_unlink(pol, dir);\n\t\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\t\tcnt++;\n\t\txfrm_audit_policy_delete(pol, 1, task_valid);\n\t\txfrm_policy_kill(pol);\n\t\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\t\tgoto again;\n\t}\n\tif (cnt)\n\t\t__xfrm_policy_inexact_flush(net);\n\telse\n\t\terr = -ESRCH;\nout:\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\treturn err;\n}\nEXPORT_SYMBOL(xfrm_dev_policy_flush);\n\nint xfrm_policy_walk(struct net *net, struct xfrm_policy_walk *walk,\n\t\t     int (*func)(struct xfrm_policy *, int, int, void*),\n\t\t     void *data)\n{\n\tstruct xfrm_policy *pol;\n\tstruct xfrm_policy_walk_entry *x;\n\tint error = 0;\n\n\tif (walk->type >= XFRM_POLICY_TYPE_MAX &&\n\t    walk->type != XFRM_POLICY_TYPE_ANY)\n\t\treturn -EINVAL;\n\n\tif (list_empty(&walk->walk.all) && walk->seq != 0)\n\t\treturn 0;\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\tif (list_empty(&walk->walk.all))\n\t\tx = list_first_entry(&net->xfrm.policy_all, struct xfrm_policy_walk_entry, all);\n\telse\n\t\tx = list_first_entry(&walk->walk.all,\n\t\t\t\t     struct xfrm_policy_walk_entry, all);\n\n\tlist_for_each_entry_from(x, &net->xfrm.policy_all, all) {\n\t\tif (x->dead)\n\t\t\tcontinue;\n\t\tpol = container_of(x, struct xfrm_policy, walk);\n\t\tif (walk->type != XFRM_POLICY_TYPE_ANY &&\n\t\t    walk->type != pol->type)\n\t\t\tcontinue;\n\t\terror = func(pol, xfrm_policy_id2dir(pol->index),\n\t\t\t     walk->seq, data);\n\t\tif (error) {\n\t\t\tlist_move_tail(&walk->walk.all, &x->all);\n\t\t\tgoto out;\n\t\t}\n\t\twalk->seq++;\n\t}\n\tif (walk->seq == 0) {\n\t\terror = -ENOENT;\n\t\tgoto out;\n\t}\n\tlist_del_init(&walk->walk.all);\nout:\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\treturn error;\n}\nEXPORT_SYMBOL(xfrm_policy_walk);\n\nvoid xfrm_policy_walk_init(struct xfrm_policy_walk *walk, u8 type)\n{\n\tINIT_LIST_HEAD(&walk->walk.all);\n\twalk->walk.dead = 1;\n\twalk->type = type;\n\twalk->seq = 0;\n}\nEXPORT_SYMBOL(xfrm_policy_walk_init);\n\nvoid xfrm_policy_walk_done(struct xfrm_policy_walk *walk, struct net *net)\n{\n\tif (list_empty(&walk->walk.all))\n\t\treturn;\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock); /*FIXME where is net? */\n\tlist_del(&walk->walk.all);\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n}\nEXPORT_SYMBOL(xfrm_policy_walk_done);\n\n/*\n * Find policy to apply to this flow.\n *\n * Returns 0 if policy found, else an -errno.\n */\nstatic int xfrm_policy_match(const struct xfrm_policy *pol,\n\t\t\t     const struct flowi *fl,\n\t\t\t     u8 type, u16 family, u32 if_id)\n{\n\tconst struct xfrm_selector *sel = &pol->selector;\n\tint ret = -ESRCH;\n\tbool match;\n\n\tif (pol->family != family ||\n\t    pol->if_id != if_id ||\n\t    (fl->flowi_mark & pol->mark.m) != pol->mark.v ||\n\t    pol->type != type)\n\t\treturn ret;\n\n\tmatch = xfrm_selector_match(sel, fl, family);\n\tif (match)\n\t\tret = security_xfrm_policy_lookup(pol->security, fl->flowi_secid);\n\treturn ret;\n}\n\nstatic struct xfrm_pol_inexact_node *\nxfrm_policy_lookup_inexact_addr(const struct rb_root *r,\n\t\t\t\tseqcount_spinlock_t *count,\n\t\t\t\tconst xfrm_address_t *addr, u16 family)\n{\n\tconst struct rb_node *parent;\n\tint seq;\n\nagain:\n\tseq = read_seqcount_begin(count);\n\n\tparent = rcu_dereference_raw(r->rb_node);\n\twhile (parent) {\n\t\tstruct xfrm_pol_inexact_node *node;\n\t\tint delta;\n\n\t\tnode = rb_entry(parent, struct xfrm_pol_inexact_node, node);\n\n\t\tdelta = xfrm_policy_addr_delta(addr, &node->addr,\n\t\t\t\t\t       node->prefixlen, family);\n\t\tif (delta < 0) {\n\t\t\tparent = rcu_dereference_raw(parent->rb_left);\n\t\t\tcontinue;\n\t\t} else if (delta > 0) {\n\t\t\tparent = rcu_dereference_raw(parent->rb_right);\n\t\t\tcontinue;\n\t\t}\n\n\t\treturn node;\n\t}\n\n\tif (read_seqcount_retry(count, seq))\n\t\tgoto again;\n\n\treturn NULL;\n}\n\nstatic bool\nxfrm_policy_find_inexact_candidates(struct xfrm_pol_inexact_candidates *cand,\n\t\t\t\t    struct xfrm_pol_inexact_bin *b,\n\t\t\t\t    const xfrm_address_t *saddr,\n\t\t\t\t    const xfrm_address_t *daddr)\n{\n\tstruct xfrm_pol_inexact_node *n;\n\tu16 family;\n\n\tif (!b)\n\t\treturn false;\n\n\tfamily = b->k.family;\n\tmemset(cand, 0, sizeof(*cand));\n\tcand->res[XFRM_POL_CAND_ANY] = &b->hhead;\n\n\tn = xfrm_policy_lookup_inexact_addr(&b->root_d, &b->count, daddr,\n\t\t\t\t\t    family);\n\tif (n) {\n\t\tcand->res[XFRM_POL_CAND_DADDR] = &n->hhead;\n\t\tn = xfrm_policy_lookup_inexact_addr(&n->root, &b->count, saddr,\n\t\t\t\t\t\t    family);\n\t\tif (n)\n\t\t\tcand->res[XFRM_POL_CAND_BOTH] = &n->hhead;\n\t}\n\n\tn = xfrm_policy_lookup_inexact_addr(&b->root_s, &b->count, saddr,\n\t\t\t\t\t    family);\n\tif (n)\n\t\tcand->res[XFRM_POL_CAND_SADDR] = &n->hhead;\n\n\treturn true;\n}\n\nstatic struct xfrm_pol_inexact_bin *\nxfrm_policy_inexact_lookup_rcu(struct net *net, u8 type, u16 family,\n\t\t\t       u8 dir, u32 if_id)\n{\n\tstruct xfrm_pol_inexact_key k = {\n\t\t.family = family,\n\t\t.type = type,\n\t\t.dir = dir,\n\t\t.if_id = if_id,\n\t};\n\n\twrite_pnet(&k.net, net);\n\n\treturn rhashtable_lookup(&xfrm_policy_inexact_table, &k,\n\t\t\t\t xfrm_pol_inexact_params);\n}\n\nstatic struct xfrm_pol_inexact_bin *\nxfrm_policy_inexact_lookup(struct net *net, u8 type, u16 family,\n\t\t\t   u8 dir, u32 if_id)\n{\n\tstruct xfrm_pol_inexact_bin *bin;\n\n\tlockdep_assert_held(&net->xfrm.xfrm_policy_lock);\n\n\trcu_read_lock();\n\tbin = xfrm_policy_inexact_lookup_rcu(net, type, family, dir, if_id);\n\trcu_read_unlock();\n\n\treturn bin;\n}\n\nstatic struct xfrm_policy *\n__xfrm_policy_eval_candidates(struct hlist_head *chain,\n\t\t\t      struct xfrm_policy *prefer,\n\t\t\t      const struct flowi *fl,\n\t\t\t      u8 type, u16 family, u32 if_id)\n{\n\tu32 priority = prefer ? prefer->priority : ~0u;\n\tstruct xfrm_policy *pol;\n\n\tif (!chain)\n\t\treturn NULL;\n\n\thlist_for_each_entry_rcu(pol, chain, bydst) {\n\t\tint err;\n\n\t\tif (pol->priority > priority)\n\t\t\tbreak;\n\n\t\terr = xfrm_policy_match(pol, fl, type, family, if_id);\n\t\tif (err) {\n\t\t\tif (err != -ESRCH)\n\t\t\t\treturn ERR_PTR(err);\n\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (prefer) {\n\t\t\t/* matches.  Is it older than *prefer? */\n\t\t\tif (pol->priority == priority &&\n\t\t\t    prefer->pos < pol->pos)\n\t\t\t\treturn prefer;\n\t\t}\n\n\t\treturn pol;\n\t}\n\n\treturn NULL;\n}\n\nstatic struct xfrm_policy *\nxfrm_policy_eval_candidates(struct xfrm_pol_inexact_candidates *cand,\n\t\t\t    struct xfrm_policy *prefer,\n\t\t\t    const struct flowi *fl,\n\t\t\t    u8 type, u16 family, u32 if_id)\n{\n\tstruct xfrm_policy *tmp;\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(cand->res); i++) {\n\t\ttmp = __xfrm_policy_eval_candidates(cand->res[i],\n\t\t\t\t\t\t    prefer,\n\t\t\t\t\t\t    fl, type, family, if_id);\n\t\tif (!tmp)\n\t\t\tcontinue;\n\n\t\tif (IS_ERR(tmp))\n\t\t\treturn tmp;\n\t\tprefer = tmp;\n\t}\n\n\treturn prefer;\n}\n\nstatic struct xfrm_policy *xfrm_policy_lookup_bytype(struct net *net, u8 type,\n\t\t\t\t\t\t     const struct flowi *fl,\n\t\t\t\t\t\t     u16 family, u8 dir,\n\t\t\t\t\t\t     u32 if_id)\n{\n\tstruct xfrm_pol_inexact_candidates cand;\n\tconst xfrm_address_t *daddr, *saddr;\n\tstruct xfrm_pol_inexact_bin *bin;\n\tstruct xfrm_policy *pol, *ret;\n\tstruct hlist_head *chain;\n\tunsigned int sequence;\n\tint err;\n\n\tdaddr = xfrm_flowi_daddr(fl, family);\n\tsaddr = xfrm_flowi_saddr(fl, family);\n\tif (unlikely(!daddr || !saddr))\n\t\treturn NULL;\n\n\trcu_read_lock();\n retry:\n\tdo {\n\t\tsequence = read_seqcount_begin(&net->xfrm.xfrm_policy_hash_generation);\n\t\tchain = policy_hash_direct(net, daddr, saddr, family, dir);\n\t} while (read_seqcount_retry(&net->xfrm.xfrm_policy_hash_generation, sequence));\n\n\tret = NULL;\n\thlist_for_each_entry_rcu(pol, chain, bydst) {\n\t\terr = xfrm_policy_match(pol, fl, type, family, if_id);\n\t\tif (err) {\n\t\t\tif (err == -ESRCH)\n\t\t\t\tcontinue;\n\t\t\telse {\n\t\t\t\tret = ERR_PTR(err);\n\t\t\t\tgoto fail;\n\t\t\t}\n\t\t} else {\n\t\t\tret = pol;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (ret && ret->xdo.type == XFRM_DEV_OFFLOAD_PACKET)\n\t\tgoto skip_inexact;\n\n\tbin = xfrm_policy_inexact_lookup_rcu(net, type, family, dir, if_id);\n\tif (!bin || !xfrm_policy_find_inexact_candidates(&cand, bin, saddr,\n\t\t\t\t\t\t\t daddr))\n\t\tgoto skip_inexact;\n\n\tpol = xfrm_policy_eval_candidates(&cand, ret, fl, type,\n\t\t\t\t\t  family, if_id);\n\tif (pol) {\n\t\tret = pol;\n\t\tif (IS_ERR(pol))\n\t\t\tgoto fail;\n\t}\n\nskip_inexact:\n\tif (read_seqcount_retry(&net->xfrm.xfrm_policy_hash_generation, sequence))\n\t\tgoto retry;\n\n\tif (ret && !xfrm_pol_hold_rcu(ret))\n\t\tgoto retry;\nfail:\n\trcu_read_unlock();\n\n\treturn ret;\n}\n\nstatic struct xfrm_policy *xfrm_policy_lookup(struct net *net,\n\t\t\t\t\t      const struct flowi *fl,\n\t\t\t\t\t      u16 family, u8 dir, u32 if_id)\n{\n#ifdef CONFIG_XFRM_SUB_POLICY\n\tstruct xfrm_policy *pol;\n\n\tpol = xfrm_policy_lookup_bytype(net, XFRM_POLICY_TYPE_SUB, fl, family,\n\t\t\t\t\tdir, if_id);\n\tif (pol != NULL)\n\t\treturn pol;\n#endif\n\treturn xfrm_policy_lookup_bytype(net, XFRM_POLICY_TYPE_MAIN, fl, family,\n\t\t\t\t\t dir, if_id);\n}\n\nstatic struct xfrm_policy *xfrm_sk_policy_lookup(const struct sock *sk, int dir,\n\t\t\t\t\t\t const struct flowi *fl,\n\t\t\t\t\t\t u16 family, u32 if_id)\n{\n\tstruct xfrm_policy *pol;\n\n\trcu_read_lock();\n again:\n\tpol = rcu_dereference(sk->sk_policy[dir]);\n\tif (pol != NULL) {\n\t\tbool match;\n\t\tint err = 0;\n\n\t\tif (pol->family != family) {\n\t\t\tpol = NULL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tmatch = xfrm_selector_match(&pol->selector, fl, family);\n\t\tif (match) {\n\t\t\tif ((READ_ONCE(sk->sk_mark) & pol->mark.m) != pol->mark.v ||\n\t\t\t    pol->if_id != if_id) {\n\t\t\t\tpol = NULL;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\terr = security_xfrm_policy_lookup(pol->security,\n\t\t\t\t\t\t      fl->flowi_secid);\n\t\t\tif (!err) {\n\t\t\t\tif (!xfrm_pol_hold_rcu(pol))\n\t\t\t\t\tgoto again;\n\t\t\t} else if (err == -ESRCH) {\n\t\t\t\tpol = NULL;\n\t\t\t} else {\n\t\t\t\tpol = ERR_PTR(err);\n\t\t\t}\n\t\t} else\n\t\t\tpol = NULL;\n\t}\nout:\n\trcu_read_unlock();\n\treturn pol;\n}\n\nstatic u32 xfrm_gen_pos_slow(struct net *net)\n{\n\tstruct xfrm_policy *policy;\n\tu32 i = 0;\n\n\t/* oldest entry is last in list */\n\tlist_for_each_entry_reverse(policy, &net->xfrm.policy_all, walk.all) {\n\t\tif (!xfrm_policy_is_dead_or_sk(policy))\n\t\t\tpolicy->pos = ++i;\n\t}\n\n\treturn i;\n}\n\nstatic u32 xfrm_gen_pos(struct net *net)\n{\n\tconst struct xfrm_policy *policy;\n\tu32 i = 0;\n\n\t/* most recently added policy is at the head of the list */\n\tlist_for_each_entry(policy, &net->xfrm.policy_all, walk.all) {\n\t\tif (xfrm_policy_is_dead_or_sk(policy))\n\t\t\tcontinue;\n\n\t\tif (policy->pos == UINT_MAX)\n\t\t\treturn xfrm_gen_pos_slow(net);\n\n\t\ti = policy->pos + 1;\n\t\tbreak;\n\t}\n\n\treturn i;\n}\n\nstatic void __xfrm_policy_link(struct xfrm_policy *pol, int dir)\n{\n\tstruct net *net = xp_net(pol);\n\n\tswitch (dir) {\n\tcase XFRM_POLICY_IN:\n\tcase XFRM_POLICY_FWD:\n\tcase XFRM_POLICY_OUT:\n\t\tpol->pos = xfrm_gen_pos(net);\n\t\tbreak;\n\t}\n\n\tlist_add(&pol->walk.all, &net->xfrm.policy_all);\n\tnet->xfrm.policy_count[dir]++;\n\txfrm_pol_hold(pol);\n}\n\nstatic struct xfrm_policy *__xfrm_policy_unlink(struct xfrm_policy *pol,\n\t\t\t\t\t\tint dir)\n{\n\tstruct net *net = xp_net(pol);\n\n\tif (list_empty(&pol->walk.all))\n\t\treturn NULL;\n\n\t/* Socket policies are not hashed. */\n\tif (!hlist_unhashed(&pol->bydst)) {\n\t\thlist_del_rcu(&pol->bydst);\n\t\thlist_del(&pol->byidx);\n\t}\n\n\tlist_del_init(&pol->walk.all);\n\tnet->xfrm.policy_count[dir]--;\n\n\treturn pol;\n}\n\nstatic void xfrm_sk_policy_link(struct xfrm_policy *pol, int dir)\n{\n\t__xfrm_policy_link(pol, XFRM_POLICY_MAX + dir);\n}\n\nstatic void xfrm_sk_policy_unlink(struct xfrm_policy *pol, int dir)\n{\n\t__xfrm_policy_unlink(pol, XFRM_POLICY_MAX + dir);\n}\n\nint xfrm_policy_delete(struct xfrm_policy *pol, int dir)\n{\n\tstruct net *net = xp_net(pol);\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\tpol = __xfrm_policy_unlink(pol, dir);\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\tif (pol) {\n\t\txfrm_policy_kill(pol);\n\t\treturn 0;\n\t}\n\treturn -ENOENT;\n}\nEXPORT_SYMBOL(xfrm_policy_delete);\n\nint xfrm_sk_policy_insert(struct sock *sk, int dir, struct xfrm_policy *pol)\n{\n\tstruct net *net = sock_net(sk);\n\tstruct xfrm_policy *old_pol;\n\n#ifdef CONFIG_XFRM_SUB_POLICY\n\tif (pol && pol->type != XFRM_POLICY_TYPE_MAIN)\n\t\treturn -EINVAL;\n#endif\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\told_pol = rcu_dereference_protected(sk->sk_policy[dir],\n\t\t\t\tlockdep_is_held(&net->xfrm.xfrm_policy_lock));\n\tif (pol) {\n\t\tpol->curlft.add_time = ktime_get_real_seconds();\n\t\tpol->index = xfrm_gen_index(net, XFRM_POLICY_MAX+dir, 0);\n\t\txfrm_sk_policy_link(pol, dir);\n\t}\n\trcu_assign_pointer(sk->sk_policy[dir], pol);\n\tif (old_pol) {\n\t\tif (pol)\n\t\t\txfrm_policy_requeue(old_pol, pol);\n\n\t\t/* Unlinking succeeds always. This is the only function\n\t\t * allowed to delete or replace socket policy.\n\t\t */\n\t\txfrm_sk_policy_unlink(old_pol, dir);\n\t}\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\n\tif (old_pol) {\n\t\txfrm_policy_kill(old_pol);\n\t}\n\treturn 0;\n}\n\nstatic struct xfrm_policy *clone_policy(const struct xfrm_policy *old, int dir)\n{\n\tstruct xfrm_policy *newp = xfrm_policy_alloc(xp_net(old), GFP_ATOMIC);\n\tstruct net *net = xp_net(old);\n\n\tif (newp) {\n\t\tnewp->selector = old->selector;\n\t\tif (security_xfrm_policy_clone(old->security,\n\t\t\t\t\t       &newp->security)) {\n\t\t\tkfree(newp);\n\t\t\treturn NULL;  /* ENOMEM */\n\t\t}\n\t\tnewp->lft = old->lft;\n\t\tnewp->curlft = old->curlft;\n\t\tnewp->mark = old->mark;\n\t\tnewp->if_id = old->if_id;\n\t\tnewp->action = old->action;\n\t\tnewp->flags = old->flags;\n\t\tnewp->xfrm_nr = old->xfrm_nr;\n\t\tnewp->index = old->index;\n\t\tnewp->type = old->type;\n\t\tnewp->family = old->family;\n\t\tmemcpy(newp->xfrm_vec, old->xfrm_vec,\n\t\t       newp->xfrm_nr*sizeof(struct xfrm_tmpl));\n\t\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\t\txfrm_sk_policy_link(newp, dir);\n\t\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\t\txfrm_pol_put(newp);\n\t}\n\treturn newp;\n}\n\nint __xfrm_sk_clone_policy(struct sock *sk, const struct sock *osk)\n{\n\tconst struct xfrm_policy *p;\n\tstruct xfrm_policy *np;\n\tint i, ret = 0;\n\n\trcu_read_lock();\n\tfor (i = 0; i < 2; i++) {\n\t\tp = rcu_dereference(osk->sk_policy[i]);\n\t\tif (p) {\n\t\t\tnp = clone_policy(p, i);\n\t\t\tif (unlikely(!np)) {\n\t\t\t\tret = -ENOMEM;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\trcu_assign_pointer(sk->sk_policy[i], np);\n\t\t}\n\t}\n\trcu_read_unlock();\n\treturn ret;\n}\n\nstatic int\nxfrm_get_saddr(unsigned short family, xfrm_address_t *saddr,\n\t       const struct xfrm_dst_lookup_params *params)\n{\n\tint err;\n\tconst struct xfrm_policy_afinfo *afinfo = xfrm_policy_get_afinfo(family);\n\n\tif (unlikely(afinfo == NULL))\n\t\treturn -EINVAL;\n\terr = afinfo->get_saddr(saddr, params);\n\trcu_read_unlock();\n\treturn err;\n}\n\n/* Resolve list of templates for the flow, given policy. */\n\nstatic int\nxfrm_tmpl_resolve_one(struct xfrm_policy *policy, const struct flowi *fl,\n\t\t      struct xfrm_state **xfrm, unsigned short family)\n{\n\tstruct net *net = xp_net(policy);\n\tint nx;\n\tint i, error;\n\txfrm_address_t *daddr = xfrm_flowi_daddr(fl, family);\n\txfrm_address_t *saddr = xfrm_flowi_saddr(fl, family);\n\txfrm_address_t tmp;\n\n\tfor (nx = 0, i = 0; i < policy->xfrm_nr; i++) {\n\t\tstruct xfrm_state *x;\n\t\txfrm_address_t *remote = daddr;\n\t\txfrm_address_t *local  = saddr;\n\t\tstruct xfrm_tmpl *tmpl = &policy->xfrm_vec[i];\n\n\t\tif (tmpl->mode == XFRM_MODE_TUNNEL ||\n\t\t    tmpl->mode == XFRM_MODE_IPTFS ||\n\t\t    tmpl->mode == XFRM_MODE_BEET) {\n\t\t\tremote = &tmpl->id.daddr;\n\t\t\tlocal = &tmpl->saddr;\n\t\t\tif (xfrm_addr_any(local, tmpl->encap_family)) {\n\t\t\t\tstruct xfrm_dst_lookup_params params;\n\n\t\t\t\tmemset(&params, 0, sizeof(params));\n\t\t\t\tparams.net = net;\n\t\t\t\tparams.oif = fl->flowi_oif;\n\t\t\t\tparams.daddr = remote;\n\t\t\t\terror = xfrm_get_saddr(tmpl->encap_family, &tmp,\n\t\t\t\t\t\t       &params);\n\t\t\t\tif (error)\n\t\t\t\t\tgoto fail;\n\t\t\t\tlocal = &tmp;\n\t\t\t}\n\t\t}\n\n\t\tx = xfrm_state_find(remote, local, fl, tmpl, policy, &error,\n\t\t\t\t    family, policy->if_id);\n\t\tif (x && x->dir && x->dir != XFRM_SA_DIR_OUT) {\n\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMOUTSTATEDIRERROR);\n\t\t\txfrm_state_put(x);\n\t\t\terror = -EINVAL;\n\t\t\tgoto fail;\n\t\t}\n\n\t\tif (x && x->km.state == XFRM_STATE_VALID) {\n\t\t\txfrm[nx++] = x;\n\t\t\tdaddr = remote;\n\t\t\tsaddr = local;\n\t\t\tcontinue;\n\t\t}\n\t\tif (x) {\n\t\t\terror = (x->km.state == XFRM_STATE_ERROR ?\n\t\t\t\t -EINVAL : -EAGAIN);\n\t\t\txfrm_state_put(x);\n\t\t} else if (error == -ESRCH) {\n\t\t\terror = -EAGAIN;\n\t\t}\n\n\t\tif (!tmpl->optional)\n\t\t\tgoto fail;\n\t}\n\treturn nx;\n\nfail:\n\tfor (nx--; nx >= 0; nx--)\n\t\txfrm_state_put(xfrm[nx]);\n\treturn error;\n}\n\nstatic int\nxfrm_tmpl_resolve(struct xfrm_policy **pols, int npols, const struct flowi *fl,\n\t\t  struct xfrm_state **xfrm, unsigned short family)\n{\n\tstruct xfrm_state *tp[XFRM_MAX_DEPTH];\n\tstruct xfrm_state **tpp = (npols > 1) ? tp : xfrm;\n\tint cnx = 0;\n\tint error;\n\tint ret;\n\tint i;\n\n\tfor (i = 0; i < npols; i++) {\n\t\tif (cnx + pols[i]->xfrm_nr >= XFRM_MAX_DEPTH) {\n\t\t\terror = -ENOBUFS;\n\t\t\tgoto fail;\n\t\t}\n\n\t\tret = xfrm_tmpl_resolve_one(pols[i], fl, &tpp[cnx], family);\n\t\tif (ret < 0) {\n\t\t\terror = ret;\n\t\t\tgoto fail;\n\t\t} else\n\t\t\tcnx += ret;\n\t}\n\n\t/* found states are sorted for outbound processing */\n\tif (npols > 1)\n\t\txfrm_state_sort(xfrm, tpp, cnx, family);\n\n\treturn cnx;\n\n fail:\n\tfor (cnx--; cnx >= 0; cnx--)\n\t\txfrm_state_put(tpp[cnx]);\n\treturn error;\n\n}\n\nstatic dscp_t xfrm_get_dscp(const struct flowi *fl, int family)\n{\n\tif (family == AF_INET)\n\t\treturn fl->u.ip4.flowi4_dscp;\n\n\treturn 0;\n}\n\nstatic inline struct xfrm_dst *xfrm_alloc_dst(struct net *net, int family)\n{\n\tconst struct xfrm_policy_afinfo *afinfo = xfrm_policy_get_afinfo(family);\n\tstruct dst_ops *dst_ops;\n\tstruct xfrm_dst *xdst;\n\n\tif (!afinfo)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tswitch (family) {\n\tcase AF_INET:\n\t\tdst_ops = &net->xfrm.xfrm4_dst_ops;\n\t\tbreak;\n#if IS_ENABLED(CONFIG_IPV6)\n\tcase AF_INET6:\n\t\tdst_ops = &net->xfrm.xfrm6_dst_ops;\n\t\tbreak;\n#endif\n\tdefault:\n\t\tBUG();\n\t}\n\txdst = dst_alloc(dst_ops, NULL, DST_OBSOLETE_NONE, 0);\n\n\tif (likely(xdst)) {\n\t\tmemset_after(xdst, 0, u.dst);\n\t} else\n\t\txdst = ERR_PTR(-ENOBUFS);\n\n\trcu_read_unlock();\n\n\treturn xdst;\n}\n\nstatic void xfrm_init_path(struct xfrm_dst *path, struct dst_entry *dst,\n\t\t\t   int nfheader_len)\n{\n\tif (dst->ops->family == AF_INET6) {\n\t\tpath->path_cookie = rt6_get_cookie(dst_rt6_info(dst));\n\t\tpath->u.rt6.rt6i_nfheader_len = nfheader_len;\n\t}\n}\n\nstatic inline int xfrm_fill_dst(struct xfrm_dst *xdst, struct net_device *dev,\n\t\t\t\tconst struct flowi *fl)\n{\n\tconst struct xfrm_policy_afinfo *afinfo =\n\t\txfrm_policy_get_afinfo(xdst->u.dst.ops->family);\n\tint err;\n\n\tif (!afinfo)\n\t\treturn -EINVAL;\n\n\terr = afinfo->fill_dst(xdst, dev, fl);\n\n\trcu_read_unlock();\n\n\treturn err;\n}\n\n\n/* Allocate chain of dst_entry's, attach known xfrm's, calculate\n * all the metrics... Shortly, bundle a bundle.\n */\n\nstatic struct dst_entry *xfrm_bundle_create(struct xfrm_policy *policy,\n\t\t\t\t\t    struct xfrm_state **xfrm,\n\t\t\t\t\t    struct xfrm_dst **bundle,\n\t\t\t\t\t    int nx,\n\t\t\t\t\t    const struct flowi *fl,\n\t\t\t\t\t    struct dst_entry *dst)\n{\n\tconst struct xfrm_state_afinfo *afinfo;\n\tconst struct xfrm_mode *inner_mode;\n\tstruct net *net = xp_net(policy);\n\tunsigned long now = jiffies;\n\tstruct net_device *dev;\n\tstruct xfrm_dst *xdst_prev = NULL;\n\tstruct xfrm_dst *xdst0 = NULL;\n\tint i = 0;\n\tint err;\n\tint header_len = 0;\n\tint nfheader_len = 0;\n\tint trailer_len = 0;\n\tint family = policy->selector.family;\n\txfrm_address_t saddr, daddr;\n\tdscp_t dscp;\n\n\txfrm_flowi_addr_get(fl, &saddr, &daddr, family);\n\n\tdscp = xfrm_get_dscp(fl, family);\n\n\tdst_hold(dst);\n\n\tfor (; i < nx; i++) {\n\t\tstruct xfrm_dst *xdst = xfrm_alloc_dst(net, family);\n\t\tstruct dst_entry *dst1 = &xdst->u.dst;\n\n\t\terr = PTR_ERR(xdst);\n\t\tif (IS_ERR(xdst)) {\n\t\t\tdst_release(dst);\n\t\t\tgoto put_states;\n\t\t}\n\n\t\tbundle[i] = xdst;\n\t\tif (!xdst_prev)\n\t\t\txdst0 = xdst;\n\t\telse\n\t\t\t/* Ref count is taken during xfrm_alloc_dst()\n\t\t\t * No need to do dst_clone() on dst1\n\t\t\t */\n\t\t\txfrm_dst_set_child(xdst_prev, &xdst->u.dst);\n\n\t\tif (xfrm[i]->sel.family == AF_UNSPEC) {\n\t\t\tinner_mode = xfrm_ip2inner_mode(xfrm[i],\n\t\t\t\t\t\t\txfrm_af2proto(family));\n\t\t\tif (!inner_mode) {\n\t\t\t\terr = -EAFNOSUPPORT;\n\t\t\t\tdst_release(dst);\n\t\t\t\tgoto put_states;\n\t\t\t}\n\t\t} else\n\t\t\tinner_mode = &xfrm[i]->inner_mode;\n\n\t\txdst->route = dst;\n\t\tdst_copy_metrics(dst1, dst);\n\n\t\tif (xfrm[i]->props.mode != XFRM_MODE_TRANSPORT) {\n\t\t\t__u32 mark = 0;\n\t\t\tint oif;\n\n\t\t\tif (xfrm[i]->props.smark.v || xfrm[i]->props.smark.m)\n\t\t\t\tmark = xfrm_smark_get(fl->flowi_mark, xfrm[i]);\n\n\t\t\tif (xfrm[i]->xso.type != XFRM_DEV_OFFLOAD_PACKET)\n\t\t\t\tfamily = xfrm[i]->props.family;\n\n\t\t\toif = fl->flowi_oif ? : fl->flowi_l3mdev;\n\t\t\tdst = xfrm_dst_lookup(xfrm[i], dscp, oif, &saddr,\n\t\t\t\t\t      &daddr, family, mark);\n\t\t\terr = PTR_ERR(dst);\n\t\t\tif (IS_ERR(dst))\n\t\t\t\tgoto put_states;\n\t\t} else\n\t\t\tdst_hold(dst);\n\n\t\tdst1->xfrm = xfrm[i];\n\t\txdst->xfrm_genid = xfrm[i]->genid;\n\n\t\tdst1->obsolete = DST_OBSOLETE_FORCE_CHK;\n\t\tdst1->lastuse = now;\n\n\t\tdst1->input = dst_discard;\n\n\t\tif (xfrm[i]->mode_cbs && xfrm[i]->mode_cbs->output) {\n\t\t\tdst1->output = xfrm[i]->mode_cbs->output;\n\t\t} else {\n\t\t\trcu_read_lock();\n\t\t\tafinfo = xfrm_state_afinfo_get_rcu(inner_mode->family);\n\t\t\tif (likely(afinfo))\n\t\t\t\tdst1->output = afinfo->output;\n\t\t\telse\n\t\t\t\tdst1->output = dst_discard_out;\n\t\t\trcu_read_unlock();\n\t\t}\n\n\t\txdst_prev = xdst;\n\n\t\theader_len += xfrm[i]->props.header_len;\n\t\tif (xfrm[i]->type->flags & XFRM_TYPE_NON_FRAGMENT)\n\t\t\tnfheader_len += xfrm[i]->props.header_len;\n\t\ttrailer_len += xfrm[i]->props.trailer_len;\n\t}\n\n\txfrm_dst_set_child(xdst_prev, dst);\n\txdst0->path = dst;\n\n\terr = -ENODEV;\n\tdev = dst->dev;\n\tif (!dev)\n\t\tgoto free_dst;\n\n\txfrm_init_path(xdst0, dst, nfheader_len);\n\txfrm_init_pmtu(bundle, nx);\n\n\tfor (xdst_prev = xdst0; xdst_prev != (struct xfrm_dst *)dst;\n\t     xdst_prev = (struct xfrm_dst *) xfrm_dst_child(&xdst_prev->u.dst)) {\n\t\terr = xfrm_fill_dst(xdst_prev, dev, fl);\n\t\tif (err)\n\t\t\tgoto free_dst;\n\n\t\txdst_prev->u.dst.header_len = header_len;\n\t\txdst_prev->u.dst.trailer_len = trailer_len;\n\t\theader_len -= xdst_prev->u.dst.xfrm->props.header_len;\n\t\ttrailer_len -= xdst_prev->u.dst.xfrm->props.trailer_len;\n\t}\n\n\treturn &xdst0->u.dst;\n\nput_states:\n\tfor (; i < nx; i++)\n\t\txfrm_state_put(xfrm[i]);\nfree_dst:\n\tif (xdst0)\n\t\tdst_release_immediate(&xdst0->u.dst);\n\n\treturn ERR_PTR(err);\n}\n\nstatic int xfrm_expand_policies(const struct flowi *fl, u16 family,\n\t\t\t\tstruct xfrm_policy **pols,\n\t\t\t\tint *num_pols, int *num_xfrms)\n{\n\tint i;\n\n\tif (*num_pols == 0 || !pols[0]) {\n\t\t*num_pols = 0;\n\t\t*num_xfrms = 0;\n\t\treturn 0;\n\t}\n\tif (IS_ERR(pols[0])) {\n\t\t*num_pols = 0;\n\t\treturn PTR_ERR(pols[0]);\n\t}\n\n\t*num_xfrms = pols[0]->xfrm_nr;\n\n#ifdef CONFIG_XFRM_SUB_POLICY\n\tif (pols[0]->action == XFRM_POLICY_ALLOW &&\n\t    pols[0]->type != XFRM_POLICY_TYPE_MAIN) {\n\t\tpols[1] = xfrm_policy_lookup_bytype(xp_net(pols[0]),\n\t\t\t\t\t\t    XFRM_POLICY_TYPE_MAIN,\n\t\t\t\t\t\t    fl, family,\n\t\t\t\t\t\t    XFRM_POLICY_OUT,\n\t\t\t\t\t\t    pols[0]->if_id);\n\t\tif (pols[1]) {\n\t\t\tif (IS_ERR(pols[1])) {\n\t\t\t\txfrm_pols_put(pols, *num_pols);\n\t\t\t\t*num_pols = 0;\n\t\t\t\treturn PTR_ERR(pols[1]);\n\t\t\t}\n\t\t\t(*num_pols)++;\n\t\t\t(*num_xfrms) += pols[1]->xfrm_nr;\n\t\t}\n\t}\n#endif\n\tfor (i = 0; i < *num_pols; i++) {\n\t\tif (pols[i]->action != XFRM_POLICY_ALLOW) {\n\t\t\t*num_xfrms = -1;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn 0;\n\n}\n\nstatic struct xfrm_dst *\nxfrm_resolve_and_create_bundle(struct xfrm_policy **pols, int num_pols,\n\t\t\t       const struct flowi *fl, u16 family,\n\t\t\t       struct dst_entry *dst_orig)\n{\n\tstruct net *net = xp_net(pols[0]);\n\tstruct xfrm_state *xfrm[XFRM_MAX_DEPTH];\n\tstruct xfrm_dst *bundle[XFRM_MAX_DEPTH];\n\tstruct xfrm_dst *xdst;\n\tstruct dst_entry *dst;\n\tint err;\n\n\t/* Try to instantiate a bundle */\n\terr = xfrm_tmpl_resolve(pols, num_pols, fl, xfrm, family);\n\tif (err <= 0) {\n\t\tif (err == 0)\n\t\t\treturn NULL;\n\n\t\tif (err != -EAGAIN)\n\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMOUTPOLERROR);\n\t\treturn ERR_PTR(err);\n\t}\n\n\tdst = xfrm_bundle_create(pols[0], xfrm, bundle, err, fl, dst_orig);\n\tif (IS_ERR(dst)) {\n\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMOUTBUNDLEGENERROR);\n\t\treturn ERR_CAST(dst);\n\t}\n\n\txdst = (struct xfrm_dst *)dst;\n\txdst->num_xfrms = err;\n\txdst->num_pols = num_pols;\n\tmemcpy(xdst->pols, pols, sizeof(struct xfrm_policy *) * num_pols);\n\txdst->policy_genid = atomic_read(&pols[0]->genid);\n\n\treturn xdst;\n}\n\nstatic void xfrm_policy_queue_process(struct timer_list *t)\n{\n\tstruct sk_buff *skb;\n\tstruct sock *sk;\n\tstruct dst_entry *dst;\n\tstruct xfrm_policy *pol = timer_container_of(pol, t, polq.hold_timer);\n\tstruct net *net = xp_net(pol);\n\tstruct xfrm_policy_queue *pq = &pol->polq;\n\tstruct flowi fl;\n\tstruct sk_buff_head list;\n\t__u32 skb_mark;\n\n\tspin_lock(&pq->hold_queue.lock);\n\tskb = skb_peek(&pq->hold_queue);\n\tif (!skb) {\n\t\tspin_unlock(&pq->hold_queue.lock);\n\t\tgoto out;\n\t}\n\tdst = skb_dst(skb);\n\tsk = skb->sk;\n\n\t/* Fixup the mark to support VTI. */\n\tskb_mark = skb->mark;\n\tskb->mark = pol->mark.v;\n\txfrm_decode_session(net, skb, &fl, dst->ops->family);\n\tskb->mark = skb_mark;\n\tspin_unlock(&pq->hold_queue.lock);\n\n\tdst_hold(xfrm_dst_path(dst));\n\tdst = xfrm_lookup(net, xfrm_dst_path(dst), &fl, sk, XFRM_LOOKUP_QUEUE);\n\tif (IS_ERR(dst))\n\t\tgoto purge_queue;\n\n\tif (dst->flags & DST_XFRM_QUEUE) {\n\t\tdst_release(dst);\n\n\t\tif (pq->timeout >= XFRM_QUEUE_TMO_MAX)\n\t\t\tgoto purge_queue;\n\n\t\tpq->timeout = pq->timeout << 1;\n\t\tif (!mod_timer(&pq->hold_timer, jiffies + pq->timeout))\n\t\t\txfrm_pol_hold(pol);\n\t\tgoto out;\n\t}\n\n\tdst_release(dst);\n\n\t__skb_queue_head_init(&list);\n\n\tspin_lock(&pq->hold_queue.lock);\n\tpq->timeout = 0;\n\tskb_queue_splice_init(&pq->hold_queue, &list);\n\tspin_unlock(&pq->hold_queue.lock);\n\n\twhile (!skb_queue_empty(&list)) {\n\t\tskb = __skb_dequeue(&list);\n\n\t\t/* Fixup the mark to support VTI. */\n\t\tskb_mark = skb->mark;\n\t\tskb->mark = pol->mark.v;\n\t\txfrm_decode_session(net, skb, &fl, skb_dst(skb)->ops->family);\n\t\tskb->mark = skb_mark;\n\n\t\tdst_hold(xfrm_dst_path(skb_dst(skb)));\n\t\tdst = xfrm_lookup(net, xfrm_dst_path(skb_dst(skb)), &fl, skb->sk, 0);\n\t\tif (IS_ERR(dst)) {\n\t\t\tkfree_skb(skb);\n\t\t\tcontinue;\n\t\t}\n\n\t\tnf_reset_ct(skb);\n\t\tskb_dst_drop(skb);\n\t\tskb_dst_set(skb, dst);\n\n\t\tdst_output(net, skb_to_full_sk(skb), skb);\n\t}\n\nout:\n\txfrm_pol_put(pol);\n\treturn;\n\npurge_queue:\n\tpq->timeout = 0;\n\tskb_queue_purge(&pq->hold_queue);\n\txfrm_pol_put(pol);\n}\n\nstatic int xdst_queue_output(struct net *net, struct sock *sk, struct sk_buff *skb)\n{\n\tunsigned long sched_next;\n\tstruct dst_entry *dst = skb_dst(skb);\n\tstruct xfrm_dst *xdst = (struct xfrm_dst *) dst;\n\tstruct xfrm_policy *pol = xdst->pols[0];\n\tstruct xfrm_policy_queue *pq = &pol->polq;\n\n\tif (unlikely(skb_fclone_busy(sk, skb))) {\n\t\tkfree_skb(skb);\n\t\treturn 0;\n\t}\n\n\tif (pq->hold_queue.qlen > XFRM_MAX_QUEUE_LEN) {\n\t\tkfree_skb(skb);\n\t\treturn -EAGAIN;\n\t}\n\n\tskb_dst_force(skb);\n\n\tspin_lock_bh(&pq->hold_queue.lock);\n\n\tif (!pq->timeout)\n\t\tpq->timeout = XFRM_QUEUE_TMO_MIN;\n\n\tsched_next = jiffies + pq->timeout;\n\n\tif (timer_delete(&pq->hold_timer)) {\n\t\tif (time_before(pq->hold_timer.expires, sched_next))\n\t\t\tsched_next = pq->hold_timer.expires;\n\t\txfrm_pol_put(pol);\n\t}\n\n\t__skb_queue_tail(&pq->hold_queue, skb);\n\tif (!mod_timer(&pq->hold_timer, sched_next))\n\t\txfrm_pol_hold(pol);\n\n\tspin_unlock_bh(&pq->hold_queue.lock);\n\n\treturn 0;\n}\n\nstatic struct xfrm_dst *xfrm_create_dummy_bundle(struct net *net,\n\t\t\t\t\t\t struct xfrm_flo *xflo,\n\t\t\t\t\t\t const struct flowi *fl,\n\t\t\t\t\t\t int num_xfrms,\n\t\t\t\t\t\t u16 family)\n{\n\tint err;\n\tstruct net_device *dev;\n\tstruct dst_entry *dst;\n\tstruct dst_entry *dst1;\n\tstruct xfrm_dst *xdst;\n\n\txdst = xfrm_alloc_dst(net, family);\n\tif (IS_ERR(xdst))\n\t\treturn xdst;\n\n\tif (!(xflo->flags & XFRM_LOOKUP_QUEUE) ||\n\t    net->xfrm.sysctl_larval_drop ||\n\t    num_xfrms <= 0)\n\t\treturn xdst;\n\n\tdst = xflo->dst_orig;\n\tdst1 = &xdst->u.dst;\n\tdst_hold(dst);\n\txdst->route = dst;\n\n\tdst_copy_metrics(dst1, dst);\n\n\tdst1->obsolete = DST_OBSOLETE_FORCE_CHK;\n\tdst1->flags |= DST_XFRM_QUEUE;\n\tdst1->lastuse = jiffies;\n\n\tdst1->input = dst_discard;\n\tdst1->output = xdst_queue_output;\n\n\tdst_hold(dst);\n\txfrm_dst_set_child(xdst, dst);\n\txdst->path = dst;\n\n\txfrm_init_path((struct xfrm_dst *)dst1, dst, 0);\n\n\terr = -ENODEV;\n\tdev = dst->dev;\n\tif (!dev)\n\t\tgoto free_dst;\n\n\terr = xfrm_fill_dst(xdst, dev, fl);\n\tif (err)\n\t\tgoto free_dst;\n\nout:\n\treturn xdst;\n\nfree_dst:\n\tdst_release(dst1);\n\txdst = ERR_PTR(err);\n\tgoto out;\n}\n\nstatic struct xfrm_dst *xfrm_bundle_lookup(struct net *net,\n\t\t\t\t\t   const struct flowi *fl,\n\t\t\t\t\t   u16 family, u8 dir,\n\t\t\t\t\t   struct xfrm_flo *xflo, u32 if_id)\n{\n\tstruct xfrm_policy *pols[XFRM_POLICY_TYPE_MAX];\n\tint num_pols = 0, num_xfrms = 0, err;\n\tstruct xfrm_dst *xdst;\n\n\t/* Resolve policies to use if we couldn't get them from\n\t * previous cache entry */\n\tnum_pols = 1;\n\tpols[0] = xfrm_policy_lookup(net, fl, family, dir, if_id);\n\terr = xfrm_expand_policies(fl, family, pols,\n\t\t\t\t\t   &num_pols, &num_xfrms);\n\tif (err < 0)\n\t\tgoto inc_error;\n\tif (num_pols == 0)\n\t\treturn NULL;\n\tif (num_xfrms <= 0)\n\t\tgoto make_dummy_bundle;\n\n\txdst = xfrm_resolve_and_create_bundle(pols, num_pols, fl, family,\n\t\t\t\t\t      xflo->dst_orig);\n\tif (IS_ERR(xdst)) {\n\t\terr = PTR_ERR(xdst);\n\t\tif (err == -EREMOTE) {\n\t\t\txfrm_pols_put(pols, num_pols);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (err != -EAGAIN)\n\t\t\tgoto error;\n\t\tgoto make_dummy_bundle;\n\t} else if (xdst == NULL) {\n\t\tnum_xfrms = 0;\n\t\tgoto make_dummy_bundle;\n\t}\n\n\treturn xdst;\n\nmake_dummy_bundle:\n\t/* We found policies, but there's no bundles to instantiate:\n\t * either because the policy blocks, has no transformations or\n\t * we could not build template (no xfrm_states).*/\n\txdst = xfrm_create_dummy_bundle(net, xflo, fl, num_xfrms, family);\n\tif (IS_ERR(xdst)) {\n\t\txfrm_pols_put(pols, num_pols);\n\t\treturn ERR_CAST(xdst);\n\t}\n\txdst->num_pols = num_pols;\n\txdst->num_xfrms = num_xfrms;\n\tmemcpy(xdst->pols, pols, sizeof(struct xfrm_policy *) * num_pols);\n\n\treturn xdst;\n\ninc_error:\n\tXFRM_INC_STATS(net, LINUX_MIB_XFRMOUTPOLERROR);\nerror:\n\txfrm_pols_put(pols, num_pols);\n\treturn ERR_PTR(err);\n}\n\nstatic struct dst_entry *make_blackhole(struct net *net, u16 family,\n\t\t\t\t\tstruct dst_entry *dst_orig)\n{\n\tconst struct xfrm_policy_afinfo *afinfo = xfrm_policy_get_afinfo(family);\n\tstruct dst_entry *ret;\n\n\tif (!afinfo) {\n\t\tdst_release(dst_orig);\n\t\treturn ERR_PTR(-EINVAL);\n\t} else {\n\t\tret = afinfo->blackhole_route(net, dst_orig);\n\t}\n\trcu_read_unlock();\n\n\treturn ret;\n}\n\n/* Finds/creates a bundle for given flow and if_id\n *\n * At the moment we eat a raw IP route. Mostly to speed up lookups\n * on interfaces with disabled IPsec.\n *\n * xfrm_lookup uses an if_id of 0 by default, and is provided for\n * compatibility\n */\nstruct dst_entry *xfrm_lookup_with_ifid(struct net *net,\n\t\t\t\t\tstruct dst_entry *dst_orig,\n\t\t\t\t\tconst struct flowi *fl,\n\t\t\t\t\tconst struct sock *sk,\n\t\t\t\t\tint flags, u32 if_id)\n{\n\tstruct xfrm_policy *pols[XFRM_POLICY_TYPE_MAX];\n\tstruct xfrm_dst *xdst;\n\tstruct dst_entry *dst, *route;\n\tu16 family = dst_orig->ops->family;\n\tu8 dir = XFRM_POLICY_OUT;\n\tint i, err, num_pols, num_xfrms = 0, drop_pols = 0;\n\n\tdst = NULL;\n\txdst = NULL;\n\troute = NULL;\n\n\tsk = sk_const_to_full_sk(sk);\n\tif (sk && sk->sk_policy[XFRM_POLICY_OUT]) {\n\t\tnum_pols = 1;\n\t\tpols[0] = xfrm_sk_policy_lookup(sk, XFRM_POLICY_OUT, fl, family,\n\t\t\t\t\t\tif_id);\n\t\terr = xfrm_expand_policies(fl, family, pols,\n\t\t\t\t\t   &num_pols, &num_xfrms);\n\t\tif (err < 0)\n\t\t\tgoto dropdst;\n\n\t\tif (num_pols) {\n\t\t\tif (num_xfrms <= 0) {\n\t\t\t\tdrop_pols = num_pols;\n\t\t\t\tgoto no_transform;\n\t\t\t}\n\n\t\t\txdst = xfrm_resolve_and_create_bundle(\n\t\t\t\t\tpols, num_pols, fl,\n\t\t\t\t\tfamily, dst_orig);\n\n\t\t\tif (IS_ERR(xdst)) {\n\t\t\t\txfrm_pols_put(pols, num_pols);\n\t\t\t\terr = PTR_ERR(xdst);\n\t\t\t\tif (err == -EREMOTE)\n\t\t\t\t\tgoto nopol;\n\n\t\t\t\tgoto dropdst;\n\t\t\t} else if (xdst == NULL) {\n\t\t\t\tnum_xfrms = 0;\n\t\t\t\tdrop_pols = num_pols;\n\t\t\t\tgoto no_transform;\n\t\t\t}\n\n\t\t\troute = xdst->route;\n\t\t}\n\t}\n\n\tif (xdst == NULL) {\n\t\tstruct xfrm_flo xflo;\n\n\t\txflo.dst_orig = dst_orig;\n\t\txflo.flags = flags;\n\n\t\t/* To accelerate a bit...  */\n\t\tif (!if_id && ((dst_orig->flags & DST_NOXFRM) ||\n\t\t\t       !net->xfrm.policy_count[XFRM_POLICY_OUT]))\n\t\t\tgoto nopol;\n\n\t\txdst = xfrm_bundle_lookup(net, fl, family, dir, &xflo, if_id);\n\t\tif (xdst == NULL)\n\t\t\tgoto nopol;\n\t\tif (IS_ERR(xdst)) {\n\t\t\terr = PTR_ERR(xdst);\n\t\t\tgoto dropdst;\n\t\t}\n\n\t\tnum_pols = xdst->num_pols;\n\t\tnum_xfrms = xdst->num_xfrms;\n\t\tmemcpy(pols, xdst->pols, sizeof(struct xfrm_policy *) * num_pols);\n\t\troute = xdst->route;\n\t}\n\n\tdst = &xdst->u.dst;\n\tif (route == NULL && num_xfrms > 0) {\n\t\t/* The only case when xfrm_bundle_lookup() returns a\n\t\t * bundle with null route, is when the template could\n\t\t * not be resolved. It means policies are there, but\n\t\t * bundle could not be created, since we don't yet\n\t\t * have the xfrm_state's. We need to wait for KM to\n\t\t * negotiate new SA's or bail out with error.*/\n\t\tif (net->xfrm.sysctl_larval_drop) {\n\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMOUTNOSTATES);\n\t\t\terr = -EREMOTE;\n\t\t\tgoto error;\n\t\t}\n\n\t\terr = -EAGAIN;\n\n\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMOUTNOSTATES);\n\t\tgoto error;\n\t}\n\nno_transform:\n\tif (num_pols == 0)\n\t\tgoto nopol;\n\n\tif ((flags & XFRM_LOOKUP_ICMP) &&\n\t    !(pols[0]->flags & XFRM_POLICY_ICMP)) {\n\t\terr = -ENOENT;\n\t\tgoto error;\n\t}\n\n\tfor (i = 0; i < num_pols; i++)\n\t\tWRITE_ONCE(pols[i]->curlft.use_time, ktime_get_real_seconds());\n\n\tif (num_xfrms < 0) {\n\t\t/* Prohibit the flow */\n\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMOUTPOLBLOCK);\n\t\terr = -EPERM;\n\t\tgoto error;\n\t} else if (num_xfrms > 0) {\n\t\t/* Flow transformed */\n\t\tdst_release(dst_orig);\n\t} else {\n\t\t/* Flow passes untransformed */\n\t\tdst_release(dst);\n\t\tdst = dst_orig;\n\t}\n\nok:\n\txfrm_pols_put(pols, drop_pols);\n\tif (dst->xfrm &&\n\t    (dst->xfrm->props.mode == XFRM_MODE_TUNNEL ||\n\t     dst->xfrm->props.mode == XFRM_MODE_IPTFS))\n\t\tdst->flags |= DST_XFRM_TUNNEL;\n\treturn dst;\n\nnopol:\n\tif ((!dst_orig->dev || !(dst_orig->dev->flags & IFF_LOOPBACK)) &&\n\t    net->xfrm.policy_default[dir] == XFRM_USERPOLICY_BLOCK) {\n\t\terr = -EPERM;\n\t\tgoto error;\n\t}\n\tif (!(flags & XFRM_LOOKUP_ICMP)) {\n\t\tdst = dst_orig;\n\t\tgoto ok;\n\t}\n\terr = -ENOENT;\nerror:\n\tdst_release(dst);\ndropdst:\n\tif (!(flags & XFRM_LOOKUP_KEEP_DST_REF))\n\t\tdst_release(dst_orig);\n\txfrm_pols_put(pols, drop_pols);\n\treturn ERR_PTR(err);\n}\nEXPORT_SYMBOL(xfrm_lookup_with_ifid);\n\n/* Main function: finds/creates a bundle for given flow.\n *\n * At the moment we eat a raw IP route. Mostly to speed up lookups\n * on interfaces with disabled IPsec.\n */\nstruct dst_entry *xfrm_lookup(struct net *net, struct dst_entry *dst_orig,\n\t\t\t      const struct flowi *fl, const struct sock *sk,\n\t\t\t      int flags)\n{\n\treturn xfrm_lookup_with_ifid(net, dst_orig, fl, sk, flags, 0);\n}\nEXPORT_SYMBOL(xfrm_lookup);\n\n/* Callers of xfrm_lookup_route() must ensure a call to dst_output().\n * Otherwise we may send out blackholed packets.\n */\nstruct dst_entry *xfrm_lookup_route(struct net *net, struct dst_entry *dst_orig,\n\t\t\t\t    const struct flowi *fl,\n\t\t\t\t    const struct sock *sk, int flags)\n{\n\tstruct dst_entry *dst = xfrm_lookup(net, dst_orig, fl, sk,\n\t\t\t\t\t    flags | XFRM_LOOKUP_QUEUE |\n\t\t\t\t\t    XFRM_LOOKUP_KEEP_DST_REF);\n\n\tif (PTR_ERR(dst) == -EREMOTE)\n\t\treturn make_blackhole(net, dst_orig->ops->family, dst_orig);\n\n\tif (IS_ERR(dst))\n\t\tdst_release(dst_orig);\n\n\treturn dst;\n}\nEXPORT_SYMBOL(xfrm_lookup_route);\n\nstatic inline int\nxfrm_secpath_reject(int idx, struct sk_buff *skb, const struct flowi *fl)\n{\n\tstruct sec_path *sp = skb_sec_path(skb);\n\tstruct xfrm_state *x;\n\n\tif (!sp || idx < 0 || idx >= sp->len)\n\t\treturn 0;\n\tx = sp->xvec[idx];\n\tif (!x->type->reject)\n\t\treturn 0;\n\treturn x->type->reject(x, skb, fl);\n}\n\n/* When skb is transformed back to its \"native\" form, we have to\n * check policy restrictions. At the moment we make this in maximally\n * stupid way. Shame on me. :-) Of course, connected sockets must\n * have policy cached at them.\n */\n\nstatic inline int\nxfrm_state_ok(const struct xfrm_tmpl *tmpl, const struct xfrm_state *x,\n\t      unsigned short family, u32 if_id)\n{\n\tif (xfrm_state_kern(x))\n\t\treturn tmpl->optional && !xfrm_state_addr_cmp(tmpl, x, tmpl->encap_family);\n\treturn\tx->id.proto == tmpl->id.proto &&\n\t\t(x->id.spi == tmpl->id.spi || !tmpl->id.spi) &&\n\t\t(x->props.reqid == tmpl->reqid || !tmpl->reqid) &&\n\t\tx->props.mode == tmpl->mode &&\n\t\t(tmpl->allalgs || (tmpl->aalgos & (1<<x->props.aalgo)) ||\n\t\t !(xfrm_id_proto_match(tmpl->id.proto, IPSEC_PROTO_ANY))) &&\n\t\t!(x->props.mode != XFRM_MODE_TRANSPORT &&\n\t\t  xfrm_state_addr_cmp(tmpl, x, family)) &&\n\t\t(if_id == 0 || if_id == x->if_id);\n}\n\n/*\n * 0 or more than 0 is returned when validation is succeeded (either bypass\n * because of optional transport mode, or next index of the matched secpath\n * state with the template.\n * -1 is returned when no matching template is found.\n * Otherwise \"-2 - errored_index\" is returned.\n */\nstatic inline int\nxfrm_policy_ok(const struct xfrm_tmpl *tmpl, const struct sec_path *sp, int start,\n\t       unsigned short family, u32 if_id)\n{\n\tint idx = start;\n\n\tif (tmpl->optional) {\n\t\tif (tmpl->mode == XFRM_MODE_TRANSPORT)\n\t\t\treturn start;\n\t} else\n\t\tstart = -1;\n\tfor (; idx < sp->len; idx++) {\n\t\tif (xfrm_state_ok(tmpl, sp->xvec[idx], family, if_id))\n\t\t\treturn ++idx;\n\t\tif (sp->xvec[idx]->props.mode != XFRM_MODE_TRANSPORT) {\n\t\t\tif (idx < sp->verified_cnt) {\n\t\t\t\t/* Secpath entry previously verified, consider optional and\n\t\t\t\t * continue searching\n\t\t\t\t */\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (start == -1)\n\t\t\t\tstart = -2-idx;\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn start;\n}\n\nstatic void\ndecode_session4(const struct xfrm_flow_keys *flkeys, struct flowi *fl, bool reverse)\n{\n\tstruct flowi4 *fl4 = &fl->u.ip4;\n\n\tmemset(fl4, 0, sizeof(struct flowi4));\n\n\tif (reverse) {\n\t\tfl4->saddr = flkeys->addrs.ipv4.dst;\n\t\tfl4->daddr = flkeys->addrs.ipv4.src;\n\t\tfl4->fl4_sport = flkeys->ports.dst;\n\t\tfl4->fl4_dport = flkeys->ports.src;\n\t} else {\n\t\tfl4->saddr = flkeys->addrs.ipv4.src;\n\t\tfl4->daddr = flkeys->addrs.ipv4.dst;\n\t\tfl4->fl4_sport = flkeys->ports.src;\n\t\tfl4->fl4_dport = flkeys->ports.dst;\n\t}\n\n\tswitch (flkeys->basic.ip_proto) {\n\tcase IPPROTO_GRE:\n\t\tfl4->fl4_gre_key = flkeys->gre.keyid;\n\t\tbreak;\n\tcase IPPROTO_ICMP:\n\t\tfl4->fl4_icmp_type = flkeys->icmp.type;\n\t\tfl4->fl4_icmp_code = flkeys->icmp.code;\n\t\tbreak;\n\t}\n\n\tfl4->flowi4_proto = flkeys->basic.ip_proto;\n\tfl4->flowi4_dscp = inet_dsfield_to_dscp(flkeys->ip.tos);\n}\n\n#if IS_ENABLED(CONFIG_IPV6)\nstatic void\ndecode_session6(const struct xfrm_flow_keys *flkeys, struct flowi *fl, bool reverse)\n{\n\tstruct flowi6 *fl6 = &fl->u.ip6;\n\n\tmemset(fl6, 0, sizeof(struct flowi6));\n\n\tif (reverse) {\n\t\tfl6->saddr = flkeys->addrs.ipv6.dst;\n\t\tfl6->daddr = flkeys->addrs.ipv6.src;\n\t\tfl6->fl6_sport = flkeys->ports.dst;\n\t\tfl6->fl6_dport = flkeys->ports.src;\n\t} else {\n\t\tfl6->saddr = flkeys->addrs.ipv6.src;\n\t\tfl6->daddr = flkeys->addrs.ipv6.dst;\n\t\tfl6->fl6_sport = flkeys->ports.src;\n\t\tfl6->fl6_dport = flkeys->ports.dst;\n\t}\n\n\tswitch (flkeys->basic.ip_proto) {\n\tcase IPPROTO_GRE:\n\t\tfl6->fl6_gre_key = flkeys->gre.keyid;\n\t\tbreak;\n\tcase IPPROTO_ICMPV6:\n\t\tfl6->fl6_icmp_type = flkeys->icmp.type;\n\t\tfl6->fl6_icmp_code = flkeys->icmp.code;\n\t\tbreak;\n\t}\n\n\tfl6->flowi6_proto = flkeys->basic.ip_proto;\n}\n#endif\n\nint __xfrm_decode_session(struct net *net, struct sk_buff *skb, struct flowi *fl,\n\t\t\t  unsigned int family, int reverse)\n{\n\tstruct xfrm_flow_keys flkeys;\n\n\tmemset(&flkeys, 0, sizeof(flkeys));\n\t__skb_flow_dissect(net, skb, &xfrm_session_dissector, &flkeys,\n\t\t\t   NULL, 0, 0, 0, FLOW_DISSECTOR_F_STOP_AT_ENCAP);\n\n\tswitch (family) {\n\tcase AF_INET:\n\t\tdecode_session4(&flkeys, fl, reverse);\n\t\tbreak;\n#if IS_ENABLED(CONFIG_IPV6)\n\tcase AF_INET6:\n\t\tdecode_session6(&flkeys, fl, reverse);\n\t\tbreak;\n#endif\n\tdefault:\n\t\treturn -EAFNOSUPPORT;\n\t}\n\n\tfl->flowi_mark = skb->mark;\n\tif (reverse) {\n\t\tfl->flowi_oif = skb->skb_iif;\n\t} else {\n\t\tint oif = 0;\n\n\t\tif (skb_dst(skb) && skb_dst(skb)->dev)\n\t\t\toif = skb_dst(skb)->dev->ifindex;\n\n\t\tfl->flowi_oif = oif;\n\t}\n\n\treturn security_xfrm_decode_session(skb, &fl->flowi_secid);\n}\nEXPORT_SYMBOL(__xfrm_decode_session);\n\nstatic inline int secpath_has_nontransport(const struct sec_path *sp, int k, int *idxp)\n{\n\tfor (; k < sp->len; k++) {\n\t\tif (sp->xvec[k]->props.mode != XFRM_MODE_TRANSPORT) {\n\t\t\t*idxp = k;\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic bool icmp_err_packet(const struct flowi *fl, unsigned short family)\n{\n\tconst struct flowi4 *fl4 = &fl->u.ip4;\n\n\tif (family == AF_INET &&\n\t    fl4->flowi4_proto == IPPROTO_ICMP &&\n\t    (fl4->fl4_icmp_type == ICMP_DEST_UNREACH ||\n\t     fl4->fl4_icmp_type == ICMP_TIME_EXCEEDED))\n\t\treturn true;\n\n#if IS_ENABLED(CONFIG_IPV6)\n\tif (family == AF_INET6) {\n\t\tconst struct flowi6 *fl6 = &fl->u.ip6;\n\n\t\tif (fl6->flowi6_proto == IPPROTO_ICMPV6 &&\n\t\t    (fl6->fl6_icmp_type == ICMPV6_DEST_UNREACH ||\n\t\t    fl6->fl6_icmp_type == ICMPV6_PKT_TOOBIG ||\n\t\t    fl6->fl6_icmp_type == ICMPV6_TIME_EXCEED))\n\t\t\treturn true;\n\t}\n#endif\n\treturn false;\n}\n\nstatic bool xfrm_icmp_flow_decode(struct sk_buff *skb, unsigned short family,\n\t\t\t\t  const struct flowi *fl, struct flowi *fl1)\n{\n\tbool ret = true;\n\tstruct sk_buff *newskb = skb_clone(skb, GFP_ATOMIC);\n\tint hl = family == AF_INET ? (sizeof(struct iphdr) +  sizeof(struct icmphdr)) :\n\t\t (sizeof(struct ipv6hdr) + sizeof(struct icmp6hdr));\n\n\tif (!newskb)\n\t\treturn true;\n\n\tif (!pskb_pull(newskb, hl))\n\t\tgoto out;\n\n\tskb_reset_network_header(newskb);\n\n\tif (xfrm_decode_session_reverse(dev_net(skb->dev), newskb, fl1, family) < 0)\n\t\tgoto out;\n\n\tfl1->flowi_oif = fl->flowi_oif;\n\tfl1->flowi_mark = fl->flowi_mark;\n\tfl1->flowi_dscp = fl->flowi_dscp;\n\tnf_nat_decode_session(newskb, fl1, family);\n\tret = false;\n\nout:\n\tconsume_skb(newskb);\n\treturn ret;\n}\n\nstatic bool xfrm_selector_inner_icmp_match(struct sk_buff *skb, unsigned short family,\n\t\t\t\t\t   const struct xfrm_selector *sel,\n\t\t\t\t\t   const struct flowi *fl)\n{\n\tbool ret = false;\n\n\tif (icmp_err_packet(fl, family)) {\n\t\tstruct flowi fl1;\n\n\t\tif (xfrm_icmp_flow_decode(skb, family, fl, &fl1))\n\t\t\treturn ret;\n\n\t\tret = xfrm_selector_match(sel, &fl1, family);\n\t}\n\n\treturn ret;\n}\n\nstatic inline struct\nxfrm_policy *xfrm_in_fwd_icmp(struct sk_buff *skb,\n\t\t\t      const struct flowi *fl, unsigned short family,\n\t\t\t      u32 if_id)\n{\n\tstruct xfrm_policy *pol = NULL;\n\n\tif (icmp_err_packet(fl, family)) {\n\t\tstruct flowi fl1;\n\t\tstruct net *net = dev_net(skb->dev);\n\n\t\tif (xfrm_icmp_flow_decode(skb, family, fl, &fl1))\n\t\t\treturn pol;\n\n\t\tpol = xfrm_policy_lookup(net, &fl1, family, XFRM_POLICY_FWD, if_id);\n\t\tif (IS_ERR(pol))\n\t\t\tpol = NULL;\n\t}\n\n\treturn pol;\n}\n\nstatic inline struct\ndst_entry *xfrm_out_fwd_icmp(struct sk_buff *skb, struct flowi *fl,\n\t\t\t     unsigned short family, struct dst_entry *dst)\n{\n\tif (icmp_err_packet(fl, family)) {\n\t\tstruct net *net = dev_net(skb->dev);\n\t\tstruct dst_entry *dst2;\n\t\tstruct flowi fl1;\n\n\t\tif (xfrm_icmp_flow_decode(skb, family, fl, &fl1))\n\t\t\treturn dst;\n\n\t\tdst_hold(dst);\n\n\t\tdst2 = xfrm_lookup(net, dst, &fl1, NULL, (XFRM_LOOKUP_QUEUE | XFRM_LOOKUP_ICMP));\n\n\t\tif (IS_ERR(dst2))\n\t\t\treturn dst;\n\n\t\tif (dst2->xfrm) {\n\t\t\tdst_release(dst);\n\t\t\tdst = dst2;\n\t\t} else {\n\t\t\tdst_release(dst2);\n\t\t}\n\t}\n\n\treturn dst;\n}\n\nint __xfrm_policy_check(struct sock *sk, int dir, struct sk_buff *skb,\n\t\t\tunsigned short family)\n{\n\tstruct net *net = dev_net(skb->dev);\n\tstruct xfrm_policy *pol;\n\tstruct xfrm_policy *pols[XFRM_POLICY_TYPE_MAX];\n\tint npols = 0;\n\tint xfrm_nr;\n\tint pi;\n\tint reverse;\n\tstruct flowi fl;\n\tint xerr_idx = -1;\n\tconst struct xfrm_if_cb *ifcb;\n\tstruct sec_path *sp;\n\tu32 if_id = 0;\n\n\trcu_read_lock();\n\tifcb = xfrm_if_get_cb();\n\n\tif (ifcb) {\n\t\tstruct xfrm_if_decode_session_result r;\n\n\t\tif (ifcb->decode_session(skb, family, &r)) {\n\t\t\tif_id = r.if_id;\n\t\t\tnet = r.net;\n\t\t}\n\t}\n\trcu_read_unlock();\n\n\treverse = dir & ~XFRM_POLICY_MASK;\n\tdir &= XFRM_POLICY_MASK;\n\n\tif (__xfrm_decode_session(net, skb, &fl, family, reverse) < 0) {\n\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINHDRERROR);\n\t\treturn 0;\n\t}\n\n\tnf_nat_decode_session(skb, &fl, family);\n\n\t/* First, check used SA against their selectors. */\n\tsp = skb_sec_path(skb);\n\tif (sp) {\n\t\tint i;\n\n\t\tfor (i = sp->len - 1; i >= 0; i--) {\n\t\t\tstruct xfrm_state *x = sp->xvec[i];\n\t\t\tint ret = 0;\n\n\t\t\tif (!xfrm_selector_match(&x->sel, &fl, family)) {\n\t\t\t\tret = 1;\n\t\t\t\tif (x->props.flags & XFRM_STATE_ICMP &&\n\t\t\t\t    xfrm_selector_inner_icmp_match(skb, family, &x->sel, &fl))\n\t\t\t\t\tret = 0;\n\t\t\t\tif (ret) {\n\t\t\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINSTATEMISMATCH);\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tpol = NULL;\n\tsk = sk_to_full_sk(sk);\n\tif (sk && sk->sk_policy[dir]) {\n\t\tpol = xfrm_sk_policy_lookup(sk, dir, &fl, family, if_id);\n\t\tif (IS_ERR(pol)) {\n\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINPOLERROR);\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\tif (!pol)\n\t\tpol = xfrm_policy_lookup(net, &fl, family, dir, if_id);\n\n\tif (IS_ERR(pol)) {\n\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINPOLERROR);\n\t\treturn 0;\n\t}\n\n\tif (!pol && dir == XFRM_POLICY_FWD)\n\t\tpol = xfrm_in_fwd_icmp(skb, &fl, family, if_id);\n\n\tif (!pol) {\n\t\tconst bool is_crypto_offload = sp &&\n\t\t\t(xfrm_input_state(skb)->xso.type == XFRM_DEV_OFFLOAD_CRYPTO);\n\n\t\tif (net->xfrm.policy_default[dir] == XFRM_USERPOLICY_BLOCK) {\n\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINNOPOLS);\n\t\t\treturn 0;\n\t\t}\n\n\t\tif (sp && secpath_has_nontransport(sp, 0, &xerr_idx) && !is_crypto_offload) {\n\t\t\txfrm_secpath_reject(xerr_idx, skb, &fl);\n\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINNOPOLS);\n\t\t\treturn 0;\n\t\t}\n\t\treturn 1;\n\t}\n\n\t/* This lockless write can happen from different cpus. */\n\tWRITE_ONCE(pol->curlft.use_time, ktime_get_real_seconds());\n\n\tpols[0] = pol;\n\tnpols++;\n#ifdef CONFIG_XFRM_SUB_POLICY\n\tif (pols[0]->type != XFRM_POLICY_TYPE_MAIN) {\n\t\tpols[1] = xfrm_policy_lookup_bytype(net, XFRM_POLICY_TYPE_MAIN,\n\t\t\t\t\t\t    &fl, family,\n\t\t\t\t\t\t    XFRM_POLICY_IN, if_id);\n\t\tif (pols[1]) {\n\t\t\tif (IS_ERR(pols[1])) {\n\t\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINPOLERROR);\n\t\t\t\txfrm_pol_put(pols[0]);\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\t/* This write can happen from different cpus. */\n\t\t\tWRITE_ONCE(pols[1]->curlft.use_time,\n\t\t\t\t   ktime_get_real_seconds());\n\t\t\tnpols++;\n\t\t}\n\t}\n#endif\n\n\tif (pol->action == XFRM_POLICY_ALLOW) {\n\t\tstatic struct sec_path dummy;\n\t\tstruct xfrm_tmpl *tp[XFRM_MAX_DEPTH];\n\t\tstruct xfrm_tmpl *stp[XFRM_MAX_DEPTH];\n\t\tstruct xfrm_tmpl **tpp = tp;\n\t\tint ti = 0;\n\t\tint i, k;\n\n\t\tsp = skb_sec_path(skb);\n\t\tif (!sp)\n\t\t\tsp = &dummy;\n\n\t\tfor (pi = 0; pi < npols; pi++) {\n\t\t\tif (pols[pi] != pol &&\n\t\t\t    pols[pi]->action != XFRM_POLICY_ALLOW) {\n\t\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINPOLBLOCK);\n\t\t\t\tgoto reject;\n\t\t\t}\n\t\t\tif (ti + pols[pi]->xfrm_nr >= XFRM_MAX_DEPTH) {\n\t\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINBUFFERERROR);\n\t\t\t\tgoto reject_error;\n\t\t\t}\n\t\t\tfor (i = 0; i < pols[pi]->xfrm_nr; i++)\n\t\t\t\ttpp[ti++] = &pols[pi]->xfrm_vec[i];\n\t\t}\n\t\txfrm_nr = ti;\n\n\t\tif (npols > 1) {\n\t\t\txfrm_tmpl_sort(stp, tpp, xfrm_nr, family);\n\t\t\ttpp = stp;\n\t\t}\n\n\t\t/* For each tunnel xfrm, find the first matching tmpl.\n\t\t * For each tmpl before that, find corresponding xfrm.\n\t\t * Order is _important_. Later we will implement\n\t\t * some barriers, but at the moment barriers\n\t\t * are implied between each two transformations.\n\t\t * Upon success, marks secpath entries as having been\n\t\t * verified to allow them to be skipped in future policy\n\t\t * checks (e.g. nested tunnels).\n\t\t */\n\t\tfor (i = xfrm_nr-1, k = 0; i >= 0; i--) {\n\t\t\tk = xfrm_policy_ok(tpp[i], sp, k, family, if_id);\n\t\t\tif (k < 0) {\n\t\t\t\tif (k < -1)\n\t\t\t\t\t/* \"-2 - errored_index\" returned */\n\t\t\t\t\txerr_idx = -(2+k);\n\t\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINTMPLMISMATCH);\n\t\t\t\tgoto reject;\n\t\t\t}\n\t\t}\n\n\t\tif (secpath_has_nontransport(sp, k, &xerr_idx)) {\n\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINTMPLMISMATCH);\n\t\t\tgoto reject;\n\t\t}\n\n\t\txfrm_pols_put(pols, npols);\n\t\tsp->verified_cnt = k;\n\n\t\treturn 1;\n\t}\n\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINPOLBLOCK);\n\nreject:\n\txfrm_secpath_reject(xerr_idx, skb, &fl);\nreject_error:\n\txfrm_pols_put(pols, npols);\n\treturn 0;\n}\nEXPORT_SYMBOL(__xfrm_policy_check);\n\nint __xfrm_route_forward(struct sk_buff *skb, unsigned short family)\n{\n\tstruct net *net = dev_net(skb->dev);\n\tstruct flowi fl;\n\tstruct dst_entry *dst;\n\tint res = 1;\n\n\tif (xfrm_decode_session(net, skb, &fl, family) < 0) {\n\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMFWDHDRERROR);\n\t\treturn 0;\n\t}\n\n\tskb_dst_force(skb);\n\tdst = skb_dst(skb);\n\tif (!dst) {\n\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMFWDHDRERROR);\n\t\treturn 0;\n\t}\n\n\t/* ignore return value from skb_dstref_steal, xfrm_lookup takes\n\t * care of dropping the refcnt if needed.\n\t */\n\tskb_dstref_steal(skb);\n\n\tdst = xfrm_lookup(net, dst, &fl, NULL, XFRM_LOOKUP_QUEUE);\n\tif (IS_ERR(dst)) {\n\t\tres = 0;\n\t\tdst = NULL;\n\t}\n\n\tif (dst && !dst->xfrm)\n\t\tdst = xfrm_out_fwd_icmp(skb, &fl, family, dst);\n\n\tskb_dst_set(skb, dst);\n\treturn res;\n}\nEXPORT_SYMBOL(__xfrm_route_forward);\n\n/* Optimize later using cookies and generation ids. */\n\nstatic struct dst_entry *xfrm_dst_check(struct dst_entry *dst, u32 cookie)\n{\n\t/* Code (such as __xfrm4_bundle_create()) sets dst->obsolete\n\t * to DST_OBSOLETE_FORCE_CHK to force all XFRM destinations to\n\t * get validated by dst_ops->check on every use.  We do this\n\t * because when a normal route referenced by an XFRM dst is\n\t * obsoleted we do not go looking around for all parent\n\t * referencing XFRM dsts so that we can invalidate them.  It\n\t * is just too much work.  Instead we make the checks here on\n\t * every use.  For example:\n\t *\n\t *\tXFRM dst A --> IPv4 dst X\n\t *\n\t * X is the \"xdst->route\" of A (X is also the \"dst->path\" of A\n\t * in this example).  If X is marked obsolete, \"A\" will not\n\t * notice.  That's what we are validating here via the\n\t * stale_bundle() check.\n\t *\n\t * When a dst is removed from the fib tree, DST_OBSOLETE_DEAD will\n\t * be marked on it.\n\t * This will force stale_bundle() to fail on any xdst bundle with\n\t * this dst linked in it.\n\t */\n\tif (READ_ONCE(dst->obsolete) < 0 && !stale_bundle(dst))\n\t\treturn dst;\n\n\treturn NULL;\n}\n\nstatic int stale_bundle(struct dst_entry *dst)\n{\n\treturn !xfrm_bundle_ok((struct xfrm_dst *)dst);\n}\n\nvoid xfrm_dst_ifdown(struct dst_entry *dst, struct net_device *dev)\n{\n\twhile ((dst = xfrm_dst_child(dst)) && dst->xfrm && dst->dev == dev) {\n\t\tdst->dev = blackhole_netdev;\n\t\tdev_hold(dst->dev);\n\t\tdev_put(dev);\n\t}\n}\nEXPORT_SYMBOL(xfrm_dst_ifdown);\n\nstatic void xfrm_link_failure(struct sk_buff *skb)\n{\n\t/* Impossible. Such dst must be popped before reaches point of failure. */\n}\n\nstatic void xfrm_negative_advice(struct sock *sk, struct dst_entry *dst)\n{\n\tif (READ_ONCE(dst->obsolete))\n\t\tsk_dst_reset(sk);\n}\n\nstatic void xfrm_init_pmtu(struct xfrm_dst **bundle, int nr)\n{\n\twhile (nr--) {\n\t\tstruct xfrm_dst *xdst = bundle[nr];\n\t\tu32 pmtu, route_mtu_cached;\n\t\tstruct dst_entry *dst;\n\n\t\tdst = &xdst->u.dst;\n\t\tpmtu = dst_mtu(xfrm_dst_child(dst));\n\t\txdst->child_mtu_cached = pmtu;\n\n\t\tpmtu = xfrm_state_mtu(dst->xfrm, pmtu);\n\n\t\troute_mtu_cached = dst_mtu(xdst->route);\n\t\txdst->route_mtu_cached = route_mtu_cached;\n\n\t\tif (pmtu > route_mtu_cached)\n\t\t\tpmtu = route_mtu_cached;\n\n\t\tdst_metric_set(dst, RTAX_MTU, pmtu);\n\t}\n}\n\n/* Check that the bundle accepts the flow and its components are\n * still valid.\n */\n\nstatic int xfrm_bundle_ok(struct xfrm_dst *first)\n{\n\tstruct xfrm_dst *bundle[XFRM_MAX_DEPTH];\n\tstruct dst_entry *dst = &first->u.dst;\n\tstruct xfrm_dst *xdst;\n\tint start_from, nr;\n\tu32 mtu;\n\n\tif (!dst_check(xfrm_dst_path(dst), ((struct xfrm_dst *)dst)->path_cookie) ||\n\t    (dst->dev && !netif_running(dst->dev)))\n\t\treturn 0;\n\n\tif (dst->flags & DST_XFRM_QUEUE)\n\t\treturn 1;\n\n\tstart_from = nr = 0;\n\tdo {\n\t\tstruct xfrm_dst *xdst = (struct xfrm_dst *)dst;\n\n\t\tif (dst->xfrm->km.state != XFRM_STATE_VALID)\n\t\t\treturn 0;\n\t\tif (xdst->xfrm_genid != dst->xfrm->genid)\n\t\t\treturn 0;\n\t\tif (xdst->num_pols > 0 &&\n\t\t    xdst->policy_genid != atomic_read(&xdst->pols[0]->genid))\n\t\t\treturn 0;\n\n\t\tbundle[nr++] = xdst;\n\n\t\tmtu = dst_mtu(xfrm_dst_child(dst));\n\t\tif (xdst->child_mtu_cached != mtu) {\n\t\t\tstart_from = nr;\n\t\t\txdst->child_mtu_cached = mtu;\n\t\t}\n\n\t\tif (!dst_check(xdst->route, xdst->route_cookie))\n\t\t\treturn 0;\n\t\tmtu = dst_mtu(xdst->route);\n\t\tif (xdst->route_mtu_cached != mtu) {\n\t\t\tstart_from = nr;\n\t\t\txdst->route_mtu_cached = mtu;\n\t\t}\n\n\t\tdst = xfrm_dst_child(dst);\n\t} while (dst->xfrm);\n\n\tif (likely(!start_from))\n\t\treturn 1;\n\n\txdst = bundle[start_from - 1];\n\tmtu = xdst->child_mtu_cached;\n\twhile (start_from--) {\n\t\tdst = &xdst->u.dst;\n\n\t\tmtu = xfrm_state_mtu(dst->xfrm, mtu);\n\t\tif (mtu > xdst->route_mtu_cached)\n\t\t\tmtu = xdst->route_mtu_cached;\n\t\tdst_metric_set(dst, RTAX_MTU, mtu);\n\t\tif (!start_from)\n\t\t\tbreak;\n\n\t\txdst = bundle[start_from - 1];\n\t\txdst->child_mtu_cached = mtu;\n\t}\n\n\treturn 1;\n}\n\nstatic unsigned int xfrm_default_advmss(const struct dst_entry *dst)\n{\n\treturn dst_metric_advmss(xfrm_dst_path(dst));\n}\n\nstatic unsigned int xfrm_mtu(const struct dst_entry *dst)\n{\n\tunsigned int mtu = dst_metric_raw(dst, RTAX_MTU);\n\n\treturn mtu ? : dst_mtu(xfrm_dst_path(dst));\n}\n\nstatic const void *xfrm_get_dst_nexthop(const struct dst_entry *dst,\n\t\t\t\t\tconst void *daddr)\n{\n\twhile (dst->xfrm) {\n\t\tconst struct xfrm_state *xfrm = dst->xfrm;\n\n\t\tdst = xfrm_dst_child(dst);\n\n\t\tif (xfrm->props.mode == XFRM_MODE_TRANSPORT)\n\t\t\tcontinue;\n\t\tif (xfrm->type->flags & XFRM_TYPE_REMOTE_COADDR)\n\t\t\tdaddr = xfrm->coaddr;\n\t\telse if (!(xfrm->type->flags & XFRM_TYPE_LOCAL_COADDR))\n\t\t\tdaddr = &xfrm->id.daddr;\n\t}\n\treturn daddr;\n}\n\nstatic struct neighbour *xfrm_neigh_lookup(const struct dst_entry *dst,\n\t\t\t\t\t   struct sk_buff *skb,\n\t\t\t\t\t   const void *daddr)\n{\n\tconst struct dst_entry *path = xfrm_dst_path(dst);\n\n\tif (!skb)\n\t\tdaddr = xfrm_get_dst_nexthop(dst, daddr);\n\treturn path->ops->neigh_lookup(path, skb, daddr);\n}\n\nstatic void xfrm_confirm_neigh(const struct dst_entry *dst, const void *daddr)\n{\n\tconst struct dst_entry *path = xfrm_dst_path(dst);\n\n\tdaddr = xfrm_get_dst_nexthop(dst, daddr);\n\tpath->ops->confirm_neigh(path, daddr);\n}\n\nint xfrm_policy_register_afinfo(const struct xfrm_policy_afinfo *afinfo, int family)\n{\n\tint err = 0;\n\n\tif (WARN_ON(family >= ARRAY_SIZE(xfrm_policy_afinfo)))\n\t\treturn -EAFNOSUPPORT;\n\n\tspin_lock(&xfrm_policy_afinfo_lock);\n\tif (unlikely(xfrm_policy_afinfo[family] != NULL))\n\t\terr = -EEXIST;\n\telse {\n\t\tstruct dst_ops *dst_ops = afinfo->dst_ops;\n\t\tif (likely(dst_ops->kmem_cachep == NULL))\n\t\t\tdst_ops->kmem_cachep = xfrm_dst_cache;\n\t\tif (likely(dst_ops->check == NULL))\n\t\t\tdst_ops->check = xfrm_dst_check;\n\t\tif (likely(dst_ops->default_advmss == NULL))\n\t\t\tdst_ops->default_advmss = xfrm_default_advmss;\n\t\tif (likely(dst_ops->mtu == NULL))\n\t\t\tdst_ops->mtu = xfrm_mtu;\n\t\tif (likely(dst_ops->negative_advice == NULL))\n\t\t\tdst_ops->negative_advice = xfrm_negative_advice;\n\t\tif (likely(dst_ops->link_failure == NULL))\n\t\t\tdst_ops->link_failure = xfrm_link_failure;\n\t\tif (likely(dst_ops->neigh_lookup == NULL))\n\t\t\tdst_ops->neigh_lookup = xfrm_neigh_lookup;\n\t\tif (likely(!dst_ops->confirm_neigh))\n\t\t\tdst_ops->confirm_neigh = xfrm_confirm_neigh;\n\t\trcu_assign_pointer(xfrm_policy_afinfo[family], afinfo);\n\t}\n\tspin_unlock(&xfrm_policy_afinfo_lock);\n\n\treturn err;\n}\nEXPORT_SYMBOL(xfrm_policy_register_afinfo);\n\nvoid xfrm_policy_unregister_afinfo(const struct xfrm_policy_afinfo *afinfo)\n{\n\tstruct dst_ops *dst_ops = afinfo->dst_ops;\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(xfrm_policy_afinfo); i++) {\n\t\tif (xfrm_policy_afinfo[i] != afinfo)\n\t\t\tcontinue;\n\t\tRCU_INIT_POINTER(xfrm_policy_afinfo[i], NULL);\n\t\tbreak;\n\t}\n\n\tsynchronize_rcu();\n\n\tdst_ops->kmem_cachep = NULL;\n\tdst_ops->check = NULL;\n\tdst_ops->negative_advice = NULL;\n\tdst_ops->link_failure = NULL;\n}\nEXPORT_SYMBOL(xfrm_policy_unregister_afinfo);\n\nvoid xfrm_if_register_cb(const struct xfrm_if_cb *ifcb)\n{\n\tspin_lock(&xfrm_if_cb_lock);\n\trcu_assign_pointer(xfrm_if_cb, ifcb);\n\tspin_unlock(&xfrm_if_cb_lock);\n}\nEXPORT_SYMBOL(xfrm_if_register_cb);\n\nvoid xfrm_if_unregister_cb(void)\n{\n\tRCU_INIT_POINTER(xfrm_if_cb, NULL);\n\tsynchronize_rcu();\n}\nEXPORT_SYMBOL(xfrm_if_unregister_cb);\n\n#ifdef CONFIG_XFRM_STATISTICS\nstatic int __net_init xfrm_statistics_init(struct net *net)\n{\n\tint rv;\n\tnet->mib.xfrm_statistics = alloc_percpu(struct linux_xfrm_mib);\n\tif (!net->mib.xfrm_statistics)\n\t\treturn -ENOMEM;\n\trv = xfrm_proc_init(net);\n\tif (rv < 0)\n\t\tfree_percpu(net->mib.xfrm_statistics);\n\treturn rv;\n}\n\nstatic void xfrm_statistics_fini(struct net *net)\n{\n\txfrm_proc_fini(net);\n\tfree_percpu(net->mib.xfrm_statistics);\n}\n#else\nstatic int __net_init xfrm_statistics_init(struct net *net)\n{\n\treturn 0;\n}\n\nstatic void xfrm_statistics_fini(struct net *net)\n{\n}\n#endif\n\nstatic int __net_init xfrm_policy_init(struct net *net)\n{\n\tunsigned int hmask, sz;\n\tint dir, err;\n\n\tif (net_eq(net, &init_net)) {\n\t\txfrm_dst_cache = KMEM_CACHE(xfrm_dst, SLAB_HWCACHE_ALIGN | SLAB_PANIC);\n\t\terr = rhashtable_init(&xfrm_policy_inexact_table,\n\t\t\t\t      &xfrm_pol_inexact_params);\n\t\tBUG_ON(err);\n\t}\n\n\thmask = 8 - 1;\n\tsz = (hmask+1) * sizeof(struct hlist_head);\n\n\tnet->xfrm.policy_byidx = xfrm_hash_alloc(sz);\n\tif (!net->xfrm.policy_byidx)\n\t\tgoto out_byidx;\n\tnet->xfrm.policy_idx_hmask = hmask;\n\n\tfor (dir = 0; dir < XFRM_POLICY_MAX; dir++) {\n\t\tstruct xfrm_policy_hash *htab;\n\n\t\tnet->xfrm.policy_count[dir] = 0;\n\t\tnet->xfrm.policy_count[XFRM_POLICY_MAX + dir] = 0;\n\n\t\thtab = &net->xfrm.policy_bydst[dir];\n\t\thtab->table = xfrm_hash_alloc(sz);\n\t\tif (!htab->table)\n\t\t\tgoto out_bydst;\n\t\thtab->hmask = hmask;\n\t\thtab->dbits4 = 32;\n\t\thtab->sbits4 = 32;\n\t\thtab->dbits6 = 128;\n\t\thtab->sbits6 = 128;\n\t}\n\tnet->xfrm.policy_hthresh.lbits4 = 32;\n\tnet->xfrm.policy_hthresh.rbits4 = 32;\n\tnet->xfrm.policy_hthresh.lbits6 = 128;\n\tnet->xfrm.policy_hthresh.rbits6 = 128;\n\n\tseqlock_init(&net->xfrm.policy_hthresh.lock);\n\n\tINIT_LIST_HEAD(&net->xfrm.policy_all);\n\tINIT_LIST_HEAD(&net->xfrm.inexact_bins);\n\tINIT_WORK(&net->xfrm.policy_hash_work, xfrm_hash_resize);\n\tINIT_WORK(&net->xfrm.policy_hthresh.work, xfrm_hash_rebuild);\n\treturn 0;\n\nout_bydst:\n\tfor (dir--; dir >= 0; dir--) {\n\t\tstruct xfrm_policy_hash *htab;\n\n\t\thtab = &net->xfrm.policy_bydst[dir];\n\t\txfrm_hash_free(htab->table, sz);\n\t}\n\txfrm_hash_free(net->xfrm.policy_byidx, sz);\nout_byidx:\n\treturn -ENOMEM;\n}\n\nstatic void xfrm_policy_fini(struct net *net)\n{\n\tstruct xfrm_pol_inexact_bin *b, *t;\n\tunsigned int sz;\n\tint dir;\n\n\tflush_work(&net->xfrm.policy_hash_work);\n#ifdef CONFIG_XFRM_SUB_POLICY\n\txfrm_policy_flush(net, XFRM_POLICY_TYPE_SUB, false);\n#endif\n\txfrm_policy_flush(net, XFRM_POLICY_TYPE_MAIN, false);\n\n\tWARN_ON(!list_empty(&net->xfrm.policy_all));\n\n\tfor (dir = 0; dir < XFRM_POLICY_MAX; dir++) {\n\t\tstruct xfrm_policy_hash *htab;\n\n\t\thtab = &net->xfrm.policy_bydst[dir];\n\t\tsz = (htab->hmask + 1) * sizeof(struct hlist_head);\n\t\tWARN_ON(!hlist_empty(htab->table));\n\t\txfrm_hash_free(htab->table, sz);\n\t}\n\n\tsz = (net->xfrm.policy_idx_hmask + 1) * sizeof(struct hlist_head);\n\tWARN_ON(!hlist_empty(net->xfrm.policy_byidx));\n\txfrm_hash_free(net->xfrm.policy_byidx, sz);\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\tlist_for_each_entry_safe(b, t, &net->xfrm.inexact_bins, inexact_bins)\n\t\t__xfrm_policy_inexact_prune_bin(b, true);\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n}\n\nstatic int __net_init xfrm_net_init(struct net *net)\n{\n\tint rv;\n\n\t/* Initialize the per-net locks here */\n\tspin_lock_init(&net->xfrm.xfrm_state_lock);\n\tspin_lock_init(&net->xfrm.xfrm_policy_lock);\n\tseqcount_spinlock_init(&net->xfrm.xfrm_policy_hash_generation, &net->xfrm.xfrm_policy_lock);\n\tmutex_init(&net->xfrm.xfrm_cfg_mutex);\n\tnet->xfrm.policy_default[XFRM_POLICY_IN] = XFRM_USERPOLICY_ACCEPT;\n\tnet->xfrm.policy_default[XFRM_POLICY_FWD] = XFRM_USERPOLICY_ACCEPT;\n\tnet->xfrm.policy_default[XFRM_POLICY_OUT] = XFRM_USERPOLICY_ACCEPT;\n\n\trv = xfrm_statistics_init(net);\n\tif (rv < 0)\n\t\tgoto out_statistics;\n\trv = xfrm_state_init(net);\n\tif (rv < 0)\n\t\tgoto out_state;\n\trv = xfrm_policy_init(net);\n\tif (rv < 0)\n\t\tgoto out_policy;\n\trv = xfrm_sysctl_init(net);\n\tif (rv < 0)\n\t\tgoto out_sysctl;\n\n\trv = xfrm_nat_keepalive_net_init(net);\n\tif (rv < 0)\n\t\tgoto out_nat_keepalive;\n\n\treturn 0;\n\nout_nat_keepalive:\n\txfrm_sysctl_fini(net);\nout_sysctl:\n\txfrm_policy_fini(net);\nout_policy:\n\txfrm_state_fini(net);\nout_state:\n\txfrm_statistics_fini(net);\nout_statistics:\n\treturn rv;\n}\n\nstatic void __net_exit xfrm_net_exit(struct net *net)\n{\n\txfrm_nat_keepalive_net_fini(net);\n\txfrm_sysctl_fini(net);\n\txfrm_policy_fini(net);\n\txfrm_state_fini(net);\n\txfrm_statistics_fini(net);\n}\n\nstatic struct pernet_operations __net_initdata xfrm_net_ops = {\n\t.init = xfrm_net_init,\n\t.exit = xfrm_net_exit,\n};\n\nstatic const struct flow_dissector_key xfrm_flow_dissector_keys[] = {\n\t{\n\t\t.key_id = FLOW_DISSECTOR_KEY_CONTROL,\n\t\t.offset = offsetof(struct xfrm_flow_keys, control),\n\t},\n\t{\n\t\t.key_id = FLOW_DISSECTOR_KEY_BASIC,\n\t\t.offset = offsetof(struct xfrm_flow_keys, basic),\n\t},\n\t{\n\t\t.key_id = FLOW_DISSECTOR_KEY_IPV4_ADDRS,\n\t\t.offset = offsetof(struct xfrm_flow_keys, addrs.ipv4),\n\t},\n\t{\n\t\t.key_id = FLOW_DISSECTOR_KEY_IPV6_ADDRS,\n\t\t.offset = offsetof(struct xfrm_flow_keys, addrs.ipv6),\n\t},\n\t{\n\t\t.key_id = FLOW_DISSECTOR_KEY_PORTS,\n\t\t.offset = offsetof(struct xfrm_flow_keys, ports),\n\t},\n\t{\n\t\t.key_id = FLOW_DISSECTOR_KEY_GRE_KEYID,\n\t\t.offset = offsetof(struct xfrm_flow_keys, gre),\n\t},\n\t{\n\t\t.key_id = FLOW_DISSECTOR_KEY_IP,\n\t\t.offset = offsetof(struct xfrm_flow_keys, ip),\n\t},\n\t{\n\t\t.key_id = FLOW_DISSECTOR_KEY_ICMP,\n\t\t.offset = offsetof(struct xfrm_flow_keys, icmp),\n\t},\n};\n\nvoid __init xfrm_init(void)\n{\n\tskb_flow_dissector_init(&xfrm_session_dissector,\n\t\t\t\txfrm_flow_dissector_keys,\n\t\t\t\tARRAY_SIZE(xfrm_flow_dissector_keys));\n\n\tregister_pernet_subsys(&xfrm_net_ops);\n\txfrm_dev_init();\n\txfrm_input_init();\n\n#ifdef CONFIG_XFRM_ESPINTCP\n\tespintcp_init();\n#endif\n\n\tregister_xfrm_state_bpf();\n\txfrm_nat_keepalive_init(AF_INET);\n}\n\n#ifdef CONFIG_AUDITSYSCALL\nstatic void xfrm_audit_common_policyinfo(struct xfrm_policy *xp,\n\t\t\t\t\t struct audit_buffer *audit_buf)\n{\n\tstruct xfrm_sec_ctx *ctx = xp->security;\n\tstruct xfrm_selector *sel = &xp->selector;\n\n\tif (ctx)\n\t\taudit_log_format(audit_buf, \" sec_alg=%u sec_doi=%u sec_obj=%s\",\n\t\t\t\t ctx->ctx_alg, ctx->ctx_doi, ctx->ctx_str);\n\n\tswitch (sel->family) {\n\tcase AF_INET:\n\t\taudit_log_format(audit_buf, \" src=%pI4\", &sel->saddr.a4);\n\t\tif (sel->prefixlen_s != 32)\n\t\t\taudit_log_format(audit_buf, \" src_prefixlen=%d\",\n\t\t\t\t\t sel->prefixlen_s);\n\t\taudit_log_format(audit_buf, \" dst=%pI4\", &sel->daddr.a4);\n\t\tif (sel->prefixlen_d != 32)\n\t\t\taudit_log_format(audit_buf, \" dst_prefixlen=%d\",\n\t\t\t\t\t sel->prefixlen_d);\n\t\tbreak;\n\tcase AF_INET6:\n\t\taudit_log_format(audit_buf, \" src=%pI6\", sel->saddr.a6);\n\t\tif (sel->prefixlen_s != 128)\n\t\t\taudit_log_format(audit_buf, \" src_prefixlen=%d\",\n\t\t\t\t\t sel->prefixlen_s);\n\t\taudit_log_format(audit_buf, \" dst=%pI6\", sel->daddr.a6);\n\t\tif (sel->prefixlen_d != 128)\n\t\t\taudit_log_format(audit_buf, \" dst_prefixlen=%d\",\n\t\t\t\t\t sel->prefixlen_d);\n\t\tbreak;\n\t}\n}\n\nvoid xfrm_audit_policy_add(struct xfrm_policy *xp, int result, bool task_valid)\n{\n\tstruct audit_buffer *audit_buf;\n\n\taudit_buf = xfrm_audit_start(\"SPD-add\");\n\tif (audit_buf == NULL)\n\t\treturn;\n\txfrm_audit_helper_usrinfo(task_valid, audit_buf);\n\taudit_log_format(audit_buf, \" res=%u\", result);\n\txfrm_audit_common_policyinfo(xp, audit_buf);\n\taudit_log_end(audit_buf);\n}\nEXPORT_SYMBOL_GPL(xfrm_audit_policy_add);\n\nvoid xfrm_audit_policy_delete(struct xfrm_policy *xp, int result,\n\t\t\t      bool task_valid)\n{\n\tstruct audit_buffer *audit_buf;\n\n\taudit_buf = xfrm_audit_start(\"SPD-delete\");\n\tif (audit_buf == NULL)\n\t\treturn;\n\txfrm_audit_helper_usrinfo(task_valid, audit_buf);\n\taudit_log_format(audit_buf, \" res=%u\", result);\n\txfrm_audit_common_policyinfo(xp, audit_buf);\n\taudit_log_end(audit_buf);\n}\nEXPORT_SYMBOL_GPL(xfrm_audit_policy_delete);\n#endif\n\n#ifdef CONFIG_XFRM_MIGRATE\nstatic struct xfrm_policy *xfrm_migrate_policy_find(const struct xfrm_selector *sel,\n\t\t\t\t\t\t    u8 dir, u8 type, struct net *net, u32 if_id)\n{\n\tstruct xfrm_policy *pol;\n\tstruct flowi fl;\n\n\tmemset(&fl, 0, sizeof(fl));\n\n\tfl.flowi_proto = sel->proto;\n\n\tswitch (sel->family) {\n\tcase AF_INET:\n\t\tfl.u.ip4.saddr = sel->saddr.a4;\n\t\tfl.u.ip4.daddr = sel->daddr.a4;\n\t\tif (sel->proto == IPSEC_ULPROTO_ANY)\n\t\t\tbreak;\n\t\tfl.u.flowi4_oif = sel->ifindex;\n\t\tfl.u.ip4.fl4_sport = sel->sport;\n\t\tfl.u.ip4.fl4_dport = sel->dport;\n\t\tbreak;\n\tcase AF_INET6:\n\t\tfl.u.ip6.saddr = sel->saddr.in6;\n\t\tfl.u.ip6.daddr = sel->daddr.in6;\n\t\tif (sel->proto == IPSEC_ULPROTO_ANY)\n\t\t\tbreak;\n\t\tfl.u.flowi6_oif = sel->ifindex;\n\t\tfl.u.ip6.fl4_sport = sel->sport;\n\t\tfl.u.ip6.fl4_dport = sel->dport;\n\t\tbreak;\n\tdefault:\n\t\treturn ERR_PTR(-EAFNOSUPPORT);\n\t}\n\n\trcu_read_lock();\n\n\tpol = xfrm_policy_lookup_bytype(net, type, &fl, sel->family, dir, if_id);\n\tif (IS_ERR_OR_NULL(pol))\n\t\tgoto out_unlock;\n\n\tif (!xfrm_pol_hold_rcu(pol))\n\t\tpol = NULL;\nout_unlock:\n\trcu_read_unlock();\n\treturn pol;\n}\n\nstatic int migrate_tmpl_match(const struct xfrm_migrate *m, const struct xfrm_tmpl *t)\n{\n\tint match = 0;\n\n\tif (t->mode == m->mode && t->id.proto == m->proto &&\n\t    (m->reqid == 0 || t->reqid == m->reqid)) {\n\t\tswitch (t->mode) {\n\t\tcase XFRM_MODE_TUNNEL:\n\t\tcase XFRM_MODE_BEET:\n\t\tcase XFRM_MODE_IPTFS:\n\t\t\tif (xfrm_addr_equal(&t->id.daddr, &m->old_daddr,\n\t\t\t\t\t    m->old_family) &&\n\t\t\t    xfrm_addr_equal(&t->saddr, &m->old_saddr,\n\t\t\t\t\t    m->old_family)) {\n\t\t\t\tmatch = 1;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase XFRM_MODE_TRANSPORT:\n\t\t\t/* in case of transport mode, template does not store\n\t\t\t   any IP addresses, hence we just compare mode and\n\t\t\t   protocol */\n\t\t\tmatch = 1;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn match;\n}\n\n/* update endpoint address(es) of template(s) */\nstatic int xfrm_policy_migrate(struct xfrm_policy *pol,\n\t\t\t       struct xfrm_migrate *m, int num_migrate,\n\t\t\t       struct netlink_ext_ack *extack)\n{\n\tstruct xfrm_migrate *mp;\n\tint i, j, n = 0;\n\n\twrite_lock_bh(&pol->lock);\n\tif (unlikely(pol->walk.dead)) {\n\t\t/* target policy has been deleted */\n\t\tNL_SET_ERR_MSG(extack, \"Target policy not found\");\n\t\twrite_unlock_bh(&pol->lock);\n\t\treturn -ENOENT;\n\t}\n\n\tfor (i = 0; i < pol->xfrm_nr; i++) {\n\t\tfor (j = 0, mp = m; j < num_migrate; j++, mp++) {\n\t\t\tif (!migrate_tmpl_match(mp, &pol->xfrm_vec[i]))\n\t\t\t\tcontinue;\n\t\t\tn++;\n\t\t\tif (pol->xfrm_vec[i].mode != XFRM_MODE_TUNNEL &&\n\t\t\t    pol->xfrm_vec[i].mode != XFRM_MODE_BEET &&\n\t\t\t    pol->xfrm_vec[i].mode != XFRM_MODE_IPTFS)\n\t\t\t\tcontinue;\n\t\t\t/* update endpoints */\n\t\t\tmemcpy(&pol->xfrm_vec[i].id.daddr, &mp->new_daddr,\n\t\t\t       sizeof(pol->xfrm_vec[i].id.daddr));\n\t\t\tmemcpy(&pol->xfrm_vec[i].saddr, &mp->new_saddr,\n\t\t\t       sizeof(pol->xfrm_vec[i].saddr));\n\t\t\tpol->xfrm_vec[i].encap_family = mp->new_family;\n\t\t\t/* flush bundles */\n\t\t\tatomic_inc(&pol->genid);\n\t\t}\n\t}\n\n\twrite_unlock_bh(&pol->lock);\n\n\tif (!n)\n\t\treturn -ENODATA;\n\n\treturn 0;\n}\n\nstatic int xfrm_migrate_check(const struct xfrm_migrate *m, int num_migrate,\n\t\t\t      struct netlink_ext_ack *extack)\n{\n\tint i, j;\n\n\tif (num_migrate < 1 || num_migrate > XFRM_MAX_DEPTH) {\n\t\tNL_SET_ERR_MSG(extack, \"Invalid number of SAs to migrate, must be 0 < num <= XFRM_MAX_DEPTH (6)\");\n\t\treturn -EINVAL;\n\t}\n\n\tfor (i = 0; i < num_migrate; i++) {\n\t\tif (xfrm_addr_any(&m[i].new_daddr, m[i].new_family) ||\n\t\t    xfrm_addr_any(&m[i].new_saddr, m[i].new_family)) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Addresses in the MIGRATE attribute's list cannot be null\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t/* check if there is any duplicated entry */\n\t\tfor (j = i + 1; j < num_migrate; j++) {\n\t\t\tif (!memcmp(&m[i].old_daddr, &m[j].old_daddr,\n\t\t\t\t    sizeof(m[i].old_daddr)) &&\n\t\t\t    !memcmp(&m[i].old_saddr, &m[j].old_saddr,\n\t\t\t\t    sizeof(m[i].old_saddr)) &&\n\t\t\t    m[i].proto == m[j].proto &&\n\t\t\t    m[i].mode == m[j].mode &&\n\t\t\t    m[i].reqid == m[j].reqid &&\n\t\t\t    m[i].old_family == m[j].old_family) {\n\t\t\t\tNL_SET_ERR_MSG(extack, \"Entries in the MIGRATE attribute's list must be unique\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nint xfrm_migrate(const struct xfrm_selector *sel, u8 dir, u8 type,\n\t\t struct xfrm_migrate *m, int num_migrate,\n\t\t struct xfrm_kmaddress *k, struct net *net,\n\t\t struct xfrm_encap_tmpl *encap, u32 if_id,\n\t\t struct netlink_ext_ack *extack, struct xfrm_user_offload *xuo)\n{\n\tint i, err, nx_cur = 0, nx_new = 0;\n\tstruct xfrm_policy *pol = NULL;\n\tstruct xfrm_state *x, *xc;\n\tstruct xfrm_state *x_cur[XFRM_MAX_DEPTH];\n\tstruct xfrm_state *x_new[XFRM_MAX_DEPTH];\n\tstruct xfrm_migrate *mp;\n\n\t/* Stage 0 - sanity checks */\n\terr = xfrm_migrate_check(m, num_migrate, extack);\n\tif (err < 0)\n\t\tgoto out;\n\n\tif (dir >= XFRM_POLICY_MAX) {\n\t\tNL_SET_ERR_MSG(extack, \"Invalid policy direction\");\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\t/* Stage 1 - find policy */\n\tpol = xfrm_migrate_policy_find(sel, dir, type, net, if_id);\n\tif (IS_ERR_OR_NULL(pol)) {\n\t\tNL_SET_ERR_MSG(extack, \"Target policy not found\");\n\t\terr = IS_ERR(pol) ? PTR_ERR(pol) : -ENOENT;\n\t\tgoto out;\n\t}\n\n\t/* Stage 2 - find and update state(s) */\n\tfor (i = 0, mp = m; i < num_migrate; i++, mp++) {\n\t\tif ((x = xfrm_migrate_state_find(mp, net, if_id))) {\n\t\t\tx_cur[nx_cur] = x;\n\t\t\tnx_cur++;\n\t\t\txc = xfrm_state_migrate(x, mp, encap, net, xuo, extack);\n\t\t\tif (xc) {\n\t\t\t\tx_new[nx_new] = xc;\n\t\t\t\tnx_new++;\n\t\t\t} else {\n\t\t\t\terr = -ENODATA;\n\t\t\t\tgoto restore_state;\n\t\t\t}\n\t\t}\n\t}\n\n\t/* Stage 3 - update policy */\n\terr = xfrm_policy_migrate(pol, m, num_migrate, extack);\n\tif (err < 0)\n\t\tgoto restore_state;\n\n\t/* Stage 4 - delete old state(s) */\n\tif (nx_cur) {\n\t\txfrm_states_put(x_cur, nx_cur);\n\t\txfrm_states_delete(x_cur, nx_cur);\n\t}\n\n\t/* Stage 5 - announce */\n\tkm_migrate(sel, dir, type, m, num_migrate, k, encap);\n\n\txfrm_pol_put(pol);\n\n\treturn 0;\nout:\n\treturn err;\n\nrestore_state:\n\tif (pol)\n\t\txfrm_pol_put(pol);\n\tif (nx_cur)\n\t\txfrm_states_put(x_cur, nx_cur);\n\tif (nx_new)\n\t\txfrm_states_delete(x_new, nx_new);\n\n\treturn err;\n}\nEXPORT_SYMBOL(xfrm_migrate);\n#endif"
            ]
        ],
        "explanation": "Explanation: The data-flow propagation path in question involves the variable `ret` in the function `xfrm_policy_bysel_ctx` at line 63. The function returns `ret` at line 67. The path is considered for a UAF (Use-After-Free) bug. \n\nIn this function, `ret` is initialized to `NULL` at line 7. It is set to `pol` at line 59 if `pol` is non-NULL. The function has several early return points (lines 21, 28) that return `NULL`, which would not lead to a UAF. \n\nAt line 63, there is a condition: `if (ret && delete)`. If `ret` is non-NULL and `delete` is true, `xfrm_policy_kill(ret)` is called at line 64. This function likely frees the policy. However, after this, at line 67, `ret` is returned. If `delete` is true and `ret` was non-NULL, this would return a pointer that has just been freed, causing a UAF.\n\nBut note: The condition at line 63 checks both `ret` and `delete`. If `delete` is false, `ret` is not freed and is returned safely. If `ret` is NULL, it is returned without being freed. The UAF only occurs if both `ret` is non-NULL and `delete` is true. \n\nTherefore, the path is reachable and buggy when `ret` is non-NULL and `delete` is true, as it returns a freed pointer.\n\nAnswer: Yes",
        "is_human_confirmed_true": "False",
        "reason": "the LLM mess up program points and sink points. The logic of analysis is correct, while due to limited context, it can not find that all caller of this function have null-check of its return value."
    },
    "1": {
        "bug_type": "UAF",
        "buggy_value": "((delete)\n\t\txfrm_policy_inexact_prune_bin(bin), /data/jiangjiajun/LLM4Security/data/projects/linux/net/xfrm/xfrm_policy.c, 1714, -1), ValueLabel.SRC)",
        "relevant_functions": [
            [
                "/data/jiangjiajun/LLM4Security/data/projects/linux/net/xfrm/xfrm_policy.c"
            ],
            [
                "xfrm_policy_bysel_ctx"
            ],
            [
                "struct xfrm_policy *\nxfrm_policy_bysel_ctx(struct net *net, const struct xfrm_mark *mark, u32 if_id,\n\t\t      u8 type, int dir, struct xfrm_selector *sel,\n\t\t      struct xfrm_sec_ctx *ctx, int delete, int *err)\n{\n\tstruct xfrm_pol_inexact_bin *bin = NULL;\n\tstruct xfrm_policy *pol, *ret = NULL;\n\tstruct hlist_head *chain;\n\n\t*err = 0;\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\tchain = policy_hash_bysel(net, sel, sel->family, dir);\n\tif (!chain) {\n\t\tstruct xfrm_pol_inexact_candidates cand;\n\t\tint i;\n\n\t\tbin = xfrm_policy_inexact_lookup(net, type,\n\t\t\t\t\t\t sel->family, dir, if_id);\n\t\tif (!bin) {\n\t\t\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (!xfrm_policy_find_inexact_candidates(&cand, bin,\n\t\t\t\t\t\t\t &sel->saddr,\n\t\t\t\t\t\t\t &sel->daddr)) {\n\t\t\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tpol = NULL;\n\t\tfor (i = 0; i < ARRAY_SIZE(cand.res); i++) {\n\t\t\tstruct xfrm_policy *tmp;\n\n\t\t\ttmp = __xfrm_policy_bysel_ctx(cand.res[i], mark,\n\t\t\t\t\t\t      if_id, type, dir,\n\t\t\t\t\t\t      sel, ctx);\n\t\t\tif (!tmp)\n\t\t\t\tcontinue;\n\n\t\t\tif (!pol || tmp->pos < pol->pos)\n\t\t\t\tpol = tmp;\n\t\t}\n\t} else {\n\t\tpol = __xfrm_policy_bysel_ctx(chain, mark, if_id, type, dir,\n\t\t\t\t\t      sel, ctx);\n\t}\n\n\tif (pol) {\n\t\txfrm_pol_hold(pol);\n\t\tif (delete) {\n\t\t\t*err = security_xfrm_policy_delete(pol->security);\n\t\t\tif (*err) {\n\t\t\t\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\t\t\t\treturn pol;\n\t\t\t}\n\t\t\t__xfrm_policy_unlink(pol, dir);\n\t\t}\n\t\tret = pol;\n\t}\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\n\tif (ret && delete)\n\t\txfrm_policy_kill(ret);\n\tif (bin && delete)\n\t\txfrm_policy_inexact_prune_bin(bin);\n\treturn ret;\n}\nEXPORT_SYMBOL(xfrm_policy_bysel_ctx);\n\nstruct xfrm_policy *\nxfrm_policy_byid(struct net *net, const struct xfrm_mark *mark, u32 if_id,\n\t\t u8 type, int dir, u32 id, int delete, int *err)\n{\n\tstruct xfrm_policy *pol, *ret;\n\tstruct hlist_head *chain;\n\n\t*err = -ENOENT;\n\tif (xfrm_policy_id2dir(id) != dir)\n\t\treturn NULL;\n\n\t*err = 0;\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\tchain = net->xfrm.policy_byidx + idx_hash(net, id);\n\tret = NULL;\n\thlist_for_each_entry(pol, chain, byidx) {\n\t\tif (pol->type == type && pol->index == id &&\n\t\t    pol->if_id == if_id && xfrm_policy_mark_match(mark, pol)) {\n\t\t\txfrm_pol_hold(pol);\n\t\t\tif (delete) {\n\t\t\t\t*err = security_xfrm_policy_delete(\n\t\t\t\t\t\t\t\tpol->security);\n\t\t\t\tif (*err) {\n\t\t\t\t\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\t\t\t\t\treturn pol;\n\t\t\t\t}\n\t\t\t\t__xfrm_policy_unlink(pol, dir);\n\t\t\t}\n\t\t\tret = pol;\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\n\tif (ret && delete)\n\t\txfrm_policy_kill(ret);\n\treturn ret;\n}\nEXPORT_SYMBOL(xfrm_policy_byid);\n\n#ifdef CONFIG_SECURITY_NETWORK_XFRM\nstatic inline int\nxfrm_policy_flush_secctx_check(struct net *net, u8 type, bool task_valid)\n{\n\tstruct xfrm_policy *pol;\n\tint err = 0;\n\n\tlist_for_each_entry(pol, &net->xfrm.policy_all, walk.all) {\n\t\tif (pol->walk.dead ||\n\t\t    xfrm_policy_id2dir(pol->index) >= XFRM_POLICY_MAX ||\n\t\t    pol->type != type)\n\t\t\tcontinue;\n\n\t\terr = security_xfrm_policy_delete(pol->security);\n\t\tif (err) {\n\t\t\txfrm_audit_policy_delete(pol, 0, task_valid);\n\t\t\treturn err;\n\t\t}\n\t}\n\treturn err;\n}\n\nstatic inline int xfrm_dev_policy_flush_secctx_check(struct net *net,\n\t\t\t\t\t\t     struct net_device *dev,\n\t\t\t\t\t\t     bool task_valid)\n{\n\tstruct xfrm_policy *pol;\n\tint err = 0;\n\n\tlist_for_each_entry(pol, &net->xfrm.policy_all, walk.all) {\n\t\tif (pol->walk.dead ||\n\t\t    xfrm_policy_id2dir(pol->index) >= XFRM_POLICY_MAX ||\n\t\t    pol->xdo.dev != dev)\n\t\t\tcontinue;\n\n\t\terr = security_xfrm_policy_delete(pol->security);\n\t\tif (err) {\n\t\t\txfrm_audit_policy_delete(pol, 0, task_valid);\n\t\t\treturn err;\n\t\t}\n\t}\n\treturn err;\n}\n#else\nstatic inline int\nxfrm_policy_flush_secctx_check(struct net *net, u8 type, bool task_valid)\n{\n\treturn 0;\n}\n\nstatic inline int xfrm_dev_policy_flush_secctx_check(struct net *net,\n\t\t\t\t\t\t     struct net_device *dev,\n\t\t\t\t\t\t     bool task_valid)\n{\n\treturn 0;\n}\n#endif\n\nint xfrm_policy_flush(struct net *net, u8 type, bool task_valid)\n{\n\tint dir, err = 0, cnt = 0;\n\tstruct xfrm_policy *pol;\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\n\terr = xfrm_policy_flush_secctx_check(net, type, task_valid);\n\tif (err)\n\t\tgoto out;\n\nagain:\n\tlist_for_each_entry(pol, &net->xfrm.policy_all, walk.all) {\n\t\tif (pol->walk.dead)\n\t\t\tcontinue;\n\n\t\tdir = xfrm_policy_id2dir(pol->index);\n\t\tif (dir >= XFRM_POLICY_MAX ||\n\t\t    pol->type != type)\n\t\t\tcontinue;\n\n\t\t__xfrm_policy_unlink(pol, dir);\n\t\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\t\tcnt++;\n\t\txfrm_audit_policy_delete(pol, 1, task_valid);\n\t\txfrm_policy_kill(pol);\n\t\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\t\tgoto again;\n\t}\n\tif (cnt)\n\t\t__xfrm_policy_inexact_flush(net);\n\telse\n\t\terr = -ESRCH;\nout:\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\treturn err;\n}\nEXPORT_SYMBOL(xfrm_policy_flush);\n\nint xfrm_dev_policy_flush(struct net *net, struct net_device *dev,\n\t\t\t  bool task_valid)\n{\n\tint dir, err = 0, cnt = 0;\n\tstruct xfrm_policy *pol;\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\n\terr = xfrm_dev_policy_flush_secctx_check(net, dev, task_valid);\n\tif (err)\n\t\tgoto out;\n\nagain:\n\tlist_for_each_entry(pol, &net->xfrm.policy_all, walk.all) {\n\t\tif (pol->walk.dead)\n\t\t\tcontinue;\n\n\t\tdir = xfrm_policy_id2dir(pol->index);\n\t\tif (dir >= XFRM_POLICY_MAX ||\n\t\t    pol->xdo.dev != dev)\n\t\t\tcontinue;\n\n\t\t__xfrm_policy_unlink(pol, dir);\n\t\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\t\tcnt++;\n\t\txfrm_audit_policy_delete(pol, 1, task_valid);\n\t\txfrm_policy_kill(pol);\n\t\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\t\tgoto again;\n\t}\n\tif (cnt)\n\t\t__xfrm_policy_inexact_flush(net);\n\telse\n\t\terr = -ESRCH;\nout:\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\treturn err;\n}\nEXPORT_SYMBOL(xfrm_dev_policy_flush);\n\nint xfrm_policy_walk(struct net *net, struct xfrm_policy_walk *walk,\n\t\t     int (*func)(struct xfrm_policy *, int, int, void*),\n\t\t     void *data)\n{\n\tstruct xfrm_policy *pol;\n\tstruct xfrm_policy_walk_entry *x;\n\tint error = 0;\n\n\tif (walk->type >= XFRM_POLICY_TYPE_MAX &&\n\t    walk->type != XFRM_POLICY_TYPE_ANY)\n\t\treturn -EINVAL;\n\n\tif (list_empty(&walk->walk.all) && walk->seq != 0)\n\t\treturn 0;\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\tif (list_empty(&walk->walk.all))\n\t\tx = list_first_entry(&net->xfrm.policy_all, struct xfrm_policy_walk_entry, all);\n\telse\n\t\tx = list_first_entry(&walk->walk.all,\n\t\t\t\t     struct xfrm_policy_walk_entry, all);\n\n\tlist_for_each_entry_from(x, &net->xfrm.policy_all, all) {\n\t\tif (x->dead)\n\t\t\tcontinue;\n\t\tpol = container_of(x, struct xfrm_policy, walk);\n\t\tif (walk->type != XFRM_POLICY_TYPE_ANY &&\n\t\t    walk->type != pol->type)\n\t\t\tcontinue;\n\t\terror = func(pol, xfrm_policy_id2dir(pol->index),\n\t\t\t     walk->seq, data);\n\t\tif (error) {\n\t\t\tlist_move_tail(&walk->walk.all, &x->all);\n\t\t\tgoto out;\n\t\t}\n\t\twalk->seq++;\n\t}\n\tif (walk->seq == 0) {\n\t\terror = -ENOENT;\n\t\tgoto out;\n\t}\n\tlist_del_init(&walk->walk.all);\nout:\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\treturn error;\n}\nEXPORT_SYMBOL(xfrm_policy_walk);\n\nvoid xfrm_policy_walk_init(struct xfrm_policy_walk *walk, u8 type)\n{\n\tINIT_LIST_HEAD(&walk->walk.all);\n\twalk->walk.dead = 1;\n\twalk->type = type;\n\twalk->seq = 0;\n}\nEXPORT_SYMBOL(xfrm_policy_walk_init);\n\nvoid xfrm_policy_walk_done(struct xfrm_policy_walk *walk, struct net *net)\n{\n\tif (list_empty(&walk->walk.all))\n\t\treturn;\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock); /*FIXME where is net? */\n\tlist_del(&walk->walk.all);\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n}\nEXPORT_SYMBOL(xfrm_policy_walk_done);\n\n/*\n * Find policy to apply to this flow.\n *\n * Returns 0 if policy found, else an -errno.\n */\nstatic int xfrm_policy_match(const struct xfrm_policy *pol,\n\t\t\t     const struct flowi *fl,\n\t\t\t     u8 type, u16 family, u32 if_id)\n{\n\tconst struct xfrm_selector *sel = &pol->selector;\n\tint ret = -ESRCH;\n\tbool match;\n\n\tif (pol->family != family ||\n\t    pol->if_id != if_id ||\n\t    (fl->flowi_mark & pol->mark.m) != pol->mark.v ||\n\t    pol->type != type)\n\t\treturn ret;\n\n\tmatch = xfrm_selector_match(sel, fl, family);\n\tif (match)\n\t\tret = security_xfrm_policy_lookup(pol->security, fl->flowi_secid);\n\treturn ret;\n}\n\nstatic struct xfrm_pol_inexact_node *\nxfrm_policy_lookup_inexact_addr(const struct rb_root *r,\n\t\t\t\tseqcount_spinlock_t *count,\n\t\t\t\tconst xfrm_address_t *addr, u16 family)\n{\n\tconst struct rb_node *parent;\n\tint seq;\n\nagain:\n\tseq = read_seqcount_begin(count);\n\n\tparent = rcu_dereference_raw(r->rb_node);\n\twhile (parent) {\n\t\tstruct xfrm_pol_inexact_node *node;\n\t\tint delta;\n\n\t\tnode = rb_entry(parent, struct xfrm_pol_inexact_node, node);\n\n\t\tdelta = xfrm_policy_addr_delta(addr, &node->addr,\n\t\t\t\t\t       node->prefixlen, family);\n\t\tif (delta < 0) {\n\t\t\tparent = rcu_dereference_raw(parent->rb_left);\n\t\t\tcontinue;\n\t\t} else if (delta > 0) {\n\t\t\tparent = rcu_dereference_raw(parent->rb_right);\n\t\t\tcontinue;\n\t\t}\n\n\t\treturn node;\n\t}\n\n\tif (read_seqcount_retry(count, seq))\n\t\tgoto again;\n\n\treturn NULL;\n}\n\nstatic bool\nxfrm_policy_find_inexact_candidates(struct xfrm_pol_inexact_candidates *cand,\n\t\t\t\t    struct xfrm_pol_inexact_bin *b,\n\t\t\t\t    const xfrm_address_t *saddr,\n\t\t\t\t    const xfrm_address_t *daddr)\n{\n\tstruct xfrm_pol_inexact_node *n;\n\tu16 family;\n\n\tif (!b)\n\t\treturn false;\n\n\tfamily = b->k.family;\n\tmemset(cand, 0, sizeof(*cand));\n\tcand->res[XFRM_POL_CAND_ANY] = &b->hhead;\n\n\tn = xfrm_policy_lookup_inexact_addr(&b->root_d, &b->count, daddr,\n\t\t\t\t\t    family);\n\tif (n) {\n\t\tcand->res[XFRM_POL_CAND_DADDR] = &n->hhead;\n\t\tn = xfrm_policy_lookup_inexact_addr(&n->root, &b->count, saddr,\n\t\t\t\t\t\t    family);\n\t\tif (n)\n\t\t\tcand->res[XFRM_POL_CAND_BOTH] = &n->hhead;\n\t}\n\n\tn = xfrm_policy_lookup_inexact_addr(&b->root_s, &b->count, saddr,\n\t\t\t\t\t    family);\n\tif (n)\n\t\tcand->res[XFRM_POL_CAND_SADDR] = &n->hhead;\n\n\treturn true;\n}\n\nstatic struct xfrm_pol_inexact_bin *\nxfrm_policy_inexact_lookup_rcu(struct net *net, u8 type, u16 family,\n\t\t\t       u8 dir, u32 if_id)\n{\n\tstruct xfrm_pol_inexact_key k = {\n\t\t.family = family,\n\t\t.type = type,\n\t\t.dir = dir,\n\t\t.if_id = if_id,\n\t};\n\n\twrite_pnet(&k.net, net);\n\n\treturn rhashtable_lookup(&xfrm_policy_inexact_table, &k,\n\t\t\t\t xfrm_pol_inexact_params);\n}\n\nstatic struct xfrm_pol_inexact_bin *\nxfrm_policy_inexact_lookup(struct net *net, u8 type, u16 family,\n\t\t\t   u8 dir, u32 if_id)\n{\n\tstruct xfrm_pol_inexact_bin *bin;\n\n\tlockdep_assert_held(&net->xfrm.xfrm_policy_lock);\n\n\trcu_read_lock();\n\tbin = xfrm_policy_inexact_lookup_rcu(net, type, family, dir, if_id);\n\trcu_read_unlock();\n\n\treturn bin;\n}\n\nstatic struct xfrm_policy *\n__xfrm_policy_eval_candidates(struct hlist_head *chain,\n\t\t\t      struct xfrm_policy *prefer,\n\t\t\t      const struct flowi *fl,\n\t\t\t      u8 type, u16 family, u32 if_id)\n{\n\tu32 priority = prefer ? prefer->priority : ~0u;\n\tstruct xfrm_policy *pol;\n\n\tif (!chain)\n\t\treturn NULL;\n\n\thlist_for_each_entry_rcu(pol, chain, bydst) {\n\t\tint err;\n\n\t\tif (pol->priority > priority)\n\t\t\tbreak;\n\n\t\terr = xfrm_policy_match(pol, fl, type, family, if_id);\n\t\tif (err) {\n\t\t\tif (err != -ESRCH)\n\t\t\t\treturn ERR_PTR(err);\n\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (prefer) {\n\t\t\t/* matches.  Is it older than *prefer? */\n\t\t\tif (pol->priority == priority &&\n\t\t\t    prefer->pos < pol->pos)\n\t\t\t\treturn prefer;\n\t\t}\n\n\t\treturn pol;\n\t}\n\n\treturn NULL;\n}\n\nstatic struct xfrm_policy *\nxfrm_policy_eval_candidates(struct xfrm_pol_inexact_candidates *cand,\n\t\t\t    struct xfrm_policy *prefer,\n\t\t\t    const struct flowi *fl,\n\t\t\t    u8 type, u16 family, u32 if_id)\n{\n\tstruct xfrm_policy *tmp;\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(cand->res); i++) {\n\t\ttmp = __xfrm_policy_eval_candidates(cand->res[i],\n\t\t\t\t\t\t    prefer,\n\t\t\t\t\t\t    fl, type, family, if_id);\n\t\tif (!tmp)\n\t\t\tcontinue;\n\n\t\tif (IS_ERR(tmp))\n\t\t\treturn tmp;\n\t\tprefer = tmp;\n\t}\n\n\treturn prefer;\n}\n\nstatic struct xfrm_policy *xfrm_policy_lookup_bytype(struct net *net, u8 type,\n\t\t\t\t\t\t     const struct flowi *fl,\n\t\t\t\t\t\t     u16 family, u8 dir,\n\t\t\t\t\t\t     u32 if_id)\n{\n\tstruct xfrm_pol_inexact_candidates cand;\n\tconst xfrm_address_t *daddr, *saddr;\n\tstruct xfrm_pol_inexact_bin *bin;\n\tstruct xfrm_policy *pol, *ret;\n\tstruct hlist_head *chain;\n\tunsigned int sequence;\n\tint err;\n\n\tdaddr = xfrm_flowi_daddr(fl, family);\n\tsaddr = xfrm_flowi_saddr(fl, family);\n\tif (unlikely(!daddr || !saddr))\n\t\treturn NULL;\n\n\trcu_read_lock();\n retry:\n\tdo {\n\t\tsequence = read_seqcount_begin(&net->xfrm.xfrm_policy_hash_generation);\n\t\tchain = policy_hash_direct(net, daddr, saddr, family, dir);\n\t} while (read_seqcount_retry(&net->xfrm.xfrm_policy_hash_generation, sequence));\n\n\tret = NULL;\n\thlist_for_each_entry_rcu(pol, chain, bydst) {\n\t\terr = xfrm_policy_match(pol, fl, type, family, if_id);\n\t\tif (err) {\n\t\t\tif (err == -ESRCH)\n\t\t\t\tcontinue;\n\t\t\telse {\n\t\t\t\tret = ERR_PTR(err);\n\t\t\t\tgoto fail;\n\t\t\t}\n\t\t} else {\n\t\t\tret = pol;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (ret && ret->xdo.type == XFRM_DEV_OFFLOAD_PACKET)\n\t\tgoto skip_inexact;\n\n\tbin = xfrm_policy_inexact_lookup_rcu(net, type, family, dir, if_id);\n\tif (!bin || !xfrm_policy_find_inexact_candidates(&cand, bin, saddr,\n\t\t\t\t\t\t\t daddr))\n\t\tgoto skip_inexact;\n\n\tpol = xfrm_policy_eval_candidates(&cand, ret, fl, type,\n\t\t\t\t\t  family, if_id);\n\tif (pol) {\n\t\tret = pol;\n\t\tif (IS_ERR(pol))\n\t\t\tgoto fail;\n\t}\n\nskip_inexact:\n\tif (read_seqcount_retry(&net->xfrm.xfrm_policy_hash_generation, sequence))\n\t\tgoto retry;\n\n\tif (ret && !xfrm_pol_hold_rcu(ret))\n\t\tgoto retry;\nfail:\n\trcu_read_unlock();\n\n\treturn ret;\n}\n\nstatic struct xfrm_policy *xfrm_policy_lookup(struct net *net,\n\t\t\t\t\t      const struct flowi *fl,\n\t\t\t\t\t      u16 family, u8 dir, u32 if_id)\n{\n#ifdef CONFIG_XFRM_SUB_POLICY\n\tstruct xfrm_policy *pol;\n\n\tpol = xfrm_policy_lookup_bytype(net, XFRM_POLICY_TYPE_SUB, fl, family,\n\t\t\t\t\tdir, if_id);\n\tif (pol != NULL)\n\t\treturn pol;\n#endif\n\treturn xfrm_policy_lookup_bytype(net, XFRM_POLICY_TYPE_MAIN, fl, family,\n\t\t\t\t\t dir, if_id);\n}\n\nstatic struct xfrm_policy *xfrm_sk_policy_lookup(const struct sock *sk, int dir,\n\t\t\t\t\t\t const struct flowi *fl,\n\t\t\t\t\t\t u16 family, u32 if_id)\n{\n\tstruct xfrm_policy *pol;\n\n\trcu_read_lock();\n again:\n\tpol = rcu_dereference(sk->sk_policy[dir]);\n\tif (pol != NULL) {\n\t\tbool match;\n\t\tint err = 0;\n\n\t\tif (pol->family != family) {\n\t\t\tpol = NULL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tmatch = xfrm_selector_match(&pol->selector, fl, family);\n\t\tif (match) {\n\t\t\tif ((READ_ONCE(sk->sk_mark) & pol->mark.m) != pol->mark.v ||\n\t\t\t    pol->if_id != if_id) {\n\t\t\t\tpol = NULL;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\terr = security_xfrm_policy_lookup(pol->security,\n\t\t\t\t\t\t      fl->flowi_secid);\n\t\t\tif (!err) {\n\t\t\t\tif (!xfrm_pol_hold_rcu(pol))\n\t\t\t\t\tgoto again;\n\t\t\t} else if (err == -ESRCH) {\n\t\t\t\tpol = NULL;\n\t\t\t} else {\n\t\t\t\tpol = ERR_PTR(err);\n\t\t\t}\n\t\t} else\n\t\t\tpol = NULL;\n\t}\nout:\n\trcu_read_unlock();\n\treturn pol;\n}\n\nstatic u32 xfrm_gen_pos_slow(struct net *net)\n{\n\tstruct xfrm_policy *policy;\n\tu32 i = 0;\n\n\t/* oldest entry is last in list */\n\tlist_for_each_entry_reverse(policy, &net->xfrm.policy_all, walk.all) {\n\t\tif (!xfrm_policy_is_dead_or_sk(policy))\n\t\t\tpolicy->pos = ++i;\n\t}\n\n\treturn i;\n}\n\nstatic u32 xfrm_gen_pos(struct net *net)\n{\n\tconst struct xfrm_policy *policy;\n\tu32 i = 0;\n\n\t/* most recently added policy is at the head of the list */\n\tlist_for_each_entry(policy, &net->xfrm.policy_all, walk.all) {\n\t\tif (xfrm_policy_is_dead_or_sk(policy))\n\t\t\tcontinue;\n\n\t\tif (policy->pos == UINT_MAX)\n\t\t\treturn xfrm_gen_pos_slow(net);\n\n\t\ti = policy->pos + 1;\n\t\tbreak;\n\t}\n\n\treturn i;\n}\n\nstatic void __xfrm_policy_link(struct xfrm_policy *pol, int dir)\n{\n\tstruct net *net = xp_net(pol);\n\n\tswitch (dir) {\n\tcase XFRM_POLICY_IN:\n\tcase XFRM_POLICY_FWD:\n\tcase XFRM_POLICY_OUT:\n\t\tpol->pos = xfrm_gen_pos(net);\n\t\tbreak;\n\t}\n\n\tlist_add(&pol->walk.all, &net->xfrm.policy_all);\n\tnet->xfrm.policy_count[dir]++;\n\txfrm_pol_hold(pol);\n}\n\nstatic struct xfrm_policy *__xfrm_policy_unlink(struct xfrm_policy *pol,\n\t\t\t\t\t\tint dir)\n{\n\tstruct net *net = xp_net(pol);\n\n\tif (list_empty(&pol->walk.all))\n\t\treturn NULL;\n\n\t/* Socket policies are not hashed. */\n\tif (!hlist_unhashed(&pol->bydst)) {\n\t\thlist_del_rcu(&pol->bydst);\n\t\thlist_del(&pol->byidx);\n\t}\n\n\tlist_del_init(&pol->walk.all);\n\tnet->xfrm.policy_count[dir]--;\n\n\treturn pol;\n}\n\nstatic void xfrm_sk_policy_link(struct xfrm_policy *pol, int dir)\n{\n\t__xfrm_policy_link(pol, XFRM_POLICY_MAX + dir);\n}\n\nstatic void xfrm_sk_policy_unlink(struct xfrm_policy *pol, int dir)\n{\n\t__xfrm_policy_unlink(pol, XFRM_POLICY_MAX + dir);\n}\n\nint xfrm_policy_delete(struct xfrm_policy *pol, int dir)\n{\n\tstruct net *net = xp_net(pol);\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\tpol = __xfrm_policy_unlink(pol, dir);\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\tif (pol) {\n\t\txfrm_policy_kill(pol);\n\t\treturn 0;\n\t}\n\treturn -ENOENT;\n}\nEXPORT_SYMBOL(xfrm_policy_delete);\n\nint xfrm_sk_policy_insert(struct sock *sk, int dir, struct xfrm_policy *pol)\n{\n\tstruct net *net = sock_net(sk);\n\tstruct xfrm_policy *old_pol;\n\n#ifdef CONFIG_XFRM_SUB_POLICY\n\tif (pol && pol->type != XFRM_POLICY_TYPE_MAIN)\n\t\treturn -EINVAL;\n#endif\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\told_pol = rcu_dereference_protected(sk->sk_policy[dir],\n\t\t\t\tlockdep_is_held(&net->xfrm.xfrm_policy_lock));\n\tif (pol) {\n\t\tpol->curlft.add_time = ktime_get_real_seconds();\n\t\tpol->index = xfrm_gen_index(net, XFRM_POLICY_MAX+dir, 0);\n\t\txfrm_sk_policy_link(pol, dir);\n\t}\n\trcu_assign_pointer(sk->sk_policy[dir], pol);\n\tif (old_pol) {\n\t\tif (pol)\n\t\t\txfrm_policy_requeue(old_pol, pol);\n\n\t\t/* Unlinking succeeds always. This is the only function\n\t\t * allowed to delete or replace socket policy.\n\t\t */\n\t\txfrm_sk_policy_unlink(old_pol, dir);\n\t}\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\n\tif (old_pol) {\n\t\txfrm_policy_kill(old_pol);\n\t}\n\treturn 0;\n}\n\nstatic struct xfrm_policy *clone_policy(const struct xfrm_policy *old, int dir)\n{\n\tstruct xfrm_policy *newp = xfrm_policy_alloc(xp_net(old), GFP_ATOMIC);\n\tstruct net *net = xp_net(old);\n\n\tif (newp) {\n\t\tnewp->selector = old->selector;\n\t\tif (security_xfrm_policy_clone(old->security,\n\t\t\t\t\t       &newp->security)) {\n\t\t\tkfree(newp);\n\t\t\treturn NULL;  /* ENOMEM */\n\t\t}\n\t\tnewp->lft = old->lft;\n\t\tnewp->curlft = old->curlft;\n\t\tnewp->mark = old->mark;\n\t\tnewp->if_id = old->if_id;\n\t\tnewp->action = old->action;\n\t\tnewp->flags = old->flags;\n\t\tnewp->xfrm_nr = old->xfrm_nr;\n\t\tnewp->index = old->index;\n\t\tnewp->type = old->type;\n\t\tnewp->family = old->family;\n\t\tmemcpy(newp->xfrm_vec, old->xfrm_vec,\n\t\t       newp->xfrm_nr*sizeof(struct xfrm_tmpl));\n\t\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\t\txfrm_sk_policy_link(newp, dir);\n\t\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n\t\txfrm_pol_put(newp);\n\t}\n\treturn newp;\n}\n\nint __xfrm_sk_clone_policy(struct sock *sk, const struct sock *osk)\n{\n\tconst struct xfrm_policy *p;\n\tstruct xfrm_policy *np;\n\tint i, ret = 0;\n\n\trcu_read_lock();\n\tfor (i = 0; i < 2; i++) {\n\t\tp = rcu_dereference(osk->sk_policy[i]);\n\t\tif (p) {\n\t\t\tnp = clone_policy(p, i);\n\t\t\tif (unlikely(!np)) {\n\t\t\t\tret = -ENOMEM;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\trcu_assign_pointer(sk->sk_policy[i], np);\n\t\t}\n\t}\n\trcu_read_unlock();\n\treturn ret;\n}\n\nstatic int\nxfrm_get_saddr(unsigned short family, xfrm_address_t *saddr,\n\t       const struct xfrm_dst_lookup_params *params)\n{\n\tint err;\n\tconst struct xfrm_policy_afinfo *afinfo = xfrm_policy_get_afinfo(family);\n\n\tif (unlikely(afinfo == NULL))\n\t\treturn -EINVAL;\n\terr = afinfo->get_saddr(saddr, params);\n\trcu_read_unlock();\n\treturn err;\n}\n\n/* Resolve list of templates for the flow, given policy. */\n\nstatic int\nxfrm_tmpl_resolve_one(struct xfrm_policy *policy, const struct flowi *fl,\n\t\t      struct xfrm_state **xfrm, unsigned short family)\n{\n\tstruct net *net = xp_net(policy);\n\tint nx;\n\tint i, error;\n\txfrm_address_t *daddr = xfrm_flowi_daddr(fl, family);\n\txfrm_address_t *saddr = xfrm_flowi_saddr(fl, family);\n\txfrm_address_t tmp;\n\n\tfor (nx = 0, i = 0; i < policy->xfrm_nr; i++) {\n\t\tstruct xfrm_state *x;\n\t\txfrm_address_t *remote = daddr;\n\t\txfrm_address_t *local  = saddr;\n\t\tstruct xfrm_tmpl *tmpl = &policy->xfrm_vec[i];\n\n\t\tif (tmpl->mode == XFRM_MODE_TUNNEL ||\n\t\t    tmpl->mode == XFRM_MODE_IPTFS ||\n\t\t    tmpl->mode == XFRM_MODE_BEET) {\n\t\t\tremote = &tmpl->id.daddr;\n\t\t\tlocal = &tmpl->saddr;\n\t\t\tif (xfrm_addr_any(local, tmpl->encap_family)) {\n\t\t\t\tstruct xfrm_dst_lookup_params params;\n\n\t\t\t\tmemset(&params, 0, sizeof(params));\n\t\t\t\tparams.net = net;\n\t\t\t\tparams.oif = fl->flowi_oif;\n\t\t\t\tparams.daddr = remote;\n\t\t\t\terror = xfrm_get_saddr(tmpl->encap_family, &tmp,\n\t\t\t\t\t\t       &params);\n\t\t\t\tif (error)\n\t\t\t\t\tgoto fail;\n\t\t\t\tlocal = &tmp;\n\t\t\t}\n\t\t}\n\n\t\tx = xfrm_state_find(remote, local, fl, tmpl, policy, &error,\n\t\t\t\t    family, policy->if_id);\n\t\tif (x && x->dir && x->dir != XFRM_SA_DIR_OUT) {\n\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMOUTSTATEDIRERROR);\n\t\t\txfrm_state_put(x);\n\t\t\terror = -EINVAL;\n\t\t\tgoto fail;\n\t\t}\n\n\t\tif (x && x->km.state == XFRM_STATE_VALID) {\n\t\t\txfrm[nx++] = x;\n\t\t\tdaddr = remote;\n\t\t\tsaddr = local;\n\t\t\tcontinue;\n\t\t}\n\t\tif (x) {\n\t\t\terror = (x->km.state == XFRM_STATE_ERROR ?\n\t\t\t\t -EINVAL : -EAGAIN);\n\t\t\txfrm_state_put(x);\n\t\t} else if (error == -ESRCH) {\n\t\t\terror = -EAGAIN;\n\t\t}\n\n\t\tif (!tmpl->optional)\n\t\t\tgoto fail;\n\t}\n\treturn nx;\n\nfail:\n\tfor (nx--; nx >= 0; nx--)\n\t\txfrm_state_put(xfrm[nx]);\n\treturn error;\n}\n\nstatic int\nxfrm_tmpl_resolve(struct xfrm_policy **pols, int npols, const struct flowi *fl,\n\t\t  struct xfrm_state **xfrm, unsigned short family)\n{\n\tstruct xfrm_state *tp[XFRM_MAX_DEPTH];\n\tstruct xfrm_state **tpp = (npols > 1) ? tp : xfrm;\n\tint cnx = 0;\n\tint error;\n\tint ret;\n\tint i;\n\n\tfor (i = 0; i < npols; i++) {\n\t\tif (cnx + pols[i]->xfrm_nr >= XFRM_MAX_DEPTH) {\n\t\t\terror = -ENOBUFS;\n\t\t\tgoto fail;\n\t\t}\n\n\t\tret = xfrm_tmpl_resolve_one(pols[i], fl, &tpp[cnx], family);\n\t\tif (ret < 0) {\n\t\t\terror = ret;\n\t\t\tgoto fail;\n\t\t} else\n\t\t\tcnx += ret;\n\t}\n\n\t/* found states are sorted for outbound processing */\n\tif (npols > 1)\n\t\txfrm_state_sort(xfrm, tpp, cnx, family);\n\n\treturn cnx;\n\n fail:\n\tfor (cnx--; cnx >= 0; cnx--)\n\t\txfrm_state_put(tpp[cnx]);\n\treturn error;\n\n}\n\nstatic dscp_t xfrm_get_dscp(const struct flowi *fl, int family)\n{\n\tif (family == AF_INET)\n\t\treturn fl->u.ip4.flowi4_dscp;\n\n\treturn 0;\n}\n\nstatic inline struct xfrm_dst *xfrm_alloc_dst(struct net *net, int family)\n{\n\tconst struct xfrm_policy_afinfo *afinfo = xfrm_policy_get_afinfo(family);\n\tstruct dst_ops *dst_ops;\n\tstruct xfrm_dst *xdst;\n\n\tif (!afinfo)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tswitch (family) {\n\tcase AF_INET:\n\t\tdst_ops = &net->xfrm.xfrm4_dst_ops;\n\t\tbreak;\n#if IS_ENABLED(CONFIG_IPV6)\n\tcase AF_INET6:\n\t\tdst_ops = &net->xfrm.xfrm6_dst_ops;\n\t\tbreak;\n#endif\n\tdefault:\n\t\tBUG();\n\t}\n\txdst = dst_alloc(dst_ops, NULL, DST_OBSOLETE_NONE, 0);\n\n\tif (likely(xdst)) {\n\t\tmemset_after(xdst, 0, u.dst);\n\t} else\n\t\txdst = ERR_PTR(-ENOBUFS);\n\n\trcu_read_unlock();\n\n\treturn xdst;\n}\n\nstatic void xfrm_init_path(struct xfrm_dst *path, struct dst_entry *dst,\n\t\t\t   int nfheader_len)\n{\n\tif (dst->ops->family == AF_INET6) {\n\t\tpath->path_cookie = rt6_get_cookie(dst_rt6_info(dst));\n\t\tpath->u.rt6.rt6i_nfheader_len = nfheader_len;\n\t}\n}\n\nstatic inline int xfrm_fill_dst(struct xfrm_dst *xdst, struct net_device *dev,\n\t\t\t\tconst struct flowi *fl)\n{\n\tconst struct xfrm_policy_afinfo *afinfo =\n\t\txfrm_policy_get_afinfo(xdst->u.dst.ops->family);\n\tint err;\n\n\tif (!afinfo)\n\t\treturn -EINVAL;\n\n\terr = afinfo->fill_dst(xdst, dev, fl);\n\n\trcu_read_unlock();\n\n\treturn err;\n}\n\n\n/* Allocate chain of dst_entry's, attach known xfrm's, calculate\n * all the metrics... Shortly, bundle a bundle.\n */\n\nstatic struct dst_entry *xfrm_bundle_create(struct xfrm_policy *policy,\n\t\t\t\t\t    struct xfrm_state **xfrm,\n\t\t\t\t\t    struct xfrm_dst **bundle,\n\t\t\t\t\t    int nx,\n\t\t\t\t\t    const struct flowi *fl,\n\t\t\t\t\t    struct dst_entry *dst)\n{\n\tconst struct xfrm_state_afinfo *afinfo;\n\tconst struct xfrm_mode *inner_mode;\n\tstruct net *net = xp_net(policy);\n\tunsigned long now = jiffies;\n\tstruct net_device *dev;\n\tstruct xfrm_dst *xdst_prev = NULL;\n\tstruct xfrm_dst *xdst0 = NULL;\n\tint i = 0;\n\tint err;\n\tint header_len = 0;\n\tint nfheader_len = 0;\n\tint trailer_len = 0;\n\tint family = policy->selector.family;\n\txfrm_address_t saddr, daddr;\n\tdscp_t dscp;\n\n\txfrm_flowi_addr_get(fl, &saddr, &daddr, family);\n\n\tdscp = xfrm_get_dscp(fl, family);\n\n\tdst_hold(dst);\n\n\tfor (; i < nx; i++) {\n\t\tstruct xfrm_dst *xdst = xfrm_alloc_dst(net, family);\n\t\tstruct dst_entry *dst1 = &xdst->u.dst;\n\n\t\terr = PTR_ERR(xdst);\n\t\tif (IS_ERR(xdst)) {\n\t\t\tdst_release(dst);\n\t\t\tgoto put_states;\n\t\t}\n\n\t\tbundle[i] = xdst;\n\t\tif (!xdst_prev)\n\t\t\txdst0 = xdst;\n\t\telse\n\t\t\t/* Ref count is taken during xfrm_alloc_dst()\n\t\t\t * No need to do dst_clone() on dst1\n\t\t\t */\n\t\t\txfrm_dst_set_child(xdst_prev, &xdst->u.dst);\n\n\t\tif (xfrm[i]->sel.family == AF_UNSPEC) {\n\t\t\tinner_mode = xfrm_ip2inner_mode(xfrm[i],\n\t\t\t\t\t\t\txfrm_af2proto(family));\n\t\t\tif (!inner_mode) {\n\t\t\t\terr = -EAFNOSUPPORT;\n\t\t\t\tdst_release(dst);\n\t\t\t\tgoto put_states;\n\t\t\t}\n\t\t} else\n\t\t\tinner_mode = &xfrm[i]->inner_mode;\n\n\t\txdst->route = dst;\n\t\tdst_copy_metrics(dst1, dst);\n\n\t\tif (xfrm[i]->props.mode != XFRM_MODE_TRANSPORT) {\n\t\t\t__u32 mark = 0;\n\t\t\tint oif;\n\n\t\t\tif (xfrm[i]->props.smark.v || xfrm[i]->props.smark.m)\n\t\t\t\tmark = xfrm_smark_get(fl->flowi_mark, xfrm[i]);\n\n\t\t\tif (xfrm[i]->xso.type != XFRM_DEV_OFFLOAD_PACKET)\n\t\t\t\tfamily = xfrm[i]->props.family;\n\n\t\t\toif = fl->flowi_oif ? : fl->flowi_l3mdev;\n\t\t\tdst = xfrm_dst_lookup(xfrm[i], dscp, oif, &saddr,\n\t\t\t\t\t      &daddr, family, mark);\n\t\t\terr = PTR_ERR(dst);\n\t\t\tif (IS_ERR(dst))\n\t\t\t\tgoto put_states;\n\t\t} else\n\t\t\tdst_hold(dst);\n\n\t\tdst1->xfrm = xfrm[i];\n\t\txdst->xfrm_genid = xfrm[i]->genid;\n\n\t\tdst1->obsolete = DST_OBSOLETE_FORCE_CHK;\n\t\tdst1->lastuse = now;\n\n\t\tdst1->input = dst_discard;\n\n\t\tif (xfrm[i]->mode_cbs && xfrm[i]->mode_cbs->output) {\n\t\t\tdst1->output = xfrm[i]->mode_cbs->output;\n\t\t} else {\n\t\t\trcu_read_lock();\n\t\t\tafinfo = xfrm_state_afinfo_get_rcu(inner_mode->family);\n\t\t\tif (likely(afinfo))\n\t\t\t\tdst1->output = afinfo->output;\n\t\t\telse\n\t\t\t\tdst1->output = dst_discard_out;\n\t\t\trcu_read_unlock();\n\t\t}\n\n\t\txdst_prev = xdst;\n\n\t\theader_len += xfrm[i]->props.header_len;\n\t\tif (xfrm[i]->type->flags & XFRM_TYPE_NON_FRAGMENT)\n\t\t\tnfheader_len += xfrm[i]->props.header_len;\n\t\ttrailer_len += xfrm[i]->props.trailer_len;\n\t}\n\n\txfrm_dst_set_child(xdst_prev, dst);\n\txdst0->path = dst;\n\n\terr = -ENODEV;\n\tdev = dst->dev;\n\tif (!dev)\n\t\tgoto free_dst;\n\n\txfrm_init_path(xdst0, dst, nfheader_len);\n\txfrm_init_pmtu(bundle, nx);\n\n\tfor (xdst_prev = xdst0; xdst_prev != (struct xfrm_dst *)dst;\n\t     xdst_prev = (struct xfrm_dst *) xfrm_dst_child(&xdst_prev->u.dst)) {\n\t\terr = xfrm_fill_dst(xdst_prev, dev, fl);\n\t\tif (err)\n\t\t\tgoto free_dst;\n\n\t\txdst_prev->u.dst.header_len = header_len;\n\t\txdst_prev->u.dst.trailer_len = trailer_len;\n\t\theader_len -= xdst_prev->u.dst.xfrm->props.header_len;\n\t\ttrailer_len -= xdst_prev->u.dst.xfrm->props.trailer_len;\n\t}\n\n\treturn &xdst0->u.dst;\n\nput_states:\n\tfor (; i < nx; i++)\n\t\txfrm_state_put(xfrm[i]);\nfree_dst:\n\tif (xdst0)\n\t\tdst_release_immediate(&xdst0->u.dst);\n\n\treturn ERR_PTR(err);\n}\n\nstatic int xfrm_expand_policies(const struct flowi *fl, u16 family,\n\t\t\t\tstruct xfrm_policy **pols,\n\t\t\t\tint *num_pols, int *num_xfrms)\n{\n\tint i;\n\n\tif (*num_pols == 0 || !pols[0]) {\n\t\t*num_pols = 0;\n\t\t*num_xfrms = 0;\n\t\treturn 0;\n\t}\n\tif (IS_ERR(pols[0])) {\n\t\t*num_pols = 0;\n\t\treturn PTR_ERR(pols[0]);\n\t}\n\n\t*num_xfrms = pols[0]->xfrm_nr;\n\n#ifdef CONFIG_XFRM_SUB_POLICY\n\tif (pols[0]->action == XFRM_POLICY_ALLOW &&\n\t    pols[0]->type != XFRM_POLICY_TYPE_MAIN) {\n\t\tpols[1] = xfrm_policy_lookup_bytype(xp_net(pols[0]),\n\t\t\t\t\t\t    XFRM_POLICY_TYPE_MAIN,\n\t\t\t\t\t\t    fl, family,\n\t\t\t\t\t\t    XFRM_POLICY_OUT,\n\t\t\t\t\t\t    pols[0]->if_id);\n\t\tif (pols[1]) {\n\t\t\tif (IS_ERR(pols[1])) {\n\t\t\t\txfrm_pols_put(pols, *num_pols);\n\t\t\t\t*num_pols = 0;\n\t\t\t\treturn PTR_ERR(pols[1]);\n\t\t\t}\n\t\t\t(*num_pols)++;\n\t\t\t(*num_xfrms) += pols[1]->xfrm_nr;\n\t\t}\n\t}\n#endif\n\tfor (i = 0; i < *num_pols; i++) {\n\t\tif (pols[i]->action != XFRM_POLICY_ALLOW) {\n\t\t\t*num_xfrms = -1;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn 0;\n\n}\n\nstatic struct xfrm_dst *\nxfrm_resolve_and_create_bundle(struct xfrm_policy **pols, int num_pols,\n\t\t\t       const struct flowi *fl, u16 family,\n\t\t\t       struct dst_entry *dst_orig)\n{\n\tstruct net *net = xp_net(pols[0]);\n\tstruct xfrm_state *xfrm[XFRM_MAX_DEPTH];\n\tstruct xfrm_dst *bundle[XFRM_MAX_DEPTH];\n\tstruct xfrm_dst *xdst;\n\tstruct dst_entry *dst;\n\tint err;\n\n\t/* Try to instantiate a bundle */\n\terr = xfrm_tmpl_resolve(pols, num_pols, fl, xfrm, family);\n\tif (err <= 0) {\n\t\tif (err == 0)\n\t\t\treturn NULL;\n\n\t\tif (err != -EAGAIN)\n\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMOUTPOLERROR);\n\t\treturn ERR_PTR(err);\n\t}\n\n\tdst = xfrm_bundle_create(pols[0], xfrm, bundle, err, fl, dst_orig);\n\tif (IS_ERR(dst)) {\n\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMOUTBUNDLEGENERROR);\n\t\treturn ERR_CAST(dst);\n\t}\n\n\txdst = (struct xfrm_dst *)dst;\n\txdst->num_xfrms = err;\n\txdst->num_pols = num_pols;\n\tmemcpy(xdst->pols, pols, sizeof(struct xfrm_policy *) * num_pols);\n\txdst->policy_genid = atomic_read(&pols[0]->genid);\n\n\treturn xdst;\n}\n\nstatic void xfrm_policy_queue_process(struct timer_list *t)\n{\n\tstruct sk_buff *skb;\n\tstruct sock *sk;\n\tstruct dst_entry *dst;\n\tstruct xfrm_policy *pol = timer_container_of(pol, t, polq.hold_timer);\n\tstruct net *net = xp_net(pol);\n\tstruct xfrm_policy_queue *pq = &pol->polq;\n\tstruct flowi fl;\n\tstruct sk_buff_head list;\n\t__u32 skb_mark;\n\n\tspin_lock(&pq->hold_queue.lock);\n\tskb = skb_peek(&pq->hold_queue);\n\tif (!skb) {\n\t\tspin_unlock(&pq->hold_queue.lock);\n\t\tgoto out;\n\t}\n\tdst = skb_dst(skb);\n\tsk = skb->sk;\n\n\t/* Fixup the mark to support VTI. */\n\tskb_mark = skb->mark;\n\tskb->mark = pol->mark.v;\n\txfrm_decode_session(net, skb, &fl, dst->ops->family);\n\tskb->mark = skb_mark;\n\tspin_unlock(&pq->hold_queue.lock);\n\n\tdst_hold(xfrm_dst_path(dst));\n\tdst = xfrm_lookup(net, xfrm_dst_path(dst), &fl, sk, XFRM_LOOKUP_QUEUE);\n\tif (IS_ERR(dst))\n\t\tgoto purge_queue;\n\n\tif (dst->flags & DST_XFRM_QUEUE) {\n\t\tdst_release(dst);\n\n\t\tif (pq->timeout >= XFRM_QUEUE_TMO_MAX)\n\t\t\tgoto purge_queue;\n\n\t\tpq->timeout = pq->timeout << 1;\n\t\tif (!mod_timer(&pq->hold_timer, jiffies + pq->timeout))\n\t\t\txfrm_pol_hold(pol);\n\t\tgoto out;\n\t}\n\n\tdst_release(dst);\n\n\t__skb_queue_head_init(&list);\n\n\tspin_lock(&pq->hold_queue.lock);\n\tpq->timeout = 0;\n\tskb_queue_splice_init(&pq->hold_queue, &list);\n\tspin_unlock(&pq->hold_queue.lock);\n\n\twhile (!skb_queue_empty(&list)) {\n\t\tskb = __skb_dequeue(&list);\n\n\t\t/* Fixup the mark to support VTI. */\n\t\tskb_mark = skb->mark;\n\t\tskb->mark = pol->mark.v;\n\t\txfrm_decode_session(net, skb, &fl, skb_dst(skb)->ops->family);\n\t\tskb->mark = skb_mark;\n\n\t\tdst_hold(xfrm_dst_path(skb_dst(skb)));\n\t\tdst = xfrm_lookup(net, xfrm_dst_path(skb_dst(skb)), &fl, skb->sk, 0);\n\t\tif (IS_ERR(dst)) {\n\t\t\tkfree_skb(skb);\n\t\t\tcontinue;\n\t\t}\n\n\t\tnf_reset_ct(skb);\n\t\tskb_dst_drop(skb);\n\t\tskb_dst_set(skb, dst);\n\n\t\tdst_output(net, skb_to_full_sk(skb), skb);\n\t}\n\nout:\n\txfrm_pol_put(pol);\n\treturn;\n\npurge_queue:\n\tpq->timeout = 0;\n\tskb_queue_purge(&pq->hold_queue);\n\txfrm_pol_put(pol);\n}\n\nstatic int xdst_queue_output(struct net *net, struct sock *sk, struct sk_buff *skb)\n{\n\tunsigned long sched_next;\n\tstruct dst_entry *dst = skb_dst(skb);\n\tstruct xfrm_dst *xdst = (struct xfrm_dst *) dst;\n\tstruct xfrm_policy *pol = xdst->pols[0];\n\tstruct xfrm_policy_queue *pq = &pol->polq;\n\n\tif (unlikely(skb_fclone_busy(sk, skb))) {\n\t\tkfree_skb(skb);\n\t\treturn 0;\n\t}\n\n\tif (pq->hold_queue.qlen > XFRM_MAX_QUEUE_LEN) {\n\t\tkfree_skb(skb);\n\t\treturn -EAGAIN;\n\t}\n\n\tskb_dst_force(skb);\n\n\tspin_lock_bh(&pq->hold_queue.lock);\n\n\tif (!pq->timeout)\n\t\tpq->timeout = XFRM_QUEUE_TMO_MIN;\n\n\tsched_next = jiffies + pq->timeout;\n\n\tif (timer_delete(&pq->hold_timer)) {\n\t\tif (time_before(pq->hold_timer.expires, sched_next))\n\t\t\tsched_next = pq->hold_timer.expires;\n\t\txfrm_pol_put(pol);\n\t}\n\n\t__skb_queue_tail(&pq->hold_queue, skb);\n\tif (!mod_timer(&pq->hold_timer, sched_next))\n\t\txfrm_pol_hold(pol);\n\n\tspin_unlock_bh(&pq->hold_queue.lock);\n\n\treturn 0;\n}\n\nstatic struct xfrm_dst *xfrm_create_dummy_bundle(struct net *net,\n\t\t\t\t\t\t struct xfrm_flo *xflo,\n\t\t\t\t\t\t const struct flowi *fl,\n\t\t\t\t\t\t int num_xfrms,\n\t\t\t\t\t\t u16 family)\n{\n\tint err;\n\tstruct net_device *dev;\n\tstruct dst_entry *dst;\n\tstruct dst_entry *dst1;\n\tstruct xfrm_dst *xdst;\n\n\txdst = xfrm_alloc_dst(net, family);\n\tif (IS_ERR(xdst))\n\t\treturn xdst;\n\n\tif (!(xflo->flags & XFRM_LOOKUP_QUEUE) ||\n\t    net->xfrm.sysctl_larval_drop ||\n\t    num_xfrms <= 0)\n\t\treturn xdst;\n\n\tdst = xflo->dst_orig;\n\tdst1 = &xdst->u.dst;\n\tdst_hold(dst);\n\txdst->route = dst;\n\n\tdst_copy_metrics(dst1, dst);\n\n\tdst1->obsolete = DST_OBSOLETE_FORCE_CHK;\n\tdst1->flags |= DST_XFRM_QUEUE;\n\tdst1->lastuse = jiffies;\n\n\tdst1->input = dst_discard;\n\tdst1->output = xdst_queue_output;\n\n\tdst_hold(dst);\n\txfrm_dst_set_child(xdst, dst);\n\txdst->path = dst;\n\n\txfrm_init_path((struct xfrm_dst *)dst1, dst, 0);\n\n\terr = -ENODEV;\n\tdev = dst->dev;\n\tif (!dev)\n\t\tgoto free_dst;\n\n\terr = xfrm_fill_dst(xdst, dev, fl);\n\tif (err)\n\t\tgoto free_dst;\n\nout:\n\treturn xdst;\n\nfree_dst:\n\tdst_release(dst1);\n\txdst = ERR_PTR(err);\n\tgoto out;\n}\n\nstatic struct xfrm_dst *xfrm_bundle_lookup(struct net *net,\n\t\t\t\t\t   const struct flowi *fl,\n\t\t\t\t\t   u16 family, u8 dir,\n\t\t\t\t\t   struct xfrm_flo *xflo, u32 if_id)\n{\n\tstruct xfrm_policy *pols[XFRM_POLICY_TYPE_MAX];\n\tint num_pols = 0, num_xfrms = 0, err;\n\tstruct xfrm_dst *xdst;\n\n\t/* Resolve policies to use if we couldn't get them from\n\t * previous cache entry */\n\tnum_pols = 1;\n\tpols[0] = xfrm_policy_lookup(net, fl, family, dir, if_id);\n\terr = xfrm_expand_policies(fl, family, pols,\n\t\t\t\t\t   &num_pols, &num_xfrms);\n\tif (err < 0)\n\t\tgoto inc_error;\n\tif (num_pols == 0)\n\t\treturn NULL;\n\tif (num_xfrms <= 0)\n\t\tgoto make_dummy_bundle;\n\n\txdst = xfrm_resolve_and_create_bundle(pols, num_pols, fl, family,\n\t\t\t\t\t      xflo->dst_orig);\n\tif (IS_ERR(xdst)) {\n\t\terr = PTR_ERR(xdst);\n\t\tif (err == -EREMOTE) {\n\t\t\txfrm_pols_put(pols, num_pols);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (err != -EAGAIN)\n\t\t\tgoto error;\n\t\tgoto make_dummy_bundle;\n\t} else if (xdst == NULL) {\n\t\tnum_xfrms = 0;\n\t\tgoto make_dummy_bundle;\n\t}\n\n\treturn xdst;\n\nmake_dummy_bundle:\n\t/* We found policies, but there's no bundles to instantiate:\n\t * either because the policy blocks, has no transformations or\n\t * we could not build template (no xfrm_states).*/\n\txdst = xfrm_create_dummy_bundle(net, xflo, fl, num_xfrms, family);\n\tif (IS_ERR(xdst)) {\n\t\txfrm_pols_put(pols, num_pols);\n\t\treturn ERR_CAST(xdst);\n\t}\n\txdst->num_pols = num_pols;\n\txdst->num_xfrms = num_xfrms;\n\tmemcpy(xdst->pols, pols, sizeof(struct xfrm_policy *) * num_pols);\n\n\treturn xdst;\n\ninc_error:\n\tXFRM_INC_STATS(net, LINUX_MIB_XFRMOUTPOLERROR);\nerror:\n\txfrm_pols_put(pols, num_pols);\n\treturn ERR_PTR(err);\n}\n\nstatic struct dst_entry *make_blackhole(struct net *net, u16 family,\n\t\t\t\t\tstruct dst_entry *dst_orig)\n{\n\tconst struct xfrm_policy_afinfo *afinfo = xfrm_policy_get_afinfo(family);\n\tstruct dst_entry *ret;\n\n\tif (!afinfo) {\n\t\tdst_release(dst_orig);\n\t\treturn ERR_PTR(-EINVAL);\n\t} else {\n\t\tret = afinfo->blackhole_route(net, dst_orig);\n\t}\n\trcu_read_unlock();\n\n\treturn ret;\n}\n\n/* Finds/creates a bundle for given flow and if_id\n *\n * At the moment we eat a raw IP route. Mostly to speed up lookups\n * on interfaces with disabled IPsec.\n *\n * xfrm_lookup uses an if_id of 0 by default, and is provided for\n * compatibility\n */\nstruct dst_entry *xfrm_lookup_with_ifid(struct net *net,\n\t\t\t\t\tstruct dst_entry *dst_orig,\n\t\t\t\t\tconst struct flowi *fl,\n\t\t\t\t\tconst struct sock *sk,\n\t\t\t\t\tint flags, u32 if_id)\n{\n\tstruct xfrm_policy *pols[XFRM_POLICY_TYPE_MAX];\n\tstruct xfrm_dst *xdst;\n\tstruct dst_entry *dst, *route;\n\tu16 family = dst_orig->ops->family;\n\tu8 dir = XFRM_POLICY_OUT;\n\tint i, err, num_pols, num_xfrms = 0, drop_pols = 0;\n\n\tdst = NULL;\n\txdst = NULL;\n\troute = NULL;\n\n\tsk = sk_const_to_full_sk(sk);\n\tif (sk && sk->sk_policy[XFRM_POLICY_OUT]) {\n\t\tnum_pols = 1;\n\t\tpols[0] = xfrm_sk_policy_lookup(sk, XFRM_POLICY_OUT, fl, family,\n\t\t\t\t\t\tif_id);\n\t\terr = xfrm_expand_policies(fl, family, pols,\n\t\t\t\t\t   &num_pols, &num_xfrms);\n\t\tif (err < 0)\n\t\t\tgoto dropdst;\n\n\t\tif (num_pols) {\n\t\t\tif (num_xfrms <= 0) {\n\t\t\t\tdrop_pols = num_pols;\n\t\t\t\tgoto no_transform;\n\t\t\t}\n\n\t\t\txdst = xfrm_resolve_and_create_bundle(\n\t\t\t\t\tpols, num_pols, fl,\n\t\t\t\t\tfamily, dst_orig);\n\n\t\t\tif (IS_ERR(xdst)) {\n\t\t\t\txfrm_pols_put(pols, num_pols);\n\t\t\t\terr = PTR_ERR(xdst);\n\t\t\t\tif (err == -EREMOTE)\n\t\t\t\t\tgoto nopol;\n\n\t\t\t\tgoto dropdst;\n\t\t\t} else if (xdst == NULL) {\n\t\t\t\tnum_xfrms = 0;\n\t\t\t\tdrop_pols = num_pols;\n\t\t\t\tgoto no_transform;\n\t\t\t}\n\n\t\t\troute = xdst->route;\n\t\t}\n\t}\n\n\tif (xdst == NULL) {\n\t\tstruct xfrm_flo xflo;\n\n\t\txflo.dst_orig = dst_orig;\n\t\txflo.flags = flags;\n\n\t\t/* To accelerate a bit...  */\n\t\tif (!if_id && ((dst_orig->flags & DST_NOXFRM) ||\n\t\t\t       !net->xfrm.policy_count[XFRM_POLICY_OUT]))\n\t\t\tgoto nopol;\n\n\t\txdst = xfrm_bundle_lookup(net, fl, family, dir, &xflo, if_id);\n\t\tif (xdst == NULL)\n\t\t\tgoto nopol;\n\t\tif (IS_ERR(xdst)) {\n\t\t\terr = PTR_ERR(xdst);\n\t\t\tgoto dropdst;\n\t\t}\n\n\t\tnum_pols = xdst->num_pols;\n\t\tnum_xfrms = xdst->num_xfrms;\n\t\tmemcpy(pols, xdst->pols, sizeof(struct xfrm_policy *) * num_pols);\n\t\troute = xdst->route;\n\t}\n\n\tdst = &xdst->u.dst;\n\tif (route == NULL && num_xfrms > 0) {\n\t\t/* The only case when xfrm_bundle_lookup() returns a\n\t\t * bundle with null route, is when the template could\n\t\t * not be resolved. It means policies are there, but\n\t\t * bundle could not be created, since we don't yet\n\t\t * have the xfrm_state's. We need to wait for KM to\n\t\t * negotiate new SA's or bail out with error.*/\n\t\tif (net->xfrm.sysctl_larval_drop) {\n\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMOUTNOSTATES);\n\t\t\terr = -EREMOTE;\n\t\t\tgoto error;\n\t\t}\n\n\t\terr = -EAGAIN;\n\n\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMOUTNOSTATES);\n\t\tgoto error;\n\t}\n\nno_transform:\n\tif (num_pols == 0)\n\t\tgoto nopol;\n\n\tif ((flags & XFRM_LOOKUP_ICMP) &&\n\t    !(pols[0]->flags & XFRM_POLICY_ICMP)) {\n\t\terr = -ENOENT;\n\t\tgoto error;\n\t}\n\n\tfor (i = 0; i < num_pols; i++)\n\t\tWRITE_ONCE(pols[i]->curlft.use_time, ktime_get_real_seconds());\n\n\tif (num_xfrms < 0) {\n\t\t/* Prohibit the flow */\n\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMOUTPOLBLOCK);\n\t\terr = -EPERM;\n\t\tgoto error;\n\t} else if (num_xfrms > 0) {\n\t\t/* Flow transformed */\n\t\tdst_release(dst_orig);\n\t} else {\n\t\t/* Flow passes untransformed */\n\t\tdst_release(dst);\n\t\tdst = dst_orig;\n\t}\n\nok:\n\txfrm_pols_put(pols, drop_pols);\n\tif (dst->xfrm &&\n\t    (dst->xfrm->props.mode == XFRM_MODE_TUNNEL ||\n\t     dst->xfrm->props.mode == XFRM_MODE_IPTFS))\n\t\tdst->flags |= DST_XFRM_TUNNEL;\n\treturn dst;\n\nnopol:\n\tif ((!dst_orig->dev || !(dst_orig->dev->flags & IFF_LOOPBACK)) &&\n\t    net->xfrm.policy_default[dir] == XFRM_USERPOLICY_BLOCK) {\n\t\terr = -EPERM;\n\t\tgoto error;\n\t}\n\tif (!(flags & XFRM_LOOKUP_ICMP)) {\n\t\tdst = dst_orig;\n\t\tgoto ok;\n\t}\n\terr = -ENOENT;\nerror:\n\tdst_release(dst);\ndropdst:\n\tif (!(flags & XFRM_LOOKUP_KEEP_DST_REF))\n\t\tdst_release(dst_orig);\n\txfrm_pols_put(pols, drop_pols);\n\treturn ERR_PTR(err);\n}\nEXPORT_SYMBOL(xfrm_lookup_with_ifid);\n\n/* Main function: finds/creates a bundle for given flow.\n *\n * At the moment we eat a raw IP route. Mostly to speed up lookups\n * on interfaces with disabled IPsec.\n */\nstruct dst_entry *xfrm_lookup(struct net *net, struct dst_entry *dst_orig,\n\t\t\t      const struct flowi *fl, const struct sock *sk,\n\t\t\t      int flags)\n{\n\treturn xfrm_lookup_with_ifid(net, dst_orig, fl, sk, flags, 0);\n}\nEXPORT_SYMBOL(xfrm_lookup);\n\n/* Callers of xfrm_lookup_route() must ensure a call to dst_output().\n * Otherwise we may send out blackholed packets.\n */\nstruct dst_entry *xfrm_lookup_route(struct net *net, struct dst_entry *dst_orig,\n\t\t\t\t    const struct flowi *fl,\n\t\t\t\t    const struct sock *sk, int flags)\n{\n\tstruct dst_entry *dst = xfrm_lookup(net, dst_orig, fl, sk,\n\t\t\t\t\t    flags | XFRM_LOOKUP_QUEUE |\n\t\t\t\t\t    XFRM_LOOKUP_KEEP_DST_REF);\n\n\tif (PTR_ERR(dst) == -EREMOTE)\n\t\treturn make_blackhole(net, dst_orig->ops->family, dst_orig);\n\n\tif (IS_ERR(dst))\n\t\tdst_release(dst_orig);\n\n\treturn dst;\n}\nEXPORT_SYMBOL(xfrm_lookup_route);\n\nstatic inline int\nxfrm_secpath_reject(int idx, struct sk_buff *skb, const struct flowi *fl)\n{\n\tstruct sec_path *sp = skb_sec_path(skb);\n\tstruct xfrm_state *x;\n\n\tif (!sp || idx < 0 || idx >= sp->len)\n\t\treturn 0;\n\tx = sp->xvec[idx];\n\tif (!x->type->reject)\n\t\treturn 0;\n\treturn x->type->reject(x, skb, fl);\n}\n\n/* When skb is transformed back to its \"native\" form, we have to\n * check policy restrictions. At the moment we make this in maximally\n * stupid way. Shame on me. :-) Of course, connected sockets must\n * have policy cached at them.\n */\n\nstatic inline int\nxfrm_state_ok(const struct xfrm_tmpl *tmpl, const struct xfrm_state *x,\n\t      unsigned short family, u32 if_id)\n{\n\tif (xfrm_state_kern(x))\n\t\treturn tmpl->optional && !xfrm_state_addr_cmp(tmpl, x, tmpl->encap_family);\n\treturn\tx->id.proto == tmpl->id.proto &&\n\t\t(x->id.spi == tmpl->id.spi || !tmpl->id.spi) &&\n\t\t(x->props.reqid == tmpl->reqid || !tmpl->reqid) &&\n\t\tx->props.mode == tmpl->mode &&\n\t\t(tmpl->allalgs || (tmpl->aalgos & (1<<x->props.aalgo)) ||\n\t\t !(xfrm_id_proto_match(tmpl->id.proto, IPSEC_PROTO_ANY))) &&\n\t\t!(x->props.mode != XFRM_MODE_TRANSPORT &&\n\t\t  xfrm_state_addr_cmp(tmpl, x, family)) &&\n\t\t(if_id == 0 || if_id == x->if_id);\n}\n\n/*\n * 0 or more than 0 is returned when validation is succeeded (either bypass\n * because of optional transport mode, or next index of the matched secpath\n * state with the template.\n * -1 is returned when no matching template is found.\n * Otherwise \"-2 - errored_index\" is returned.\n */\nstatic inline int\nxfrm_policy_ok(const struct xfrm_tmpl *tmpl, const struct sec_path *sp, int start,\n\t       unsigned short family, u32 if_id)\n{\n\tint idx = start;\n\n\tif (tmpl->optional) {\n\t\tif (tmpl->mode == XFRM_MODE_TRANSPORT)\n\t\t\treturn start;\n\t} else\n\t\tstart = -1;\n\tfor (; idx < sp->len; idx++) {\n\t\tif (xfrm_state_ok(tmpl, sp->xvec[idx], family, if_id))\n\t\t\treturn ++idx;\n\t\tif (sp->xvec[idx]->props.mode != XFRM_MODE_TRANSPORT) {\n\t\t\tif (idx < sp->verified_cnt) {\n\t\t\t\t/* Secpath entry previously verified, consider optional and\n\t\t\t\t * continue searching\n\t\t\t\t */\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (start == -1)\n\t\t\t\tstart = -2-idx;\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn start;\n}\n\nstatic void\ndecode_session4(const struct xfrm_flow_keys *flkeys, struct flowi *fl, bool reverse)\n{\n\tstruct flowi4 *fl4 = &fl->u.ip4;\n\n\tmemset(fl4, 0, sizeof(struct flowi4));\n\n\tif (reverse) {\n\t\tfl4->saddr = flkeys->addrs.ipv4.dst;\n\t\tfl4->daddr = flkeys->addrs.ipv4.src;\n\t\tfl4->fl4_sport = flkeys->ports.dst;\n\t\tfl4->fl4_dport = flkeys->ports.src;\n\t} else {\n\t\tfl4->saddr = flkeys->addrs.ipv4.src;\n\t\tfl4->daddr = flkeys->addrs.ipv4.dst;\n\t\tfl4->fl4_sport = flkeys->ports.src;\n\t\tfl4->fl4_dport = flkeys->ports.dst;\n\t}\n\n\tswitch (flkeys->basic.ip_proto) {\n\tcase IPPROTO_GRE:\n\t\tfl4->fl4_gre_key = flkeys->gre.keyid;\n\t\tbreak;\n\tcase IPPROTO_ICMP:\n\t\tfl4->fl4_icmp_type = flkeys->icmp.type;\n\t\tfl4->fl4_icmp_code = flkeys->icmp.code;\n\t\tbreak;\n\t}\n\n\tfl4->flowi4_proto = flkeys->basic.ip_proto;\n\tfl4->flowi4_dscp = inet_dsfield_to_dscp(flkeys->ip.tos);\n}\n\n#if IS_ENABLED(CONFIG_IPV6)\nstatic void\ndecode_session6(const struct xfrm_flow_keys *flkeys, struct flowi *fl, bool reverse)\n{\n\tstruct flowi6 *fl6 = &fl->u.ip6;\n\n\tmemset(fl6, 0, sizeof(struct flowi6));\n\n\tif (reverse) {\n\t\tfl6->saddr = flkeys->addrs.ipv6.dst;\n\t\tfl6->daddr = flkeys->addrs.ipv6.src;\n\t\tfl6->fl6_sport = flkeys->ports.dst;\n\t\tfl6->fl6_dport = flkeys->ports.src;\n\t} else {\n\t\tfl6->saddr = flkeys->addrs.ipv6.src;\n\t\tfl6->daddr = flkeys->addrs.ipv6.dst;\n\t\tfl6->fl6_sport = flkeys->ports.src;\n\t\tfl6->fl6_dport = flkeys->ports.dst;\n\t}\n\n\tswitch (flkeys->basic.ip_proto) {\n\tcase IPPROTO_GRE:\n\t\tfl6->fl6_gre_key = flkeys->gre.keyid;\n\t\tbreak;\n\tcase IPPROTO_ICMPV6:\n\t\tfl6->fl6_icmp_type = flkeys->icmp.type;\n\t\tfl6->fl6_icmp_code = flkeys->icmp.code;\n\t\tbreak;\n\t}\n\n\tfl6->flowi6_proto = flkeys->basic.ip_proto;\n}\n#endif\n\nint __xfrm_decode_session(struct net *net, struct sk_buff *skb, struct flowi *fl,\n\t\t\t  unsigned int family, int reverse)\n{\n\tstruct xfrm_flow_keys flkeys;\n\n\tmemset(&flkeys, 0, sizeof(flkeys));\n\t__skb_flow_dissect(net, skb, &xfrm_session_dissector, &flkeys,\n\t\t\t   NULL, 0, 0, 0, FLOW_DISSECTOR_F_STOP_AT_ENCAP);\n\n\tswitch (family) {\n\tcase AF_INET:\n\t\tdecode_session4(&flkeys, fl, reverse);\n\t\tbreak;\n#if IS_ENABLED(CONFIG_IPV6)\n\tcase AF_INET6:\n\t\tdecode_session6(&flkeys, fl, reverse);\n\t\tbreak;\n#endif\n\tdefault:\n\t\treturn -EAFNOSUPPORT;\n\t}\n\n\tfl->flowi_mark = skb->mark;\n\tif (reverse) {\n\t\tfl->flowi_oif = skb->skb_iif;\n\t} else {\n\t\tint oif = 0;\n\n\t\tif (skb_dst(skb) && skb_dst(skb)->dev)\n\t\t\toif = skb_dst(skb)->dev->ifindex;\n\n\t\tfl->flowi_oif = oif;\n\t}\n\n\treturn security_xfrm_decode_session(skb, &fl->flowi_secid);\n}\nEXPORT_SYMBOL(__xfrm_decode_session);\n\nstatic inline int secpath_has_nontransport(const struct sec_path *sp, int k, int *idxp)\n{\n\tfor (; k < sp->len; k++) {\n\t\tif (sp->xvec[k]->props.mode != XFRM_MODE_TRANSPORT) {\n\t\t\t*idxp = k;\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic bool icmp_err_packet(const struct flowi *fl, unsigned short family)\n{\n\tconst struct flowi4 *fl4 = &fl->u.ip4;\n\n\tif (family == AF_INET &&\n\t    fl4->flowi4_proto == IPPROTO_ICMP &&\n\t    (fl4->fl4_icmp_type == ICMP_DEST_UNREACH ||\n\t     fl4->fl4_icmp_type == ICMP_TIME_EXCEEDED))\n\t\treturn true;\n\n#if IS_ENABLED(CONFIG_IPV6)\n\tif (family == AF_INET6) {\n\t\tconst struct flowi6 *fl6 = &fl->u.ip6;\n\n\t\tif (fl6->flowi6_proto == IPPROTO_ICMPV6 &&\n\t\t    (fl6->fl6_icmp_type == ICMPV6_DEST_UNREACH ||\n\t\t    fl6->fl6_icmp_type == ICMPV6_PKT_TOOBIG ||\n\t\t    fl6->fl6_icmp_type == ICMPV6_TIME_EXCEED))\n\t\t\treturn true;\n\t}\n#endif\n\treturn false;\n}\n\nstatic bool xfrm_icmp_flow_decode(struct sk_buff *skb, unsigned short family,\n\t\t\t\t  const struct flowi *fl, struct flowi *fl1)\n{\n\tbool ret = true;\n\tstruct sk_buff *newskb = skb_clone(skb, GFP_ATOMIC);\n\tint hl = family == AF_INET ? (sizeof(struct iphdr) +  sizeof(struct icmphdr)) :\n\t\t (sizeof(struct ipv6hdr) + sizeof(struct icmp6hdr));\n\n\tif (!newskb)\n\t\treturn true;\n\n\tif (!pskb_pull(newskb, hl))\n\t\tgoto out;\n\n\tskb_reset_network_header(newskb);\n\n\tif (xfrm_decode_session_reverse(dev_net(skb->dev), newskb, fl1, family) < 0)\n\t\tgoto out;\n\n\tfl1->flowi_oif = fl->flowi_oif;\n\tfl1->flowi_mark = fl->flowi_mark;\n\tfl1->flowi_dscp = fl->flowi_dscp;\n\tnf_nat_decode_session(newskb, fl1, family);\n\tret = false;\n\nout:\n\tconsume_skb(newskb);\n\treturn ret;\n}\n\nstatic bool xfrm_selector_inner_icmp_match(struct sk_buff *skb, unsigned short family,\n\t\t\t\t\t   const struct xfrm_selector *sel,\n\t\t\t\t\t   const struct flowi *fl)\n{\n\tbool ret = false;\n\n\tif (icmp_err_packet(fl, family)) {\n\t\tstruct flowi fl1;\n\n\t\tif (xfrm_icmp_flow_decode(skb, family, fl, &fl1))\n\t\t\treturn ret;\n\n\t\tret = xfrm_selector_match(sel, &fl1, family);\n\t}\n\n\treturn ret;\n}\n\nstatic inline struct\nxfrm_policy *xfrm_in_fwd_icmp(struct sk_buff *skb,\n\t\t\t      const struct flowi *fl, unsigned short family,\n\t\t\t      u32 if_id)\n{\n\tstruct xfrm_policy *pol = NULL;\n\n\tif (icmp_err_packet(fl, family)) {\n\t\tstruct flowi fl1;\n\t\tstruct net *net = dev_net(skb->dev);\n\n\t\tif (xfrm_icmp_flow_decode(skb, family, fl, &fl1))\n\t\t\treturn pol;\n\n\t\tpol = xfrm_policy_lookup(net, &fl1, family, XFRM_POLICY_FWD, if_id);\n\t\tif (IS_ERR(pol))\n\t\t\tpol = NULL;\n\t}\n\n\treturn pol;\n}\n\nstatic inline struct\ndst_entry *xfrm_out_fwd_icmp(struct sk_buff *skb, struct flowi *fl,\n\t\t\t     unsigned short family, struct dst_entry *dst)\n{\n\tif (icmp_err_packet(fl, family)) {\n\t\tstruct net *net = dev_net(skb->dev);\n\t\tstruct dst_entry *dst2;\n\t\tstruct flowi fl1;\n\n\t\tif (xfrm_icmp_flow_decode(skb, family, fl, &fl1))\n\t\t\treturn dst;\n\n\t\tdst_hold(dst);\n\n\t\tdst2 = xfrm_lookup(net, dst, &fl1, NULL, (XFRM_LOOKUP_QUEUE | XFRM_LOOKUP_ICMP));\n\n\t\tif (IS_ERR(dst2))\n\t\t\treturn dst;\n\n\t\tif (dst2->xfrm) {\n\t\t\tdst_release(dst);\n\t\t\tdst = dst2;\n\t\t} else {\n\t\t\tdst_release(dst2);\n\t\t}\n\t}\n\n\treturn dst;\n}\n\nint __xfrm_policy_check(struct sock *sk, int dir, struct sk_buff *skb,\n\t\t\tunsigned short family)\n{\n\tstruct net *net = dev_net(skb->dev);\n\tstruct xfrm_policy *pol;\n\tstruct xfrm_policy *pols[XFRM_POLICY_TYPE_MAX];\n\tint npols = 0;\n\tint xfrm_nr;\n\tint pi;\n\tint reverse;\n\tstruct flowi fl;\n\tint xerr_idx = -1;\n\tconst struct xfrm_if_cb *ifcb;\n\tstruct sec_path *sp;\n\tu32 if_id = 0;\n\n\trcu_read_lock();\n\tifcb = xfrm_if_get_cb();\n\n\tif (ifcb) {\n\t\tstruct xfrm_if_decode_session_result r;\n\n\t\tif (ifcb->decode_session(skb, family, &r)) {\n\t\t\tif_id = r.if_id;\n\t\t\tnet = r.net;\n\t\t}\n\t}\n\trcu_read_unlock();\n\n\treverse = dir & ~XFRM_POLICY_MASK;\n\tdir &= XFRM_POLICY_MASK;\n\n\tif (__xfrm_decode_session(net, skb, &fl, family, reverse) < 0) {\n\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINHDRERROR);\n\t\treturn 0;\n\t}\n\n\tnf_nat_decode_session(skb, &fl, family);\n\n\t/* First, check used SA against their selectors. */\n\tsp = skb_sec_path(skb);\n\tif (sp) {\n\t\tint i;\n\n\t\tfor (i = sp->len - 1; i >= 0; i--) {\n\t\t\tstruct xfrm_state *x = sp->xvec[i];\n\t\t\tint ret = 0;\n\n\t\t\tif (!xfrm_selector_match(&x->sel, &fl, family)) {\n\t\t\t\tret = 1;\n\t\t\t\tif (x->props.flags & XFRM_STATE_ICMP &&\n\t\t\t\t    xfrm_selector_inner_icmp_match(skb, family, &x->sel, &fl))\n\t\t\t\t\tret = 0;\n\t\t\t\tif (ret) {\n\t\t\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINSTATEMISMATCH);\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tpol = NULL;\n\tsk = sk_to_full_sk(sk);\n\tif (sk && sk->sk_policy[dir]) {\n\t\tpol = xfrm_sk_policy_lookup(sk, dir, &fl, family, if_id);\n\t\tif (IS_ERR(pol)) {\n\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINPOLERROR);\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\tif (!pol)\n\t\tpol = xfrm_policy_lookup(net, &fl, family, dir, if_id);\n\n\tif (IS_ERR(pol)) {\n\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINPOLERROR);\n\t\treturn 0;\n\t}\n\n\tif (!pol && dir == XFRM_POLICY_FWD)\n\t\tpol = xfrm_in_fwd_icmp(skb, &fl, family, if_id);\n\n\tif (!pol) {\n\t\tconst bool is_crypto_offload = sp &&\n\t\t\t(xfrm_input_state(skb)->xso.type == XFRM_DEV_OFFLOAD_CRYPTO);\n\n\t\tif (net->xfrm.policy_default[dir] == XFRM_USERPOLICY_BLOCK) {\n\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINNOPOLS);\n\t\t\treturn 0;\n\t\t}\n\n\t\tif (sp && secpath_has_nontransport(sp, 0, &xerr_idx) && !is_crypto_offload) {\n\t\t\txfrm_secpath_reject(xerr_idx, skb, &fl);\n\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINNOPOLS);\n\t\t\treturn 0;\n\t\t}\n\t\treturn 1;\n\t}\n\n\t/* This lockless write can happen from different cpus. */\n\tWRITE_ONCE(pol->curlft.use_time, ktime_get_real_seconds());\n\n\tpols[0] = pol;\n\tnpols++;\n#ifdef CONFIG_XFRM_SUB_POLICY\n\tif (pols[0]->type != XFRM_POLICY_TYPE_MAIN) {\n\t\tpols[1] = xfrm_policy_lookup_bytype(net, XFRM_POLICY_TYPE_MAIN,\n\t\t\t\t\t\t    &fl, family,\n\t\t\t\t\t\t    XFRM_POLICY_IN, if_id);\n\t\tif (pols[1]) {\n\t\t\tif (IS_ERR(pols[1])) {\n\t\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINPOLERROR);\n\t\t\t\txfrm_pol_put(pols[0]);\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\t/* This write can happen from different cpus. */\n\t\t\tWRITE_ONCE(pols[1]->curlft.use_time,\n\t\t\t\t   ktime_get_real_seconds());\n\t\t\tnpols++;\n\t\t}\n\t}\n#endif\n\n\tif (pol->action == XFRM_POLICY_ALLOW) {\n\t\tstatic struct sec_path dummy;\n\t\tstruct xfrm_tmpl *tp[XFRM_MAX_DEPTH];\n\t\tstruct xfrm_tmpl *stp[XFRM_MAX_DEPTH];\n\t\tstruct xfrm_tmpl **tpp = tp;\n\t\tint ti = 0;\n\t\tint i, k;\n\n\t\tsp = skb_sec_path(skb);\n\t\tif (!sp)\n\t\t\tsp = &dummy;\n\n\t\tfor (pi = 0; pi < npols; pi++) {\n\t\t\tif (pols[pi] != pol &&\n\t\t\t    pols[pi]->action != XFRM_POLICY_ALLOW) {\n\t\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINPOLBLOCK);\n\t\t\t\tgoto reject;\n\t\t\t}\n\t\t\tif (ti + pols[pi]->xfrm_nr >= XFRM_MAX_DEPTH) {\n\t\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINBUFFERERROR);\n\t\t\t\tgoto reject_error;\n\t\t\t}\n\t\t\tfor (i = 0; i < pols[pi]->xfrm_nr; i++)\n\t\t\t\ttpp[ti++] = &pols[pi]->xfrm_vec[i];\n\t\t}\n\t\txfrm_nr = ti;\n\n\t\tif (npols > 1) {\n\t\t\txfrm_tmpl_sort(stp, tpp, xfrm_nr, family);\n\t\t\ttpp = stp;\n\t\t}\n\n\t\t/* For each tunnel xfrm, find the first matching tmpl.\n\t\t * For each tmpl before that, find corresponding xfrm.\n\t\t * Order is _important_. Later we will implement\n\t\t * some barriers, but at the moment barriers\n\t\t * are implied between each two transformations.\n\t\t * Upon success, marks secpath entries as having been\n\t\t * verified to allow them to be skipped in future policy\n\t\t * checks (e.g. nested tunnels).\n\t\t */\n\t\tfor (i = xfrm_nr-1, k = 0; i >= 0; i--) {\n\t\t\tk = xfrm_policy_ok(tpp[i], sp, k, family, if_id);\n\t\t\tif (k < 0) {\n\t\t\t\tif (k < -1)\n\t\t\t\t\t/* \"-2 - errored_index\" returned */\n\t\t\t\t\txerr_idx = -(2+k);\n\t\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINTMPLMISMATCH);\n\t\t\t\tgoto reject;\n\t\t\t}\n\t\t}\n\n\t\tif (secpath_has_nontransport(sp, k, &xerr_idx)) {\n\t\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINTMPLMISMATCH);\n\t\t\tgoto reject;\n\t\t}\n\n\t\txfrm_pols_put(pols, npols);\n\t\tsp->verified_cnt = k;\n\n\t\treturn 1;\n\t}\n\tXFRM_INC_STATS(net, LINUX_MIB_XFRMINPOLBLOCK);\n\nreject:\n\txfrm_secpath_reject(xerr_idx, skb, &fl);\nreject_error:\n\txfrm_pols_put(pols, npols);\n\treturn 0;\n}\nEXPORT_SYMBOL(__xfrm_policy_check);\n\nint __xfrm_route_forward(struct sk_buff *skb, unsigned short family)\n{\n\tstruct net *net = dev_net(skb->dev);\n\tstruct flowi fl;\n\tstruct dst_entry *dst;\n\tint res = 1;\n\n\tif (xfrm_decode_session(net, skb, &fl, family) < 0) {\n\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMFWDHDRERROR);\n\t\treturn 0;\n\t}\n\n\tskb_dst_force(skb);\n\tdst = skb_dst(skb);\n\tif (!dst) {\n\t\tXFRM_INC_STATS(net, LINUX_MIB_XFRMFWDHDRERROR);\n\t\treturn 0;\n\t}\n\n\t/* ignore return value from skb_dstref_steal, xfrm_lookup takes\n\t * care of dropping the refcnt if needed.\n\t */\n\tskb_dstref_steal(skb);\n\n\tdst = xfrm_lookup(net, dst, &fl, NULL, XFRM_LOOKUP_QUEUE);\n\tif (IS_ERR(dst)) {\n\t\tres = 0;\n\t\tdst = NULL;\n\t}\n\n\tif (dst && !dst->xfrm)\n\t\tdst = xfrm_out_fwd_icmp(skb, &fl, family, dst);\n\n\tskb_dst_set(skb, dst);\n\treturn res;\n}\nEXPORT_SYMBOL(__xfrm_route_forward);\n\n/* Optimize later using cookies and generation ids. */\n\nstatic struct dst_entry *xfrm_dst_check(struct dst_entry *dst, u32 cookie)\n{\n\t/* Code (such as __xfrm4_bundle_create()) sets dst->obsolete\n\t * to DST_OBSOLETE_FORCE_CHK to force all XFRM destinations to\n\t * get validated by dst_ops->check on every use.  We do this\n\t * because when a normal route referenced by an XFRM dst is\n\t * obsoleted we do not go looking around for all parent\n\t * referencing XFRM dsts so that we can invalidate them.  It\n\t * is just too much work.  Instead we make the checks here on\n\t * every use.  For example:\n\t *\n\t *\tXFRM dst A --> IPv4 dst X\n\t *\n\t * X is the \"xdst->route\" of A (X is also the \"dst->path\" of A\n\t * in this example).  If X is marked obsolete, \"A\" will not\n\t * notice.  That's what we are validating here via the\n\t * stale_bundle() check.\n\t *\n\t * When a dst is removed from the fib tree, DST_OBSOLETE_DEAD will\n\t * be marked on it.\n\t * This will force stale_bundle() to fail on any xdst bundle with\n\t * this dst linked in it.\n\t */\n\tif (READ_ONCE(dst->obsolete) < 0 && !stale_bundle(dst))\n\t\treturn dst;\n\n\treturn NULL;\n}\n\nstatic int stale_bundle(struct dst_entry *dst)\n{\n\treturn !xfrm_bundle_ok((struct xfrm_dst *)dst);\n}\n\nvoid xfrm_dst_ifdown(struct dst_entry *dst, struct net_device *dev)\n{\n\twhile ((dst = xfrm_dst_child(dst)) && dst->xfrm && dst->dev == dev) {\n\t\tdst->dev = blackhole_netdev;\n\t\tdev_hold(dst->dev);\n\t\tdev_put(dev);\n\t}\n}\nEXPORT_SYMBOL(xfrm_dst_ifdown);\n\nstatic void xfrm_link_failure(struct sk_buff *skb)\n{\n\t/* Impossible. Such dst must be popped before reaches point of failure. */\n}\n\nstatic void xfrm_negative_advice(struct sock *sk, struct dst_entry *dst)\n{\n\tif (READ_ONCE(dst->obsolete))\n\t\tsk_dst_reset(sk);\n}\n\nstatic void xfrm_init_pmtu(struct xfrm_dst **bundle, int nr)\n{\n\twhile (nr--) {\n\t\tstruct xfrm_dst *xdst = bundle[nr];\n\t\tu32 pmtu, route_mtu_cached;\n\t\tstruct dst_entry *dst;\n\n\t\tdst = &xdst->u.dst;\n\t\tpmtu = dst_mtu(xfrm_dst_child(dst));\n\t\txdst->child_mtu_cached = pmtu;\n\n\t\tpmtu = xfrm_state_mtu(dst->xfrm, pmtu);\n\n\t\troute_mtu_cached = dst_mtu(xdst->route);\n\t\txdst->route_mtu_cached = route_mtu_cached;\n\n\t\tif (pmtu > route_mtu_cached)\n\t\t\tpmtu = route_mtu_cached;\n\n\t\tdst_metric_set(dst, RTAX_MTU, pmtu);\n\t}\n}\n\n/* Check that the bundle accepts the flow and its components are\n * still valid.\n */\n\nstatic int xfrm_bundle_ok(struct xfrm_dst *first)\n{\n\tstruct xfrm_dst *bundle[XFRM_MAX_DEPTH];\n\tstruct dst_entry *dst = &first->u.dst;\n\tstruct xfrm_dst *xdst;\n\tint start_from, nr;\n\tu32 mtu;\n\n\tif (!dst_check(xfrm_dst_path(dst), ((struct xfrm_dst *)dst)->path_cookie) ||\n\t    (dst->dev && !netif_running(dst->dev)))\n\t\treturn 0;\n\n\tif (dst->flags & DST_XFRM_QUEUE)\n\t\treturn 1;\n\n\tstart_from = nr = 0;\n\tdo {\n\t\tstruct xfrm_dst *xdst = (struct xfrm_dst *)dst;\n\n\t\tif (dst->xfrm->km.state != XFRM_STATE_VALID)\n\t\t\treturn 0;\n\t\tif (xdst->xfrm_genid != dst->xfrm->genid)\n\t\t\treturn 0;\n\t\tif (xdst->num_pols > 0 &&\n\t\t    xdst->policy_genid != atomic_read(&xdst->pols[0]->genid))\n\t\t\treturn 0;\n\n\t\tbundle[nr++] = xdst;\n\n\t\tmtu = dst_mtu(xfrm_dst_child(dst));\n\t\tif (xdst->child_mtu_cached != mtu) {\n\t\t\tstart_from = nr;\n\t\t\txdst->child_mtu_cached = mtu;\n\t\t}\n\n\t\tif (!dst_check(xdst->route, xdst->route_cookie))\n\t\t\treturn 0;\n\t\tmtu = dst_mtu(xdst->route);\n\t\tif (xdst->route_mtu_cached != mtu) {\n\t\t\tstart_from = nr;\n\t\t\txdst->route_mtu_cached = mtu;\n\t\t}\n\n\t\tdst = xfrm_dst_child(dst);\n\t} while (dst->xfrm);\n\n\tif (likely(!start_from))\n\t\treturn 1;\n\n\txdst = bundle[start_from - 1];\n\tmtu = xdst->child_mtu_cached;\n\twhile (start_from--) {\n\t\tdst = &xdst->u.dst;\n\n\t\tmtu = xfrm_state_mtu(dst->xfrm, mtu);\n\t\tif (mtu > xdst->route_mtu_cached)\n\t\t\tmtu = xdst->route_mtu_cached;\n\t\tdst_metric_set(dst, RTAX_MTU, mtu);\n\t\tif (!start_from)\n\t\t\tbreak;\n\n\t\txdst = bundle[start_from - 1];\n\t\txdst->child_mtu_cached = mtu;\n\t}\n\n\treturn 1;\n}\n\nstatic unsigned int xfrm_default_advmss(const struct dst_entry *dst)\n{\n\treturn dst_metric_advmss(xfrm_dst_path(dst));\n}\n\nstatic unsigned int xfrm_mtu(const struct dst_entry *dst)\n{\n\tunsigned int mtu = dst_metric_raw(dst, RTAX_MTU);\n\n\treturn mtu ? : dst_mtu(xfrm_dst_path(dst));\n}\n\nstatic const void *xfrm_get_dst_nexthop(const struct dst_entry *dst,\n\t\t\t\t\tconst void *daddr)\n{\n\twhile (dst->xfrm) {\n\t\tconst struct xfrm_state *xfrm = dst->xfrm;\n\n\t\tdst = xfrm_dst_child(dst);\n\n\t\tif (xfrm->props.mode == XFRM_MODE_TRANSPORT)\n\t\t\tcontinue;\n\t\tif (xfrm->type->flags & XFRM_TYPE_REMOTE_COADDR)\n\t\t\tdaddr = xfrm->coaddr;\n\t\telse if (!(xfrm->type->flags & XFRM_TYPE_LOCAL_COADDR))\n\t\t\tdaddr = &xfrm->id.daddr;\n\t}\n\treturn daddr;\n}\n\nstatic struct neighbour *xfrm_neigh_lookup(const struct dst_entry *dst,\n\t\t\t\t\t   struct sk_buff *skb,\n\t\t\t\t\t   const void *daddr)\n{\n\tconst struct dst_entry *path = xfrm_dst_path(dst);\n\n\tif (!skb)\n\t\tdaddr = xfrm_get_dst_nexthop(dst, daddr);\n\treturn path->ops->neigh_lookup(path, skb, daddr);\n}\n\nstatic void xfrm_confirm_neigh(const struct dst_entry *dst, const void *daddr)\n{\n\tconst struct dst_entry *path = xfrm_dst_path(dst);\n\n\tdaddr = xfrm_get_dst_nexthop(dst, daddr);\n\tpath->ops->confirm_neigh(path, daddr);\n}\n\nint xfrm_policy_register_afinfo(const struct xfrm_policy_afinfo *afinfo, int family)\n{\n\tint err = 0;\n\n\tif (WARN_ON(family >= ARRAY_SIZE(xfrm_policy_afinfo)))\n\t\treturn -EAFNOSUPPORT;\n\n\tspin_lock(&xfrm_policy_afinfo_lock);\n\tif (unlikely(xfrm_policy_afinfo[family] != NULL))\n\t\terr = -EEXIST;\n\telse {\n\t\tstruct dst_ops *dst_ops = afinfo->dst_ops;\n\t\tif (likely(dst_ops->kmem_cachep == NULL))\n\t\t\tdst_ops->kmem_cachep = xfrm_dst_cache;\n\t\tif (likely(dst_ops->check == NULL))\n\t\t\tdst_ops->check = xfrm_dst_check;\n\t\tif (likely(dst_ops->default_advmss == NULL))\n\t\t\tdst_ops->default_advmss = xfrm_default_advmss;\n\t\tif (likely(dst_ops->mtu == NULL))\n\t\t\tdst_ops->mtu = xfrm_mtu;\n\t\tif (likely(dst_ops->negative_advice == NULL))\n\t\t\tdst_ops->negative_advice = xfrm_negative_advice;\n\t\tif (likely(dst_ops->link_failure == NULL))\n\t\t\tdst_ops->link_failure = xfrm_link_failure;\n\t\tif (likely(dst_ops->neigh_lookup == NULL))\n\t\t\tdst_ops->neigh_lookup = xfrm_neigh_lookup;\n\t\tif (likely(!dst_ops->confirm_neigh))\n\t\t\tdst_ops->confirm_neigh = xfrm_confirm_neigh;\n\t\trcu_assign_pointer(xfrm_policy_afinfo[family], afinfo);\n\t}\n\tspin_unlock(&xfrm_policy_afinfo_lock);\n\n\treturn err;\n}\nEXPORT_SYMBOL(xfrm_policy_register_afinfo);\n\nvoid xfrm_policy_unregister_afinfo(const struct xfrm_policy_afinfo *afinfo)\n{\n\tstruct dst_ops *dst_ops = afinfo->dst_ops;\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(xfrm_policy_afinfo); i++) {\n\t\tif (xfrm_policy_afinfo[i] != afinfo)\n\t\t\tcontinue;\n\t\tRCU_INIT_POINTER(xfrm_policy_afinfo[i], NULL);\n\t\tbreak;\n\t}\n\n\tsynchronize_rcu();\n\n\tdst_ops->kmem_cachep = NULL;\n\tdst_ops->check = NULL;\n\tdst_ops->negative_advice = NULL;\n\tdst_ops->link_failure = NULL;\n}\nEXPORT_SYMBOL(xfrm_policy_unregister_afinfo);\n\nvoid xfrm_if_register_cb(const struct xfrm_if_cb *ifcb)\n{\n\tspin_lock(&xfrm_if_cb_lock);\n\trcu_assign_pointer(xfrm_if_cb, ifcb);\n\tspin_unlock(&xfrm_if_cb_lock);\n}\nEXPORT_SYMBOL(xfrm_if_register_cb);\n\nvoid xfrm_if_unregister_cb(void)\n{\n\tRCU_INIT_POINTER(xfrm_if_cb, NULL);\n\tsynchronize_rcu();\n}\nEXPORT_SYMBOL(xfrm_if_unregister_cb);\n\n#ifdef CONFIG_XFRM_STATISTICS\nstatic int __net_init xfrm_statistics_init(struct net *net)\n{\n\tint rv;\n\tnet->mib.xfrm_statistics = alloc_percpu(struct linux_xfrm_mib);\n\tif (!net->mib.xfrm_statistics)\n\t\treturn -ENOMEM;\n\trv = xfrm_proc_init(net);\n\tif (rv < 0)\n\t\tfree_percpu(net->mib.xfrm_statistics);\n\treturn rv;\n}\n\nstatic void xfrm_statistics_fini(struct net *net)\n{\n\txfrm_proc_fini(net);\n\tfree_percpu(net->mib.xfrm_statistics);\n}\n#else\nstatic int __net_init xfrm_statistics_init(struct net *net)\n{\n\treturn 0;\n}\n\nstatic void xfrm_statistics_fini(struct net *net)\n{\n}\n#endif\n\nstatic int __net_init xfrm_policy_init(struct net *net)\n{\n\tunsigned int hmask, sz;\n\tint dir, err;\n\n\tif (net_eq(net, &init_net)) {\n\t\txfrm_dst_cache = KMEM_CACHE(xfrm_dst, SLAB_HWCACHE_ALIGN | SLAB_PANIC);\n\t\terr = rhashtable_init(&xfrm_policy_inexact_table,\n\t\t\t\t      &xfrm_pol_inexact_params);\n\t\tBUG_ON(err);\n\t}\n\n\thmask = 8 - 1;\n\tsz = (hmask+1) * sizeof(struct hlist_head);\n\n\tnet->xfrm.policy_byidx = xfrm_hash_alloc(sz);\n\tif (!net->xfrm.policy_byidx)\n\t\tgoto out_byidx;\n\tnet->xfrm.policy_idx_hmask = hmask;\n\n\tfor (dir = 0; dir < XFRM_POLICY_MAX; dir++) {\n\t\tstruct xfrm_policy_hash *htab;\n\n\t\tnet->xfrm.policy_count[dir] = 0;\n\t\tnet->xfrm.policy_count[XFRM_POLICY_MAX + dir] = 0;\n\n\t\thtab = &net->xfrm.policy_bydst[dir];\n\t\thtab->table = xfrm_hash_alloc(sz);\n\t\tif (!htab->table)\n\t\t\tgoto out_bydst;\n\t\thtab->hmask = hmask;\n\t\thtab->dbits4 = 32;\n\t\thtab->sbits4 = 32;\n\t\thtab->dbits6 = 128;\n\t\thtab->sbits6 = 128;\n\t}\n\tnet->xfrm.policy_hthresh.lbits4 = 32;\n\tnet->xfrm.policy_hthresh.rbits4 = 32;\n\tnet->xfrm.policy_hthresh.lbits6 = 128;\n\tnet->xfrm.policy_hthresh.rbits6 = 128;\n\n\tseqlock_init(&net->xfrm.policy_hthresh.lock);\n\n\tINIT_LIST_HEAD(&net->xfrm.policy_all);\n\tINIT_LIST_HEAD(&net->xfrm.inexact_bins);\n\tINIT_WORK(&net->xfrm.policy_hash_work, xfrm_hash_resize);\n\tINIT_WORK(&net->xfrm.policy_hthresh.work, xfrm_hash_rebuild);\n\treturn 0;\n\nout_bydst:\n\tfor (dir--; dir >= 0; dir--) {\n\t\tstruct xfrm_policy_hash *htab;\n\n\t\thtab = &net->xfrm.policy_bydst[dir];\n\t\txfrm_hash_free(htab->table, sz);\n\t}\n\txfrm_hash_free(net->xfrm.policy_byidx, sz);\nout_byidx:\n\treturn -ENOMEM;\n}\n\nstatic void xfrm_policy_fini(struct net *net)\n{\n\tstruct xfrm_pol_inexact_bin *b, *t;\n\tunsigned int sz;\n\tint dir;\n\n\tflush_work(&net->xfrm.policy_hash_work);\n#ifdef CONFIG_XFRM_SUB_POLICY\n\txfrm_policy_flush(net, XFRM_POLICY_TYPE_SUB, false);\n#endif\n\txfrm_policy_flush(net, XFRM_POLICY_TYPE_MAIN, false);\n\n\tWARN_ON(!list_empty(&net->xfrm.policy_all));\n\n\tfor (dir = 0; dir < XFRM_POLICY_MAX; dir++) {\n\t\tstruct xfrm_policy_hash *htab;\n\n\t\thtab = &net->xfrm.policy_bydst[dir];\n\t\tsz = (htab->hmask + 1) * sizeof(struct hlist_head);\n\t\tWARN_ON(!hlist_empty(htab->table));\n\t\txfrm_hash_free(htab->table, sz);\n\t}\n\n\tsz = (net->xfrm.policy_idx_hmask + 1) * sizeof(struct hlist_head);\n\tWARN_ON(!hlist_empty(net->xfrm.policy_byidx));\n\txfrm_hash_free(net->xfrm.policy_byidx, sz);\n\n\tspin_lock_bh(&net->xfrm.xfrm_policy_lock);\n\tlist_for_each_entry_safe(b, t, &net->xfrm.inexact_bins, inexact_bins)\n\t\t__xfrm_policy_inexact_prune_bin(b, true);\n\tspin_unlock_bh(&net->xfrm.xfrm_policy_lock);\n}\n\nstatic int __net_init xfrm_net_init(struct net *net)\n{\n\tint rv;\n\n\t/* Initialize the per-net locks here */\n\tspin_lock_init(&net->xfrm.xfrm_state_lock);\n\tspin_lock_init(&net->xfrm.xfrm_policy_lock);\n\tseqcount_spinlock_init(&net->xfrm.xfrm_policy_hash_generation, &net->xfrm.xfrm_policy_lock);\n\tmutex_init(&net->xfrm.xfrm_cfg_mutex);\n\tnet->xfrm.policy_default[XFRM_POLICY_IN] = XFRM_USERPOLICY_ACCEPT;\n\tnet->xfrm.policy_default[XFRM_POLICY_FWD] = XFRM_USERPOLICY_ACCEPT;\n\tnet->xfrm.policy_default[XFRM_POLICY_OUT] = XFRM_USERPOLICY_ACCEPT;\n\n\trv = xfrm_statistics_init(net);\n\tif (rv < 0)\n\t\tgoto out_statistics;\n\trv = xfrm_state_init(net);\n\tif (rv < 0)\n\t\tgoto out_state;\n\trv = xfrm_policy_init(net);\n\tif (rv < 0)\n\t\tgoto out_policy;\n\trv = xfrm_sysctl_init(net);\n\tif (rv < 0)\n\t\tgoto out_sysctl;\n\n\trv = xfrm_nat_keepalive_net_init(net);\n\tif (rv < 0)\n\t\tgoto out_nat_keepalive;\n\n\treturn 0;\n\nout_nat_keepalive:\n\txfrm_sysctl_fini(net);\nout_sysctl:\n\txfrm_policy_fini(net);\nout_policy:\n\txfrm_state_fini(net);\nout_state:\n\txfrm_statistics_fini(net);\nout_statistics:\n\treturn rv;\n}\n\nstatic void __net_exit xfrm_net_exit(struct net *net)\n{\n\txfrm_nat_keepalive_net_fini(net);\n\txfrm_sysctl_fini(net);\n\txfrm_policy_fini(net);\n\txfrm_state_fini(net);\n\txfrm_statistics_fini(net);\n}\n\nstatic struct pernet_operations __net_initdata xfrm_net_ops = {\n\t.init = xfrm_net_init,\n\t.exit = xfrm_net_exit,\n};\n\nstatic const struct flow_dissector_key xfrm_flow_dissector_keys[] = {\n\t{\n\t\t.key_id = FLOW_DISSECTOR_KEY_CONTROL,\n\t\t.offset = offsetof(struct xfrm_flow_keys, control),\n\t},\n\t{\n\t\t.key_id = FLOW_DISSECTOR_KEY_BASIC,\n\t\t.offset = offsetof(struct xfrm_flow_keys, basic),\n\t},\n\t{\n\t\t.key_id = FLOW_DISSECTOR_KEY_IPV4_ADDRS,\n\t\t.offset = offsetof(struct xfrm_flow_keys, addrs.ipv4),\n\t},\n\t{\n\t\t.key_id = FLOW_DISSECTOR_KEY_IPV6_ADDRS,\n\t\t.offset = offsetof(struct xfrm_flow_keys, addrs.ipv6),\n\t},\n\t{\n\t\t.key_id = FLOW_DISSECTOR_KEY_PORTS,\n\t\t.offset = offsetof(struct xfrm_flow_keys, ports),\n\t},\n\t{\n\t\t.key_id = FLOW_DISSECTOR_KEY_GRE_KEYID,\n\t\t.offset = offsetof(struct xfrm_flow_keys, gre),\n\t},\n\t{\n\t\t.key_id = FLOW_DISSECTOR_KEY_IP,\n\t\t.offset = offsetof(struct xfrm_flow_keys, ip),\n\t},\n\t{\n\t\t.key_id = FLOW_DISSECTOR_KEY_ICMP,\n\t\t.offset = offsetof(struct xfrm_flow_keys, icmp),\n\t},\n};\n\nvoid __init xfrm_init(void)\n{\n\tskb_flow_dissector_init(&xfrm_session_dissector,\n\t\t\t\txfrm_flow_dissector_keys,\n\t\t\t\tARRAY_SIZE(xfrm_flow_dissector_keys));\n\n\tregister_pernet_subsys(&xfrm_net_ops);\n\txfrm_dev_init();\n\txfrm_input_init();\n\n#ifdef CONFIG_XFRM_ESPINTCP\n\tespintcp_init();\n#endif\n\n\tregister_xfrm_state_bpf();\n\txfrm_nat_keepalive_init(AF_INET);\n}\n\n#ifdef CONFIG_AUDITSYSCALL\nstatic void xfrm_audit_common_policyinfo(struct xfrm_policy *xp,\n\t\t\t\t\t struct audit_buffer *audit_buf)\n{\n\tstruct xfrm_sec_ctx *ctx = xp->security;\n\tstruct xfrm_selector *sel = &xp->selector;\n\n\tif (ctx)\n\t\taudit_log_format(audit_buf, \" sec_alg=%u sec_doi=%u sec_obj=%s\",\n\t\t\t\t ctx->ctx_alg, ctx->ctx_doi, ctx->ctx_str);\n\n\tswitch (sel->family) {\n\tcase AF_INET:\n\t\taudit_log_format(audit_buf, \" src=%pI4\", &sel->saddr.a4);\n\t\tif (sel->prefixlen_s != 32)\n\t\t\taudit_log_format(audit_buf, \" src_prefixlen=%d\",\n\t\t\t\t\t sel->prefixlen_s);\n\t\taudit_log_format(audit_buf, \" dst=%pI4\", &sel->daddr.a4);\n\t\tif (sel->prefixlen_d != 32)\n\t\t\taudit_log_format(audit_buf, \" dst_prefixlen=%d\",\n\t\t\t\t\t sel->prefixlen_d);\n\t\tbreak;\n\tcase AF_INET6:\n\t\taudit_log_format(audit_buf, \" src=%pI6\", sel->saddr.a6);\n\t\tif (sel->prefixlen_s != 128)\n\t\t\taudit_log_format(audit_buf, \" src_prefixlen=%d\",\n\t\t\t\t\t sel->prefixlen_s);\n\t\taudit_log_format(audit_buf, \" dst=%pI6\", sel->daddr.a6);\n\t\tif (sel->prefixlen_d != 128)\n\t\t\taudit_log_format(audit_buf, \" dst_prefixlen=%d\",\n\t\t\t\t\t sel->prefixlen_d);\n\t\tbreak;\n\t}\n}\n\nvoid xfrm_audit_policy_add(struct xfrm_policy *xp, int result, bool task_valid)\n{\n\tstruct audit_buffer *audit_buf;\n\n\taudit_buf = xfrm_audit_start(\"SPD-add\");\n\tif (audit_buf == NULL)\n\t\treturn;\n\txfrm_audit_helper_usrinfo(task_valid, audit_buf);\n\taudit_log_format(audit_buf, \" res=%u\", result);\n\txfrm_audit_common_policyinfo(xp, audit_buf);\n\taudit_log_end(audit_buf);\n}\nEXPORT_SYMBOL_GPL(xfrm_audit_policy_add);\n\nvoid xfrm_audit_policy_delete(struct xfrm_policy *xp, int result,\n\t\t\t      bool task_valid)\n{\n\tstruct audit_buffer *audit_buf;\n\n\taudit_buf = xfrm_audit_start(\"SPD-delete\");\n\tif (audit_buf == NULL)\n\t\treturn;\n\txfrm_audit_helper_usrinfo(task_valid, audit_buf);\n\taudit_log_format(audit_buf, \" res=%u\", result);\n\txfrm_audit_common_policyinfo(xp, audit_buf);\n\taudit_log_end(audit_buf);\n}\nEXPORT_SYMBOL_GPL(xfrm_audit_policy_delete);\n#endif\n\n#ifdef CONFIG_XFRM_MIGRATE\nstatic struct xfrm_policy *xfrm_migrate_policy_find(const struct xfrm_selector *sel,\n\t\t\t\t\t\t    u8 dir, u8 type, struct net *net, u32 if_id)\n{\n\tstruct xfrm_policy *pol;\n\tstruct flowi fl;\n\n\tmemset(&fl, 0, sizeof(fl));\n\n\tfl.flowi_proto = sel->proto;\n\n\tswitch (sel->family) {\n\tcase AF_INET:\n\t\tfl.u.ip4.saddr = sel->saddr.a4;\n\t\tfl.u.ip4.daddr = sel->daddr.a4;\n\t\tif (sel->proto == IPSEC_ULPROTO_ANY)\n\t\t\tbreak;\n\t\tfl.u.flowi4_oif = sel->ifindex;\n\t\tfl.u.ip4.fl4_sport = sel->sport;\n\t\tfl.u.ip4.fl4_dport = sel->dport;\n\t\tbreak;\n\tcase AF_INET6:\n\t\tfl.u.ip6.saddr = sel->saddr.in6;\n\t\tfl.u.ip6.daddr = sel->daddr.in6;\n\t\tif (sel->proto == IPSEC_ULPROTO_ANY)\n\t\t\tbreak;\n\t\tfl.u.flowi6_oif = sel->ifindex;\n\t\tfl.u.ip6.fl4_sport = sel->sport;\n\t\tfl.u.ip6.fl4_dport = sel->dport;\n\t\tbreak;\n\tdefault:\n\t\treturn ERR_PTR(-EAFNOSUPPORT);\n\t}\n\n\trcu_read_lock();\n\n\tpol = xfrm_policy_lookup_bytype(net, type, &fl, sel->family, dir, if_id);\n\tif (IS_ERR_OR_NULL(pol))\n\t\tgoto out_unlock;\n\n\tif (!xfrm_pol_hold_rcu(pol))\n\t\tpol = NULL;\nout_unlock:\n\trcu_read_unlock();\n\treturn pol;\n}\n\nstatic int migrate_tmpl_match(const struct xfrm_migrate *m, const struct xfrm_tmpl *t)\n{\n\tint match = 0;\n\n\tif (t->mode == m->mode && t->id.proto == m->proto &&\n\t    (m->reqid == 0 || t->reqid == m->reqid)) {\n\t\tswitch (t->mode) {\n\t\tcase XFRM_MODE_TUNNEL:\n\t\tcase XFRM_MODE_BEET:\n\t\tcase XFRM_MODE_IPTFS:\n\t\t\tif (xfrm_addr_equal(&t->id.daddr, &m->old_daddr,\n\t\t\t\t\t    m->old_family) &&\n\t\t\t    xfrm_addr_equal(&t->saddr, &m->old_saddr,\n\t\t\t\t\t    m->old_family)) {\n\t\t\t\tmatch = 1;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase XFRM_MODE_TRANSPORT:\n\t\t\t/* in case of transport mode, template does not store\n\t\t\t   any IP addresses, hence we just compare mode and\n\t\t\t   protocol */\n\t\t\tmatch = 1;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn match;\n}\n\n/* update endpoint address(es) of template(s) */\nstatic int xfrm_policy_migrate(struct xfrm_policy *pol,\n\t\t\t       struct xfrm_migrate *m, int num_migrate,\n\t\t\t       struct netlink_ext_ack *extack)\n{\n\tstruct xfrm_migrate *mp;\n\tint i, j, n = 0;\n\n\twrite_lock_bh(&pol->lock);\n\tif (unlikely(pol->walk.dead)) {\n\t\t/* target policy has been deleted */\n\t\tNL_SET_ERR_MSG(extack, \"Target policy not found\");\n\t\twrite_unlock_bh(&pol->lock);\n\t\treturn -ENOENT;\n\t}\n\n\tfor (i = 0; i < pol->xfrm_nr; i++) {\n\t\tfor (j = 0, mp = m; j < num_migrate; j++, mp++) {\n\t\t\tif (!migrate_tmpl_match(mp, &pol->xfrm_vec[i]))\n\t\t\t\tcontinue;\n\t\t\tn++;\n\t\t\tif (pol->xfrm_vec[i].mode != XFRM_MODE_TUNNEL &&\n\t\t\t    pol->xfrm_vec[i].mode != XFRM_MODE_BEET &&\n\t\t\t    pol->xfrm_vec[i].mode != XFRM_MODE_IPTFS)\n\t\t\t\tcontinue;\n\t\t\t/* update endpoints */\n\t\t\tmemcpy(&pol->xfrm_vec[i].id.daddr, &mp->new_daddr,\n\t\t\t       sizeof(pol->xfrm_vec[i].id.daddr));\n\t\t\tmemcpy(&pol->xfrm_vec[i].saddr, &mp->new_saddr,\n\t\t\t       sizeof(pol->xfrm_vec[i].saddr));\n\t\t\tpol->xfrm_vec[i].encap_family = mp->new_family;\n\t\t\t/* flush bundles */\n\t\t\tatomic_inc(&pol->genid);\n\t\t}\n\t}\n\n\twrite_unlock_bh(&pol->lock);\n\n\tif (!n)\n\t\treturn -ENODATA;\n\n\treturn 0;\n}\n\nstatic int xfrm_migrate_check(const struct xfrm_migrate *m, int num_migrate,\n\t\t\t      struct netlink_ext_ack *extack)\n{\n\tint i, j;\n\n\tif (num_migrate < 1 || num_migrate > XFRM_MAX_DEPTH) {\n\t\tNL_SET_ERR_MSG(extack, \"Invalid number of SAs to migrate, must be 0 < num <= XFRM_MAX_DEPTH (6)\");\n\t\treturn -EINVAL;\n\t}\n\n\tfor (i = 0; i < num_migrate; i++) {\n\t\tif (xfrm_addr_any(&m[i].new_daddr, m[i].new_family) ||\n\t\t    xfrm_addr_any(&m[i].new_saddr, m[i].new_family)) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Addresses in the MIGRATE attribute's list cannot be null\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t/* check if there is any duplicated entry */\n\t\tfor (j = i + 1; j < num_migrate; j++) {\n\t\t\tif (!memcmp(&m[i].old_daddr, &m[j].old_daddr,\n\t\t\t\t    sizeof(m[i].old_daddr)) &&\n\t\t\t    !memcmp(&m[i].old_saddr, &m[j].old_saddr,\n\t\t\t\t    sizeof(m[i].old_saddr)) &&\n\t\t\t    m[i].proto == m[j].proto &&\n\t\t\t    m[i].mode == m[j].mode &&\n\t\t\t    m[i].reqid == m[j].reqid &&\n\t\t\t    m[i].old_family == m[j].old_family) {\n\t\t\t\tNL_SET_ERR_MSG(extack, \"Entries in the MIGRATE attribute's list must be unique\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nint xfrm_migrate(const struct xfrm_selector *sel, u8 dir, u8 type,\n\t\t struct xfrm_migrate *m, int num_migrate,\n\t\t struct xfrm_kmaddress *k, struct net *net,\n\t\t struct xfrm_encap_tmpl *encap, u32 if_id,\n\t\t struct netlink_ext_ack *extack, struct xfrm_user_offload *xuo)\n{\n\tint i, err, nx_cur = 0, nx_new = 0;\n\tstruct xfrm_policy *pol = NULL;\n\tstruct xfrm_state *x, *xc;\n\tstruct xfrm_state *x_cur[XFRM_MAX_DEPTH];\n\tstruct xfrm_state *x_new[XFRM_MAX_DEPTH];\n\tstruct xfrm_migrate *mp;\n\n\t/* Stage 0 - sanity checks */\n\terr = xfrm_migrate_check(m, num_migrate, extack);\n\tif (err < 0)\n\t\tgoto out;\n\n\tif (dir >= XFRM_POLICY_MAX) {\n\t\tNL_SET_ERR_MSG(extack, \"Invalid policy direction\");\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\t/* Stage 1 - find policy */\n\tpol = xfrm_migrate_policy_find(sel, dir, type, net, if_id);\n\tif (IS_ERR_OR_NULL(pol)) {\n\t\tNL_SET_ERR_MSG(extack, \"Target policy not found\");\n\t\terr = IS_ERR(pol) ? PTR_ERR(pol) : -ENOENT;\n\t\tgoto out;\n\t}\n\n\t/* Stage 2 - find and update state(s) */\n\tfor (i = 0, mp = m; i < num_migrate; i++, mp++) {\n\t\tif ((x = xfrm_migrate_state_find(mp, net, if_id))) {\n\t\t\tx_cur[nx_cur] = x;\n\t\t\tnx_cur++;\n\t\t\txc = xfrm_state_migrate(x, mp, encap, net, xuo, extack);\n\t\t\tif (xc) {\n\t\t\t\tx_new[nx_new] = xc;\n\t\t\t\tnx_new++;\n\t\t\t} else {\n\t\t\t\terr = -ENODATA;\n\t\t\t\tgoto restore_state;\n\t\t\t}\n\t\t}\n\t}\n\n\t/* Stage 3 - update policy */\n\terr = xfrm_policy_migrate(pol, m, num_migrate, extack);\n\tif (err < 0)\n\t\tgoto restore_state;\n\n\t/* Stage 4 - delete old state(s) */\n\tif (nx_cur) {\n\t\txfrm_states_put(x_cur, nx_cur);\n\t\txfrm_states_delete(x_cur, nx_cur);\n\t}\n\n\t/* Stage 5 - announce */\n\tkm_migrate(sel, dir, type, m, num_migrate, k, encap);\n\n\txfrm_pol_put(pol);\n\n\treturn 0;\nout:\n\treturn err;\n\nrestore_state:\n\tif (pol)\n\t\txfrm_pol_put(pol);\n\tif (nx_cur)\n\t\txfrm_states_put(x_cur, nx_cur);\n\tif (nx_new)\n\t\txfrm_states_delete(x_new, nx_new);\n\n\treturn err;\n}\nEXPORT_SYMBOL(xfrm_migrate);\n#endif"
            ]
        ],
        "explanation": "Explanation: \nThe data-flow propagation path involves the `delete` variable in the function `xfrm_policy_bysel_ctx` leading to a sink at line 65. In this function, the `delete` parameter is checked at line 51 (`if (delete) {`). If `delete` is true (non-zero), it proceeds to call `security_xfrm_policy_delete` at line 52 and then `__xfrm_policy_unlink` at line 57. However, at line 65, there is a condition `if (bin && delete)` that calls `xfrm_policy_inexact_prune_bin(bin)`. \n\nThe critical point is that `bin` is initialized to `NULL` at line 6 and only set within the `if (!chain)` block (lines 13-43). If `chain` is not NULL (i.e., the `else` block at line 44 is taken), `bin` remains NULL. Therefore, for the sink at line 65 to be reached with `bin` non-NULL, the `if (!chain)` condition must be true. However, the `delete` variable is independent of this condition. \n\nThere is no conflict between the conditions for `delete` and the path to the sink. The sink is reachable if `delete` is true and `bin` is non-NULL (which requires the `if (!chain)` branch to be taken). Since there is no guard or modification that prevents `delete` from being true when `bin` is non-NULL, the path is reachable. The UAF bug would occur if `xfrm_policy_inexact_prune_bin(bin)` is called with a freed or invalid `bin`, but the code does not show any explicit freeing of `bin` before this call in this function. However, the question is about the propagation path causing UAF, and the path itself is reachable without interference.\n\nAnswer: Yes",
        "is_human_confirmed_true": "False",
        "reason": "the LLM mess up program points and sink points. The logic of analysis is correct, while due to limited context, it can not find that all caller of this function have null-check of its return value."
    }
}